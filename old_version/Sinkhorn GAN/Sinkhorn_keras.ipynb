{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib\n",
    "#matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle as pkl\n",
    "\n",
    "\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "np.random.seed(0)\n",
    "tf.random.set_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIM = 64 # Model dimensionality (number of neurons in the hidden layer(s))\n",
    "CRITIC_ITERS = 10 # How many critic iterations (Sinkhorn iterations) per generator iteration#was 50\n",
    "BATCH_SIZE = 1024#256 # Batch size\n",
    "ITERS = 2500#100000 # how many generator iterations to train for\n",
    "DATA_DIM = 32\n",
    "LATENT_DIM = 4\n",
    "INITIALIZATION = 'he'#'glorot'\n",
    "COVARIANCE_SCALE = np.sqrt(DATA_DIM)\n",
    "INITIALIZE_LAST = True\n",
    "SAMPLE_SIZE = 100000\n",
    "LAMBDA = 0.3#2/(COVARIANCE_SCALE)\n",
    "MODE = 'divergence' #'loss'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if INITIALIZATION == 'he':\n",
    "    weight_initializer = keras.initializers.he_uniform()\n",
    "if INITIALIZATION == 'glorot':\n",
    "    weight_initializer = keras.initializers.glorot_uniform()\n",
    "bias_initializer = keras.initializers.zeros()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator:\n",
      "Model: \"generator\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 4)]               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                320       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 32)                2080      \n",
      "=================================================================\n",
      "Total params: 10,720\n",
      "Trainable params: 10,720\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#class WGAN:\n",
    " #   def __init__()self\n",
    "latent_sample = keras.Input(shape=(LATENT_DIM,))\n",
    "hidden_layer = latent_sample\n",
    "for i in range(3):\n",
    "    hidden_layer = layers.Dense(DIM, activation=\"relu\", kernel_initializer=weight_initializer,\n",
    "        bias_initializer=bias_initializer)(hidden_layer)\n",
    "output = layers.Dense(DATA_DIM, kernel_initializer=weight_initializer,\n",
    "                      bias_initializer=bias_initializer)(hidden_layer)\n",
    "generator = keras.Model(inputs=latent_sample, outputs = output, name=\"generator\")\n",
    "print('Generator:')\n",
    "print(generator.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import logsumexp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def squared_l2_matrix_np(X, Y):\n",
    "    squared_l2_X = np.sum(np.square(X), axis = 1, keepdims=True)\n",
    "    squared_l2_Y = np.sum(np.square(Y), axis = 1, keepdims=True)\n",
    "    XY = X.dot(Y.T)\n",
    "    return squared_l2_X + tf.transpose(squared_l2_Y) - 2 * XY\n",
    "\n",
    "def log_coupling_np(psi_X, psi_Y, cost_matrix, epsilon):\n",
    "    C_tild = cost_matrix - np.expand_dims(psi_X, axis=1) - np.expand_dims(psi_Y, axis=0)\n",
    "    return -C_tild/epsilon\n",
    "\n",
    "def sinkhorn_step_np(psi_X, psi_Y, log_X_prob, log_Y_prob, cost_matrix, epsilon, return_diff = False):\n",
    "    psi_X_upd = epsilon * (log_X_prob - \\\n",
    "                       logsumexp((np.expand_dims(psi_Y, axis=0) - cost_matrix) / epsilon, axis = 1))\n",
    "    psi_Y_upd = epsilon * (log_Y_prob - \\\n",
    "                       logsumexp((np.expand_dims(psi_X_upd, axis=1) - cost_matrix)/epsilon,axis = 0))\n",
    "    if return_diff:\n",
    "        diff = np.linalg.norm(psi_X_upd - psi_X) + np.linalg.norm(psi_Y_upd - psi_Y)\n",
    "    psi_X = psi_X_upd\n",
    "    psi_Y = psi_Y_upd\n",
    "    if return_diff:\n",
    "        return psi_X, psi_Y, diff\n",
    "    return psi_X, psi_Y\n",
    "\n",
    "def sinkhorn_loss_np(X, Y, epsilon, num_steps):\n",
    "    cost_matrix = squared_l2_matrix_np(X,Y)\n",
    "    log_X_prob = - np.log(X.shape[0])\n",
    "    log_Y_prob = - np.log(Y.shape[0])\n",
    "    psi_Y = np.zeros(Y.shape[0])\n",
    "    for l in range(num_steps-1):\n",
    "        psi_X, psi_Y = sinkhorn_step_np(None, psi_Y, log_X_prob, log_Y_prob, cost_matrix, epsilon)\n",
    "    psi_X, psi_Y, diff = sinkhorn_step_np(psi_X, psi_Y, log_X_prob, log_Y_prob, \\\n",
    "                                       cost_matrix, epsilon, return_diff = True)\n",
    "    #return psi_X, psi_Y, diff\n",
    "    log_pi = log_coupling_np(psi_X, psi_Y, cost_matrix, epsilon)\n",
    "    pi = np.exp(log_pi)\n",
    "    loss = np.sum(pi*(cost_matrix+epsilon*log_pi)) - epsilon*(log_X_prob + log_Y_prob)\n",
    "    #X and Y are uniform, so entropy = -log(probability)\n",
    "    return loss, diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def squared_l2_matrix(X, Y):\n",
    "    squared_l2_X = tf.reduce_sum(tf.square(X), axis = 1, keepdims=True)\n",
    "    squared_l2_Y = tf.reduce_sum(tf.square(Y), axis = 1, keepdims=True)\n",
    "    XY = tf.matmul(X,tf.transpose(Y))\n",
    "    return squared_l2_X + tf.transpose(squared_l2_Y) - 2 * XY\n",
    "\n",
    "def log_coupling(psi_X, psi_Y, cost_matrix, epsilon):\n",
    "    C_tild = cost_matrix - tf.expand_dims(psi_X, axis=1) - tf.expand_dims(psi_Y, axis=0)\n",
    "    return -C_tild/epsilon\n",
    "\n",
    "def sinkhorn_step(psi_X, psi_Y, log_X_prob, log_Y_prob, cost_matrix, epsilon, return_diff = False):\n",
    "    psi_X_upd = epsilon * (log_X_prob - \\\n",
    "                       tf.reduce_logsumexp((tf.expand_dims(psi_Y, axis=0) - cost_matrix) / epsilon, axis = 1))\n",
    "    psi_Y_upd = epsilon * (log_Y_prob - \\\n",
    "                       tf.reduce_logsumexp((tf.expand_dims(psi_X_upd, axis=1) - cost_matrix)/epsilon,axis = 0))\n",
    "    if return_diff:\n",
    "        diff = tf.norm(psi_X_upd - psi_X) + tf.norm(psi_Y_upd - psi_Y)\n",
    "    psi_X = psi_X_upd\n",
    "    psi_Y = psi_Y_upd\n",
    "    if return_diff:\n",
    "        return psi_X, psi_Y, diff\n",
    "    return psi_X, psi_Y\n",
    "\n",
    "def sinkhorn_loss(X, Y, epsilon, num_steps, return_diff = False, return_diff_only = False):\n",
    "    cost_matrix = squared_l2_matrix(X,Y)\n",
    "    log_X_prob = - tf.math.log(tf.cast(tf.shape(X)[0], tf.float32))\n",
    "    log_Y_prob = - tf.math.log(tf.cast(tf.shape(Y)[0], tf.float32))\n",
    "    psi_Y = tf.zeros([tf.shape(Y)[0]])\n",
    "    for l in range(num_steps-1):\n",
    "        psi_X, psi_Y = sinkhorn_step(None, psi_Y, log_X_prob, log_Y_prob, cost_matrix, epsilon)\n",
    "    psi_X, psi_Y, diff = sinkhorn_step(psi_X, psi_Y, log_X_prob, log_Y_prob, \\\n",
    "                                       cost_matrix, epsilon, return_diff = True)\n",
    "    #return psi_X, psi_Y, diff\n",
    "    log_pi = log_coupling(psi_X, psi_Y, cost_matrix, epsilon)\n",
    "    pi = tf.exp(log_pi)\n",
    "    loss = tf.reduce_sum(pi*(cost_matrix+epsilon*log_pi)) - epsilon*(log_X_prob + log_Y_prob)\n",
    "    #X and Y are uniform, so entropy = -log(probability)\n",
    "    if return_diff_only:\n",
    "        return diff\n",
    "    if return_diff:\n",
    "        return loss, diff\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = LAMBDA\n",
    "if MODE == 'divergence':\n",
    "    model_loss = lambda x, y: sinkhorn_loss(x, y, epsilon, CRITIC_ITERS) - 0.5*\\\n",
    "        (sinkhorn_loss(x, x, epsilon, CRITIC_ITERS)-sinkhorn_loss(y, y, epsilon, CRITIC_ITERS))\n",
    "else:\n",
    "    model_loss = lambda x, y: sinkhorn_loss(x, y, epsilon, CRITIC_ITERS)\n",
    "\n",
    "if MODE == 'divergence':\n",
    "    args = [epsilon, CRITIC_ITERS, True, True]\n",
    "    sinkhorn_diff = lambda x, y: (sinkhorn_loss(x, y, *args)\\\n",
    "        +sinkhorn_loss(x, x, *args)+sinkhorn_loss(y, y, *args))/3\n",
    "else:\n",
    "    sinkhorn_diff = lambda x, y: sinkhorn_loss(x, y, epsilon, CRITIC_ITERS)\n",
    "\n",
    "metrics = lambda x, y: tf.norm(tfp.stats.covariance(x) - tfp.stats.covariance(y))\n",
    "generator.compile(optimizer=\"Adam\", loss=model_loss, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inf_train_gen():\n",
    "    np.random.seed(1)\n",
    "    full_dataset = np.random.randn(SAMPLE_SIZE,DATA_DIM) / np.sqrt(COVARIANCE_SCALE) \n",
    "    i = 0\n",
    "    offset = 0\n",
    "    while True:\n",
    "        dataset = full_dataset[i*BATCH_SIZE+offset:(i+1)*BATCH_SIZE+offset,:]\n",
    "        if (i+1)*BATCH_SIZE+offset > SAMPLE_SIZE: \n",
    "            offset = (i+1)*BATCH_SIZE+offset - SAMPLE_SIZE\n",
    "            np.random.shuffle(full_dataset)\n",
    "            dataset = np.concatenate([dataset,full_dataset[:offset,:]], axis = 0)\n",
    "            i = -1 \n",
    "        i+=1\n",
    "        yield dataset\n",
    "data_gen = inf_train_gen()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  0\n",
      "Training: loss 4.678339958190918, covariance difference 1.0191571712493896\n",
      "Validation: loss 5.60212407967657, covariance difference 8.62967076942069, sinkhorn epsilon 0.00026994421971048867\n",
      "Iteration  1\n",
      "Training: loss 4.577845573425293, covariance difference 1.0029255151748657\n",
      "Validation: loss 5.58790516611306, covariance difference 8.460720479334046, sinkhorn epsilon 3.248205632779033e-11\n",
      "Iteration  2\n",
      "Training: loss 4.562339782714844, covariance difference 0.9992423057556152\n",
      "Validation: loss 5.581281204060176, covariance difference 8.395882684734616, sinkhorn epsilon 8.801552625700866e-08\n",
      "Iteration  3\n",
      "Training: loss 4.552487373352051, covariance difference 0.9983996748924255\n",
      "Validation: loss 5.6549487054529095, covariance difference 8.494231741067493, sinkhorn epsilon 3.8858213705074945e-10\n",
      "Iteration  4\n",
      "Training: loss 4.627856254577637, covariance difference 1.0117124319076538\n",
      "Validation: loss 5.718280632689711, covariance difference 8.689667058771258, sinkhorn epsilon 2.3035036241502162e-12\n",
      "Iteration  5\n",
      "Training: loss 4.687665939331055, covariance difference 1.0233023166656494\n",
      "Validation: loss 5.600401562036202, covariance difference 8.615247322793804, sinkhorn epsilon 4.5729290384356576e-07\n",
      "Iteration  6\n",
      "Training: loss 4.571714401245117, covariance difference 1.002945899963379\n",
      "Validation: loss 5.735583399567313, covariance difference 8.706684492138324, sinkhorn epsilon 2.4681915433950527e-10\n",
      "Iteration  7\n",
      "Training: loss 4.709214210510254, covariance difference 1.0267360210418701\n",
      "Validation: loss 5.684916637366473, covariance difference 8.870867863438525, sinkhorn epsilon 1.074569027005798e-09\n",
      "Iteration  8\n",
      "Training: loss 4.656804084777832, covariance difference 1.0184440612792969\n",
      "Validation: loss 5.735295809009166, covariance difference 8.735028445547352, sinkhorn epsilon 6.317362042998669e-07\n",
      "Iteration  9\n",
      "Training: loss 4.708856582641602, covariance difference 1.0267786979675293\n",
      "Validation: loss 5.5823036380580096, covariance difference 8.325024893118481, sinkhorn epsilon 2.0217610898064505e-10\n",
      "Iteration  10\n",
      "Training: loss 4.551904678344727, covariance difference 0.9985905289649963\n",
      "Validation: loss 5.674598019388831, covariance difference 8.675638860697768, sinkhorn epsilon 1.6997621264192253e-10\n",
      "Iteration  11\n",
      "Training: loss 4.645580291748047, covariance difference 1.0152262449264526\n",
      "Validation: loss 5.661071781440281, covariance difference 8.82615979158902, sinkhorn epsilon 4.372881177965378e-14\n",
      "Iteration  12\n",
      "Training: loss 4.627687931060791, covariance difference 1.013627529144287\n",
      "Validation: loss 5.6451142881138034, covariance difference 8.54523466134359, sinkhorn epsilon 6.164374953864743e-11\n",
      "Iteration  13\n",
      "Training: loss 4.614173412322998, covariance difference 1.0101439952850342\n",
      "Validation: loss 5.622598726251147, covariance difference 8.72565379202672, sinkhorn epsilon 6.756367259797357e-14\n",
      "Iteration  14\n",
      "Training: loss 4.5890607833862305, covariance difference 1.0084829330444336\n",
      "Validation: loss 5.6204984569934915, covariance difference 8.448583662315837, sinkhorn epsilon 9.132852741325269e-08\n",
      "Iteration  15\n",
      "Training: loss 4.588761806488037, covariance difference 1.0070923566818237\n",
      "Validation: loss 5.674218504726584, covariance difference 8.623447980442103, sinkhorn epsilon 2.0838749969367918e-13\n",
      "Iteration  16\n",
      "Training: loss 4.641618728637695, covariance difference 1.0174013376235962\n",
      "Validation: loss 5.676563224886059, covariance difference 8.66359383371606, sinkhorn epsilon 9.852652957454348e-10\n",
      "Iteration  17\n",
      "Training: loss 4.645273208618164, covariance difference 1.0175292491912842\n",
      "Validation: loss 5.623093756501266, covariance difference 8.556775550783348, sinkhorn epsilon 2.093982703922826e-13\n",
      "Iteration  18\n",
      "Training: loss 4.59101676940918, covariance difference 1.007634162902832\n",
      "Validation: loss 5.592029771347585, covariance difference 8.586287684929193, sinkhorn epsilon 6.230267079344406e-14\n",
      "Iteration  19\n",
      "Training: loss 4.559809684753418, covariance difference 1.0020333528518677\n",
      "Validation: loss 5.629141736782662, covariance difference 8.401909754685715, sinkhorn epsilon 2.7978504887413583e-13\n",
      "Iteration  20\n",
      "Training: loss 4.594851970672607, covariance difference 1.0082082748413086\n",
      "Validation: loss 5.697434211760529, covariance difference 8.362351597365935, sinkhorn epsilon 6.920106468831608e-08\n",
      "Iteration  21\n",
      "Training: loss 4.663494110107422, covariance difference 1.0223468542099\n",
      "Validation: loss 5.692660551756583, covariance difference 8.639164093018836, sinkhorn epsilon 3.765603430190034e-13\n",
      "Iteration  22\n",
      "Training: loss 4.6598358154296875, covariance difference 1.02083420753479\n",
      "Validation: loss 5.67681523965804, covariance difference 8.933455557313474, sinkhorn epsilon 2.7230696203356577e-07\n",
      "Iteration  23\n",
      "Training: loss 4.643829345703125, covariance difference 1.0165894031524658\n",
      "Validation: loss 5.693555790192821, covariance difference 8.526923786965009, sinkhorn epsilon 9.673533968463799e-14\n",
      "Iteration  24\n",
      "Training: loss 4.659311294555664, covariance difference 1.0199973583221436\n",
      "Validation: loss 5.657636341232051, covariance difference 8.32741786698673, sinkhorn epsilon 2.019025208631032e-11\n",
      "Iteration  25\n",
      "Training: loss 4.624051570892334, covariance difference 1.0139288902282715\n",
      "Validation: loss 5.690968848407817, covariance difference 8.711459608964585, sinkhorn epsilon 5.933650168168993e-14\n",
      "Iteration  26\n",
      "Training: loss 4.657683372497559, covariance difference 1.0190951824188232\n",
      "Validation: loss 5.631042121381607, covariance difference 8.62659246477809, sinkhorn epsilon 4.750581518261023e-14\n",
      "Iteration  27\n",
      "Training: loss 4.595101833343506, covariance difference 1.009695053100586\n",
      "Validation: loss 5.698900112202743, covariance difference 8.726713516124125, sinkhorn epsilon 1.5341247670018038e-13\n",
      "Iteration  28\n",
      "Training: loss 4.66311502456665, covariance difference 1.0226925611495972\n",
      "Validation: loss 5.680105665549972, covariance difference 8.782802449517174, sinkhorn epsilon 3.673974936285051e-14\n",
      "Iteration  29\n",
      "Training: loss 4.644172191619873, covariance difference 1.0174083709716797\n",
      "Validation: loss 5.583600488272673, covariance difference 8.2767384752591, sinkhorn epsilon 1.6465700725994026e-13\n",
      "Iteration  30\n",
      "Training: loss 4.5489912033081055, covariance difference 1.0001444816589355\n",
      "Validation: loss 5.6059560609727885, covariance difference 8.566242655796133, sinkhorn epsilon 4.1607733339544026e-14\n",
      "Iteration  31\n",
      "Training: loss 4.5711188316345215, covariance difference 1.0067843198776245\n",
      "Validation: loss 5.698925831823842, covariance difference 8.303379056923879, sinkhorn epsilon 2.2932268410655224e-13\n",
      "Iteration  32\n",
      "Training: loss 4.664780616760254, covariance difference 1.0215792655944824\n",
      "Validation: loss 5.627399464612342, covariance difference 8.511861521207189, sinkhorn epsilon 1.0252656982018845e-13\n",
      "Iteration  33\n",
      "Training: loss 4.592921257019043, covariance difference 1.008293628692627\n",
      "Validation: loss 5.650679371377768, covariance difference 8.791133851878374, sinkhorn epsilon 9.642338659530399e-14\n",
      "Iteration  34\n",
      "Training: loss 4.614823341369629, covariance difference 1.014427661895752\n",
      "Validation: loss 5.675073638464644, covariance difference 8.673711105633577, sinkhorn epsilon 6.768362606437343e-14\n",
      "Iteration  35\n",
      "Training: loss 4.640102386474609, covariance difference 1.017138957977295\n",
      "Validation: loss 5.6598381528467065, covariance difference 8.497785800455524, sinkhorn epsilon 1.074364886216187e-14\n",
      "Iteration  36\n",
      "Training: loss 4.624166011810303, covariance difference 1.0148805379867554\n",
      "Validation: loss 5.604924343667352, covariance difference 8.693635042329118, sinkhorn epsilon 1.1890566916922453e-13\n",
      "Iteration  37\n",
      "Training: loss 4.569827079772949, covariance difference 1.0051218271255493\n",
      "Validation: loss 5.6466626194552045, covariance difference 8.444935107728382, sinkhorn epsilon 3.136127972451966e-14\n",
      "Iteration  38\n",
      "Training: loss 4.611163139343262, covariance difference 1.013391375541687\n",
      "Validation: loss 5.621994814129751, covariance difference 8.386854386533885, sinkhorn epsilon 3.2203082515027316e-14\n",
      "Iteration  39\n",
      "Training: loss 4.584591865539551, covariance difference 1.008846402168274\n",
      "Validation: loss 5.702662179247396, covariance difference 8.757192147855497, sinkhorn epsilon 9.185704507724239e-15\n",
      "Iteration  40\n",
      "Training: loss 4.666016578674316, covariance difference 1.0233888626098633\n",
      "Validation: loss 5.705796129931879, covariance difference 8.689981393555716, sinkhorn epsilon 2.5529846060637518e-14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  41\n",
      "Training: loss 4.669532775878906, covariance difference 1.0246940851211548\n",
      "Validation: loss 5.604947636871195, covariance difference 8.266364896379814, sinkhorn epsilon 3.4610760049220496e-14\n",
      "Iteration  42\n",
      "Training: loss 4.5683135986328125, covariance difference 1.0040119886398315\n",
      "Validation: loss 5.616511702321495, covariance difference 8.543063073719352, sinkhorn epsilon 1.2189317731430368e-14\n",
      "Iteration  43\n",
      "Training: loss 4.579812049865723, covariance difference 1.0052196979522705\n",
      "Validation: loss 5.656889041374058, covariance difference 8.915047515354901, sinkhorn epsilon 2.346716343773844e-13\n",
      "Iteration  44\n",
      "Training: loss 4.620477199554443, covariance difference 1.0139461755752563\n",
      "Validation: loss 5.708619079343099, covariance difference 8.713153250121515, sinkhorn epsilon 2.0353743076872016e-14\n",
      "Iteration  45\n",
      "Training: loss 4.671381950378418, covariance difference 1.0230929851531982\n",
      "Validation: loss 5.748954251049458, covariance difference 8.776916813466269, sinkhorn epsilon 2.8313333477585398e-14\n",
      "Iteration  46\n",
      "Training: loss 4.71231746673584, covariance difference 1.0319786071777344\n",
      "Validation: loss 5.633680484350426, covariance difference 8.600436351857107, sinkhorn epsilon 4.9862299522774964e-14\n",
      "Iteration  47\n",
      "Training: loss 4.597928047180176, covariance difference 1.010015606880188\n",
      "Validation: loss 5.697605695262885, covariance difference 8.762403032785587, sinkhorn epsilon 1.5095305899892863e-14\n",
      "Iteration  48\n",
      "Training: loss 4.660629749298096, covariance difference 1.0205767154693604\n",
      "Validation: loss 5.639243945276572, covariance difference 8.345682302963281, sinkhorn epsilon 2.809890253630868e-14\n",
      "Iteration  49\n",
      "Training: loss 4.602194786071777, covariance difference 1.0096256732940674\n",
      "Validation: loss 5.591426509350848, covariance difference 8.38448589235841, sinkhorn epsilon 2.163346076866146e-14\n",
      "Iteration  50\n",
      "Training: loss 4.55424165725708, covariance difference 1.0036003589630127\n",
      "Validation: loss 5.679799985635667, covariance difference 8.391454846740816, sinkhorn epsilon 1.444731137188953e-14\n",
      "Iteration  51\n",
      "Training: loss 4.643049240112305, covariance difference 1.0180927515029907\n",
      "Validation: loss 5.634891355166166, covariance difference 8.860395884334798, sinkhorn epsilon 1.421845177098635e-14\n",
      "Iteration  52\n",
      "Training: loss 4.596979141235352, covariance difference 1.0127360820770264\n",
      "Validation: loss 5.662794633197127, covariance difference 8.697925033582507, sinkhorn epsilon 1.2461282027149005e-14\n",
      "Iteration  53\n",
      "Training: loss 4.625694274902344, covariance difference 1.0170021057128906\n",
      "Validation: loss 5.718568326064272, covariance difference 8.539648543582562, sinkhorn epsilon 2.313004310862221e-12\n",
      "Iteration  54\n",
      "Training: loss 4.681343078613281, covariance difference 1.0243040323257446\n",
      "Validation: loss 5.677587286222132, covariance difference 8.61838064655961, sinkhorn epsilon 3.6998374681720716e-14\n",
      "Iteration  55\n",
      "Training: loss 4.640134811401367, covariance difference 1.016381859779358\n",
      "Validation: loss 5.6932661506983155, covariance difference 8.532313803194302, sinkhorn epsilon 3.689894444440946e-14\n",
      "Iteration  56\n",
      "Training: loss 4.655596733093262, covariance difference 1.0195566415786743\n",
      "Validation: loss 5.618312966141807, covariance difference 8.37364749733245, sinkhorn epsilon 1.2423280039383299e-14\n",
      "Iteration  57\n",
      "Training: loss 4.58067512512207, covariance difference 1.007794976234436\n",
      "Validation: loss 5.679258922393284, covariance difference 8.786930552565225, sinkhorn epsilon 2.220446049250313e-16\n",
      "Iteration  58\n",
      "Training: loss 4.641951560974121, covariance difference 1.0170084238052368\n",
      "Validation: loss 5.560701249335166, covariance difference 8.279621404198977, sinkhorn epsilon 3.703539342947119e-14\n",
      "Iteration  59\n",
      "Training: loss 4.523575782775879, covariance difference 0.9969939589500427\n",
      "Validation: loss 5.622447754473157, covariance difference 8.493120196522604, sinkhorn epsilon 2.01991171399841e-15\n",
      "Iteration  60\n",
      "Training: loss 4.58420467376709, covariance difference 1.0097448825836182\n",
      "Validation: loss 5.639302090871844, covariance difference 8.714241984113496, sinkhorn epsilon 1.8297035590516225e-14\n",
      "Iteration  61\n",
      "Training: loss 4.601089954376221, covariance difference 1.0116902589797974\n",
      "Validation: loss 5.691617993656021, covariance difference 8.610454345285277, sinkhorn epsilon 3.267824192913707e-15\n",
      "Iteration  62\n",
      "Training: loss 4.654081344604492, covariance difference 1.0218315124511719\n",
      "Validation: loss 5.7197795647038525, covariance difference 8.732494624532317, sinkhorn epsilon 1.3395931022007254e-14\n",
      "Iteration  63\n",
      "Training: loss 4.68199348449707, covariance difference 1.0251400470733643\n",
      "Validation: loss 5.647148134721717, covariance difference 8.526661973333583, sinkhorn epsilon 3.366451100186771e-14\n",
      "Iteration  64\n",
      "Training: loss 4.610199451446533, covariance difference 1.0135271549224854\n",
      "Validation: loss 5.7403282055128795, covariance difference 8.703049943956314, sinkhorn epsilon 2.2610831465669215e-14\n",
      "Iteration  65\n",
      "Training: loss 4.702627182006836, covariance difference 1.029725193977356\n",
      "Validation: loss 5.705451330540085, covariance difference 8.886177816889338, sinkhorn epsilon 7.64055645665405e-15\n",
      "Iteration  66\n",
      "Training: loss 4.667054176330566, covariance difference 1.0227642059326172\n",
      "Validation: loss 5.692490001365057, covariance difference 8.851786471089145, sinkhorn epsilon 2.3539958056742788e-14\n",
      "Iteration  67\n",
      "Training: loss 4.654548645019531, covariance difference 1.0209503173828125\n",
      "Validation: loss 5.603098155572477, covariance difference 8.454224992596219, sinkhorn epsilon 7.385387692052822e-14\n",
      "Iteration  68\n",
      "Training: loss 4.565340042114258, covariance difference 1.0047218799591064\n",
      "Validation: loss 5.629567413533857, covariance difference 8.721601002015381, sinkhorn epsilon 2.635375578840744e-14\n",
      "Iteration  69\n",
      "Training: loss 4.591440200805664, covariance difference 1.0085996389389038\n",
      "Validation: loss 5.635151059073949, covariance difference 8.553325663954018, sinkhorn epsilon 4.135820331245943e-15\n",
      "Iteration  70\n",
      "Training: loss 4.597041130065918, covariance difference 1.0105249881744385\n",
      "Validation: loss 5.605996208235732, covariance difference 8.521125389439597, sinkhorn epsilon 1.621138592302813e-14\n",
      "Iteration  71\n",
      "Training: loss 4.56752872467041, covariance difference 1.0055326223373413\n",
      "Validation: loss 5.640627901769143, covariance difference 8.372473823889232, sinkhorn epsilon 1.5952855584906867e-14\n",
      "Iteration  72\n",
      "Training: loss 4.602045059204102, covariance difference 1.0104185342788696\n",
      "Validation: loss 5.618470598247574, covariance difference 8.608043420920376, sinkhorn epsilon 1.2691435430492733e-14\n",
      "Iteration  73\n",
      "Training: loss 4.580281734466553, covariance difference 1.0093655586242676\n",
      "Validation: loss 5.718983002991371, covariance difference 8.674232484473723, sinkhorn epsilon 2.817465669864685e-14\n",
      "Iteration  74\n",
      "Training: loss 4.681155204772949, covariance difference 1.0243678092956543\n",
      "Validation: loss 5.700696426297436, covariance difference 8.758397508802021, sinkhorn epsilon 1.6114192617984713e-15\n",
      "Iteration  75\n",
      "Training: loss 4.662242889404297, covariance difference 1.0218455791473389\n",
      "Validation: loss 5.612554174152775, covariance difference 8.607318351117804, sinkhorn epsilon 9.903965106991255e-16\n",
      "Iteration  76\n",
      "Training: loss 4.5742692947387695, covariance difference 1.0061928033828735\n",
      "Validation: loss 5.639983457692574, covariance difference 8.631989697766784, sinkhorn epsilon 2.952588890110902e-14\n",
      "Iteration  77\n",
      "Training: loss 4.601386070251465, covariance difference 1.0124413967132568\n",
      "Validation: loss 5.72349633588519, covariance difference 8.688828881471592, sinkhorn epsilon 1.2213212050822722e-14\n",
      "Iteration  78\n",
      "Training: loss 4.685040473937988, covariance difference 1.0262172222137451\n",
      "Validation: loss 5.6552102145631284, covariance difference 8.640348083021816, sinkhorn epsilon 2.776948021846221e-14\n",
      "Iteration  79\n",
      "Training: loss 4.616990089416504, covariance difference 1.0125795602798462\n",
      "Validation: loss 5.62583664947533, covariance difference 8.513921842359203, sinkhorn epsilon 3.052757939722271e-14\n",
      "Iteration  80\n",
      "Training: loss 4.587192535400391, covariance difference 1.0087785720825195\n",
      "Validation: loss 5.676488265215735, covariance difference 8.71131286805389, sinkhorn epsilon 2.84762241641464e-14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  81\n",
      "Training: loss 4.637916564941406, covariance difference 1.0177866220474243\n",
      "Validation: loss 5.695385863917938, covariance difference 8.727246345844677, sinkhorn epsilon 3.417184930139891e-14\n",
      "Iteration  82\n",
      "Training: loss 4.656761646270752, covariance difference 1.0209609270095825\n",
      "Validation: loss 5.687597215367942, covariance difference 8.636706367598565, sinkhorn epsilon 2.590385200531446e-15\n",
      "Iteration  83\n",
      "Training: loss 4.6490960121154785, covariance difference 1.020076870918274\n",
      "Validation: loss 5.686344790644112, covariance difference 8.613278395725294, sinkhorn epsilon 1.334607041491032e-15\n",
      "Iteration  84\n",
      "Training: loss 4.647243976593018, covariance difference 1.0221680402755737\n",
      "Validation: loss 5.638856645331748, covariance difference 8.513427927873858, sinkhorn epsilon 3.088795318704387e-14\n",
      "Iteration  85\n",
      "Training: loss 4.600470542907715, covariance difference 1.012421727180481\n",
      "Validation: loss 5.570053248105544, covariance difference 8.530423130247806, sinkhorn epsilon 3.0693277831829165e-14\n",
      "Iteration  86\n",
      "Training: loss 4.531614303588867, covariance difference 0.999594509601593\n",
      "Validation: loss 5.58428135822739, covariance difference 8.576008889859832, sinkhorn epsilon 3.1401849173675503e-16\n",
      "Iteration  87\n",
      "Training: loss 4.545673847198486, covariance difference 1.002116322517395\n",
      "Validation: loss 5.678063429377292, covariance difference 8.495619455328125, sinkhorn epsilon 1.6313721343106056e-14\n",
      "Iteration  88\n",
      "Training: loss 4.639477729797363, covariance difference 1.0171875953674316\n",
      "Validation: loss 5.671200446389295, covariance difference 8.51790902182397, sinkhorn epsilon 2.888375042252778e-14\n",
      "Iteration  89\n",
      "Training: loss 4.633098125457764, covariance difference 1.0178934335708618\n",
      "Validation: loss 5.690647930979122, covariance difference 8.812387726433807, sinkhorn epsilon 1.83484639231925e-14\n",
      "Iteration  90\n",
      "Training: loss 4.651638984680176, covariance difference 1.0215457677841187\n",
      "Validation: loss 5.674740368511571, covariance difference 8.697062033390514, sinkhorn epsilon 8.326672684688674e-16\n",
      "Iteration  91\n",
      "Training: loss 4.636074066162109, covariance difference 1.0173605680465698\n",
      "Validation: loss 5.625203354280706, covariance difference 8.506590874766715, sinkhorn epsilon 3.58074884935574e-15\n",
      "Iteration  92\n",
      "Training: loss 4.586643218994141, covariance difference 1.0092347860336304\n",
      "Validation: loss 5.654280717175622, covariance difference 8.60871889654491, sinkhorn epsilon 0.0\n",
      "Iteration  93\n",
      "Training: loss 4.615230560302734, covariance difference 1.013210654258728\n",
      "Validation: loss 5.68909160055743, covariance difference 8.538060283389383, sinkhorn epsilon 1.8836222869450754e-15\n",
      "Iteration  94\n",
      "Training: loss 4.651350975036621, covariance difference 1.0209391117095947\n",
      "Validation: loss 5.657081193245753, covariance difference 8.54851158998614, sinkhorn epsilon 0.0\n",
      "Iteration  95\n",
      "Training: loss 4.618149757385254, covariance difference 1.016066312789917\n",
      "Validation: loss 5.67338489915006, covariance difference 8.682910045910903, sinkhorn epsilon 5.0161746901959794e-15\n",
      "Iteration  96\n",
      "Training: loss 4.634814262390137, covariance difference 1.0162310600280762\n",
      "Validation: loss 5.654696888434518, covariance difference 8.819018088133564, sinkhorn epsilon 1.5615027934444068e-14\n",
      "Iteration  97\n",
      "Training: loss 4.6159162521362305, covariance difference 1.0126919746398926\n",
      "Validation: loss 5.650996595514519, covariance difference 8.495162724439997, sinkhorn epsilon 1.9433558135244745e-14\n",
      "Iteration  98\n",
      "Training: loss 4.612094879150391, covariance difference 1.0144437551498413\n",
      "Validation: loss 5.625195426811075, covariance difference 8.724576804422712, sinkhorn epsilon 3.351141911375109e-14\n",
      "Iteration  99\n",
      "Training: loss 4.586397171020508, covariance difference 1.0090644359588623\n",
      "Validation: loss 5.6270746539099985, covariance difference 8.701154419460664, sinkhorn epsilon 2.5751157067496325e-14\n",
      "Iteration  100\n",
      "Training: loss 4.588308334350586, covariance difference 1.009201169013977\n",
      "Validation: loss 5.628807375893455, covariance difference 8.647218162375788, sinkhorn epsilon 2.6568880701551778e-14\n",
      "Iteration  101\n",
      "Training: loss 4.589776992797852, covariance difference 1.0077192783355713\n",
      "Validation: loss 5.67216727983912, covariance difference 8.797709793466458, sinkhorn epsilon 2.278824257809299e-14\n",
      "Iteration  102\n",
      "Training: loss 4.633289337158203, covariance difference 1.017778992652893\n",
      "Validation: loss 5.608437139152714, covariance difference 8.56803382298705, sinkhorn epsilon 1.0535026295729364e-14\n",
      "Iteration  103\n",
      "Training: loss 4.569558620452881, covariance difference 1.004912257194519\n",
      "Validation: loss 5.6825559146930145, covariance difference 8.65319232070677, sinkhorn epsilon 0.0\n",
      "Iteration  104\n",
      "Training: loss 4.643378734588623, covariance difference 1.020106315612793\n",
      "Validation: loss 5.648045577509169, covariance difference 8.420809577655563, sinkhorn epsilon 1.1930691158607366e-15\n",
      "Iteration  105\n",
      "Training: loss 4.609288215637207, covariance difference 1.0141187906265259\n",
      "Validation: loss 5.599037196910455, covariance difference 8.537582286506971, sinkhorn epsilon 4.527657013938959e-15\n",
      "Iteration  106\n",
      "Training: loss 4.560242652893066, covariance difference 1.0045242309570312\n",
      "Validation: loss 5.646551670843688, covariance difference 8.501905783502384, sinkhorn epsilon 1.0121200728381883e-14\n",
      "Iteration  107\n",
      "Training: loss 4.6076226234436035, covariance difference 1.013075828552246\n",
      "Validation: loss 5.688690678392213, covariance difference 8.73934218006054, sinkhorn epsilon 0.0\n",
      "Iteration  108\n",
      "Training: loss 4.649646282196045, covariance difference 1.01986825466156\n",
      "Validation: loss 5.660445641024216, covariance difference 8.556208686483394, sinkhorn epsilon 1.2796824264293103e-14\n",
      "Iteration  109\n",
      "Training: loss 4.62166690826416, covariance difference 1.0147998332977295\n",
      "Validation: loss 5.661349914183559, covariance difference 8.739458022581259, sinkhorn epsilon 5.071793245367104e-14\n",
      "Iteration  110\n",
      "Training: loss 4.622419357299805, covariance difference 1.0144908428192139\n",
      "Validation: loss 5.5806039837089365, covariance difference 8.725964933420787, sinkhorn epsilon 0.0\n",
      "Iteration  111\n",
      "Training: loss 4.541676998138428, covariance difference 1.001251459121704\n",
      "Validation: loss 5.761777368457978, covariance difference 8.782524171078794, sinkhorn epsilon 9.31695888430938e-15\n",
      "Iteration  112\n",
      "Training: loss 4.722687721252441, covariance difference 1.0351293087005615\n",
      "Validation: loss 5.687508434395921, covariance difference 8.736952544076065, sinkhorn epsilon 5.388752810421384e-14\n",
      "Iteration  113\n",
      "Training: loss 4.649268627166748, covariance difference 1.0193010568618774\n",
      "Validation: loss 5.634311279085329, covariance difference 8.502084472812863, sinkhorn epsilon 2.1581291715207287e-14\n",
      "Iteration  114\n",
      "Training: loss 4.595597743988037, covariance difference 1.0116925239562988\n",
      "Validation: loss 5.6443102728436, covariance difference 8.56623200289261, sinkhorn epsilon 0.0\n",
      "Iteration  115\n",
      "Training: loss 4.605212688446045, covariance difference 1.0134212970733643\n",
      "Validation: loss 5.586224823695642, covariance difference 8.403271947873261, sinkhorn epsilon 0.0\n",
      "Iteration  116\n",
      "Training: loss 4.547425746917725, covariance difference 1.00178861618042\n",
      "Validation: loss 5.609558914008623, covariance difference 8.626953117490974, sinkhorn epsilon 0.0\n",
      "Iteration  117\n",
      "Training: loss 4.570532321929932, covariance difference 1.0059806108474731\n",
      "Validation: loss 5.6694870770732235, covariance difference 8.618005472163958, sinkhorn epsilon 5.295426327528139e-16\n",
      "Iteration  118\n",
      "Training: loss 4.6306023597717285, covariance difference 1.0172816514968872\n",
      "Validation: loss 5.579770707375996, covariance difference 8.42557119771744, sinkhorn epsilon 0.0\n",
      "Iteration  119\n",
      "Training: loss 4.5405988693237305, covariance difference 1.0019334554672241\n",
      "Validation: loss 5.6332199537335015, covariance difference 8.615273147707496, sinkhorn epsilon 1.1106281904426198e-14\n",
      "Iteration  120\n",
      "Training: loss 4.594246864318848, covariance difference 1.010102391242981\n",
      "Validation: loss 5.638728359381166, covariance difference 8.523226246667237, sinkhorn epsilon 7.06957963306156e-15\n",
      "Iteration  121\n",
      "Training: loss 4.599616050720215, covariance difference 1.0087084770202637\n",
      "Validation: loss 5.536355906602293, covariance difference 8.59396279808464, sinkhorn epsilon 2.9650420006489598e-15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  122\n",
      "Training: loss 4.49701452255249, covariance difference 0.9938242435455322\n",
      "Validation: loss 5.681553071730638, covariance difference 8.577952459460251, sinkhorn epsilon 0.0\n",
      "Iteration  123\n",
      "Training: loss 4.642490386962891, covariance difference 1.0172357559204102\n",
      "Validation: loss 5.715524533258426, covariance difference 8.90490937148199, sinkhorn epsilon 0.0\n",
      "Iteration  124\n",
      "Training: loss 4.676111221313477, covariance difference 1.024778127670288\n",
      "Validation: loss 5.661212502941945, covariance difference 8.758997182520309, sinkhorn epsilon 4.044954707664469e-14\n",
      "Iteration  125\n",
      "Training: loss 4.621967792510986, covariance difference 1.0155813694000244\n",
      "Validation: loss 5.631757943524001, covariance difference 8.612479413222795, sinkhorn epsilon 3.3864672621763756e-14\n",
      "Iteration  126\n",
      "Training: loss 4.592863082885742, covariance difference 1.008902907371521\n",
      "Validation: loss 5.79035310409523, covariance difference 8.729532365236244, sinkhorn epsilon 2.7755575615628914e-16\n",
      "Iteration  127\n",
      "Training: loss 4.75123405456543, covariance difference 1.038712501525879\n",
      "Validation: loss 5.649624899674745, covariance difference 8.792039686208517, sinkhorn epsilon 2.3284732304426844e-14\n",
      "Iteration  128\n",
      "Training: loss 4.610517501831055, covariance difference 1.0145645141601562\n",
      "Validation: loss 5.642703460991475, covariance difference 8.45275520599851, sinkhorn epsilon 2.0203140137240656e-15\n",
      "Iteration  129\n",
      "Training: loss 4.603764057159424, covariance difference 1.0106004476547241\n",
      "Validation: loss 5.58960004896541, covariance difference 8.391834822092612, sinkhorn epsilon 5.544533852411452e-15\n",
      "Iteration  130\n",
      "Training: loss 4.550441741943359, covariance difference 1.0014439821243286\n",
      "Validation: loss 5.65051150628577, covariance difference 8.504193343263756, sinkhorn epsilon 3.057406802070321e-14\n",
      "Iteration  131\n",
      "Training: loss 4.611810207366943, covariance difference 1.0131416320800781\n",
      "Validation: loss 5.6629527769405, covariance difference 8.588130006769232, sinkhorn epsilon 0.0\n",
      "Iteration  132\n",
      "Training: loss 4.623926162719727, covariance difference 1.0147905349731445\n",
      "Validation: loss 5.646025635697917, covariance difference 8.670822830689803, sinkhorn epsilon 9.53318193924849e-16\n",
      "Iteration  133\n",
      "Training: loss 4.606731414794922, covariance difference 1.0121304988861084\n",
      "Validation: loss 5.655612306708553, covariance difference 8.666955337354683, sinkhorn epsilon 2.7755575615628914e-16\n",
      "Iteration  134\n",
      "Training: loss 4.616598129272461, covariance difference 1.0151923894882202\n",
      "Validation: loss 5.6560485933140505, covariance difference 8.522979357091957, sinkhorn epsilon 2.321572115091321e-15\n",
      "Iteration  135\n",
      "Training: loss 4.616934299468994, covariance difference 1.0123790502548218\n",
      "Validation: loss 5.652576440033992, covariance difference 8.445350207595785, sinkhorn epsilon 1.3054906040304362e-14\n",
      "Iteration  136\n",
      "Training: loss 4.6131768226623535, covariance difference 1.013481855392456\n",
      "Validation: loss 5.641814323507383, covariance difference 8.373316684138517, sinkhorn epsilon 1.3699059394326489e-14\n",
      "Iteration  137\n",
      "Training: loss 4.602498531341553, covariance difference 1.0118821859359741\n",
      "Validation: loss 5.7080762846913355, covariance difference 8.596214487809137, sinkhorn epsilon 1.7300341748403246e-15\n",
      "Iteration  138\n",
      "Training: loss 4.669000148773193, covariance difference 1.022493600845337\n",
      "Validation: loss 5.716716736751989, covariance difference 9.06657242332121, sinkhorn epsilon 0.0\n",
      "Iteration  139\n",
      "Training: loss 4.677433013916016, covariance difference 1.0282243490219116\n",
      "Validation: loss 5.617834510081403, covariance difference 8.487778937358007, sinkhorn epsilon 8.326672684688674e-16\n",
      "Iteration  140\n",
      "Training: loss 4.5785369873046875, covariance difference 1.008240818977356\n",
      "Validation: loss 5.682235304222624, covariance difference 8.63551942785128, sinkhorn epsilon 1.6998573116724298e-14\n",
      "Iteration  141\n",
      "Training: loss 4.642755508422852, covariance difference 1.019544005393982\n",
      "Validation: loss 5.648320729626686, covariance difference 8.51803472042838, sinkhorn epsilon 1.8398070124618354e-14\n",
      "Iteration  142\n",
      "Training: loss 4.608993053436279, covariance difference 1.0127300024032593\n",
      "Validation: loss 5.700484693805429, covariance difference 8.781876787428391, sinkhorn epsilon 0.0\n",
      "Iteration  143\n",
      "Training: loss 4.661423683166504, covariance difference 1.0203757286071777\n",
      "Validation: loss 5.660904947237743, covariance difference 8.70989054910902, sinkhorn epsilon 0.0\n",
      "Iteration  144\n",
      "Training: loss 4.621791362762451, covariance difference 1.0154849290847778\n",
      "Validation: loss 5.704996059137951, covariance difference 8.660321665626565, sinkhorn epsilon 1.424474186076616e-14\n",
      "Iteration  145\n",
      "Training: loss 4.66562557220459, covariance difference 1.0227248668670654\n",
      "Validation: loss 5.636596547559897, covariance difference 8.674800856307261, sinkhorn epsilon 2.291873277448022e-14\n",
      "Iteration  146\n",
      "Training: loss 4.597328186035156, covariance difference 1.011930227279663\n",
      "Validation: loss 5.6560303626050645, covariance difference 8.589426282551033, sinkhorn epsilon 0.0\n",
      "Iteration  147\n",
      "Training: loss 4.616628170013428, covariance difference 1.0146945714950562\n",
      "Validation: loss 5.631807147444938, covariance difference 8.525306701685949, sinkhorn epsilon 2.149036641777511e-15\n",
      "Iteration  148\n",
      "Training: loss 4.592385292053223, covariance difference 1.009812593460083\n",
      "Validation: loss 5.606608773026559, covariance difference 8.493068739971475, sinkhorn epsilon 2.9159804976851984e-14\n",
      "Iteration  149\n",
      "Training: loss 4.567203521728516, covariance difference 1.0064691305160522\n",
      "Validation: loss 5.644104187635131, covariance difference 8.814027744902559, sinkhorn epsilon 8.754291521844708e-16\n",
      "Iteration  150\n",
      "Training: loss 4.604863166809082, covariance difference 1.0131239891052246\n",
      "Validation: loss 5.746882097164026, covariance difference 8.800684377817385, sinkhorn epsilon 1.432616788222663e-15\n",
      "Iteration  151\n",
      "Training: loss 4.7075910568237305, covariance difference 1.0316526889801025\n",
      "Validation: loss 5.694459307609572, covariance difference 8.689489114421178, sinkhorn epsilon 1.8705269752018882e-14\n",
      "Iteration  152\n",
      "Training: loss 4.655158042907715, covariance difference 1.021406650543213\n",
      "Validation: loss 5.6600891338734565, covariance difference 8.710611333959465, sinkhorn epsilon 2.1714755032114943e-14\n",
      "Iteration  153\n",
      "Training: loss 4.620853424072266, covariance difference 1.0174901485443115\n",
      "Validation: loss 5.56893595511997, covariance difference 8.391613100771648, sinkhorn epsilon 2.079626055504766e-14\n",
      "Iteration  154\n",
      "Training: loss 4.5293378829956055, covariance difference 0.999443769454956\n",
      "Validation: loss 5.624075027161809, covariance difference 8.491838592899374, sinkhorn epsilon 0.0\n",
      "Iteration  155\n",
      "Training: loss 4.5846123695373535, covariance difference 1.0089820623397827\n",
      "Validation: loss 5.657806164464615, covariance difference 8.562923336460797, sinkhorn epsilon 0.0\n",
      "Iteration  156\n",
      "Training: loss 4.618221282958984, covariance difference 1.0145443677902222\n",
      "Validation: loss 5.601716999770964, covariance difference 8.68109648538514, sinkhorn epsilon 2.296682400398943e-14\n",
      "Iteration  157\n",
      "Training: loss 4.5623979568481445, covariance difference 1.0029678344726562\n",
      "Validation: loss 5.585487573298394, covariance difference 8.431696965202805, sinkhorn epsilon 2.100399715349702e-14\n",
      "Iteration  158\n",
      "Training: loss 4.545985221862793, covariance difference 1.0020320415496826\n",
      "Validation: loss 5.690282114026556, covariance difference 8.472023398154622, sinkhorn epsilon 1.727978330871408e-14\n",
      "Iteration  159\n",
      "Training: loss 4.651029586791992, covariance difference 1.0205333232879639\n",
      "Validation: loss 5.669148970305021, covariance difference 8.61800070913597, sinkhorn epsilon 8.06633338240306e-15\n",
      "Iteration  160\n",
      "Training: loss 4.629645347595215, covariance difference 1.0165071487426758\n",
      "Validation: loss 5.693828040902719, covariance difference 8.707310010317146, sinkhorn epsilon 0.0\n",
      "Iteration  161\n",
      "Training: loss 4.654583930969238, covariance difference 1.0221564769744873\n",
      "Validation: loss 5.688589272032847, covariance difference 8.612898649598696, sinkhorn epsilon 1.345935099552349e-15\n",
      "Iteration  162\n",
      "Training: loss 4.649196624755859, covariance difference 1.020541787147522\n",
      "Validation: loss 5.6546621256714955, covariance difference 8.57667795960293, sinkhorn epsilon 3.622756232962878e-14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  163\n",
      "Training: loss 4.615317344665527, covariance difference 1.0150104761123657\n",
      "Validation: loss 5.660746729425448, covariance difference 8.77425165742974, sinkhorn epsilon 3.571861599547592e-14\n",
      "Iteration  164\n",
      "Training: loss 4.621325492858887, covariance difference 1.0168911218643188\n",
      "Validation: loss 5.729930953070834, covariance difference 8.980283172904025, sinkhorn epsilon 0.0\n",
      "Iteration  165\n",
      "Training: loss 4.690426826477051, covariance difference 1.0270447731018066\n",
      "Validation: loss 5.682201181822675, covariance difference 8.577154178310003, sinkhorn epsilon 1.4790793018918976e-15\n",
      "Iteration  166\n",
      "Training: loss 4.642974376678467, covariance difference 1.0194635391235352\n",
      "Validation: loss 5.632280210565149, covariance difference 8.694287109425526, sinkhorn epsilon 0.0\n",
      "Iteration  167\n",
      "Training: loss 4.592820167541504, covariance difference 1.0085008144378662\n",
      "Validation: loss 5.648914007794456, covariance difference 8.663784009390676, sinkhorn epsilon 3.808532904460161e-15\n",
      "Iteration  168\n",
      "Training: loss 4.609456539154053, covariance difference 1.013467788696289\n",
      "Validation: loss 5.693984791719734, covariance difference 8.753547741580876, sinkhorn epsilon 0.0\n",
      "Iteration  169\n",
      "Training: loss 4.654488563537598, covariance difference 1.0225582122802734\n",
      "Validation: loss 5.682731938739087, covariance difference 8.715812683433954, sinkhorn epsilon 6.692003244261379e-14\n",
      "Iteration  170\n",
      "Training: loss 4.643242835998535, covariance difference 1.0219802856445312\n",
      "Validation: loss 5.643290812405232, covariance difference 8.575163445317616, sinkhorn epsilon 3.704536064084928e-14\n",
      "Iteration  171\n",
      "Training: loss 4.60384464263916, covariance difference 1.0148953199386597\n",
      "Validation: loss 5.6592132118036815, covariance difference 8.68809253774084, sinkhorn epsilon 3.554447978966673e-16\n",
      "Iteration  172\n",
      "Training: loss 4.619736671447754, covariance difference 1.0157594680786133\n",
      "Validation: loss 5.659381714313586, covariance difference 8.677149729938067, sinkhorn epsilon 0.0\n",
      "Iteration  173\n",
      "Training: loss 4.619903564453125, covariance difference 1.0143463611602783\n",
      "Validation: loss 5.622711833451435, covariance difference 8.697645444958903, sinkhorn epsilon 1.3989347204742876e-15\n",
      "Iteration  174\n",
      "Training: loss 4.583492279052734, covariance difference 1.0080524682998657\n",
      "Validation: loss 5.529727786769234, covariance difference 8.48584572727746, sinkhorn epsilon 0.0\n",
      "Iteration  175\n",
      "Training: loss 4.490273475646973, covariance difference 0.9919020533561707\n",
      "Validation: loss 5.615835828146386, covariance difference 8.56444443381908, sinkhorn epsilon 2.7755575615628914e-16\n",
      "Iteration  176\n",
      "Training: loss 4.57646369934082, covariance difference 1.0072355270385742\n",
      "Validation: loss 5.735524199258425, covariance difference 8.835110855867995, sinkhorn epsilon 3.1087433618082454e-15\n",
      "Iteration  177\n",
      "Training: loss 4.696264743804932, covariance difference 1.0275293588638306\n",
      "Validation: loss 5.70031687264831, covariance difference 8.50002223809981, sinkhorn epsilon 1.586898827497181e-14\n",
      "Iteration  178\n",
      "Training: loss 4.660896301269531, covariance difference 1.0242410898208618\n",
      "Validation: loss 5.576121093227552, covariance difference 8.687163510117543, sinkhorn epsilon 0.0\n",
      "Iteration  179\n",
      "Training: loss 4.536714553833008, covariance difference 0.9989052414894104\n",
      "Validation: loss 5.615008722093376, covariance difference 8.568351526890456, sinkhorn epsilon 2.4832540739490945e-14\n",
      "Iteration  180\n",
      "Training: loss 4.575491905212402, covariance difference 1.0071707963943481\n",
      "Validation: loss 5.559220698760779, covariance difference 8.546599056684702, sinkhorn epsilon 0.0\n",
      "Iteration  181\n",
      "Training: loss 4.519598960876465, covariance difference 0.9972402453422546\n",
      "Validation: loss 5.604902314638947, covariance difference 8.757630369142603, sinkhorn epsilon 5.3856701555111114e-15\n",
      "Iteration  182\n",
      "Training: loss 4.565425872802734, covariance difference 1.0045703649520874\n",
      "Validation: loss 5.621291230438012, covariance difference 8.487852965203041, sinkhorn epsilon 9.547142167908616e-15\n",
      "Iteration  183\n",
      "Training: loss 4.581999778747559, covariance difference 1.0094163417816162\n",
      "Validation: loss 5.6625257430079845, covariance difference 8.706536775553579, sinkhorn epsilon 8.2387168342569e-16\n",
      "Iteration  184\n",
      "Training: loss 4.62305212020874, covariance difference 1.0166593790054321\n",
      "Validation: loss 5.661738289787671, covariance difference 8.570787128328298, sinkhorn epsilon 0.0\n",
      "Iteration  185\n",
      "Training: loss 4.622230052947998, covariance difference 1.0153124332427979\n",
      "Validation: loss 5.675949909536508, covariance difference 8.793183116964636, sinkhorn epsilon 0.0\n",
      "Iteration  186\n",
      "Training: loss 4.636406421661377, covariance difference 1.0175541639328003\n",
      "Validation: loss 5.691689329061237, covariance difference 8.550684567271833, sinkhorn epsilon 1.6364926030255014e-14\n",
      "Iteration  187\n",
      "Training: loss 4.652192115783691, covariance difference 1.021115779876709\n",
      "Validation: loss 5.607110386667861, covariance difference 8.460987660497244, sinkhorn epsilon 0.0\n",
      "Iteration  188\n",
      "Training: loss 4.567602157592773, covariance difference 1.0058693885803223\n",
      "Validation: loss 5.642406309703682, covariance difference 8.693691879641605, sinkhorn epsilon 5.551115123125783e-16\n",
      "Iteration  189\n",
      "Training: loss 4.602874755859375, covariance difference 1.0118887424468994\n",
      "Validation: loss 5.657134408469263, covariance difference 8.404514151309762, sinkhorn epsilon 0.0\n",
      "Iteration  190\n",
      "Training: loss 4.6176438331604, covariance difference 1.0151375532150269\n",
      "Validation: loss 5.6527503516828945, covariance difference 8.569771780142467, sinkhorn epsilon 6.060091524525014e-14\n",
      "Iteration  191\n",
      "Training: loss 4.613217353820801, covariance difference 1.0139399766921997\n",
      "Validation: loss 5.6102785481997755, covariance difference 8.508019436291722, sinkhorn epsilon 0.0\n",
      "Iteration  192\n",
      "Training: loss 4.570760726928711, covariance difference 1.0074069499969482\n",
      "Validation: loss 5.642481656624895, covariance difference 8.59404487600974, sinkhorn epsilon 1.1231464298762558e-14\n",
      "Iteration  193\n",
      "Training: loss 4.6029744148254395, covariance difference 1.0127278566360474\n",
      "Validation: loss 5.689726071366977, covariance difference 8.511570595442663, sinkhorn epsilon 0.0\n",
      "Iteration  194\n",
      "Training: loss 4.650129795074463, covariance difference 1.0203496217727661\n",
      "Validation: loss 5.571824389147371, covariance difference 8.367500751969276, sinkhorn epsilon 0.0\n",
      "Iteration  195\n",
      "Training: loss 4.532314777374268, covariance difference 0.9994431138038635\n",
      "Validation: loss 5.6052872897276185, covariance difference 8.418885596833755, sinkhorn epsilon 0.0\n",
      "Iteration  196\n",
      "Training: loss 4.565873622894287, covariance difference 1.0065040588378906\n",
      "Validation: loss 5.706487738242766, covariance difference 8.531444583790408, sinkhorn epsilon 0.0\n",
      "Iteration  197\n",
      "Training: loss 4.666897773742676, covariance difference 1.0242948532104492\n",
      "Validation: loss 5.672264882999214, covariance difference 8.778186825344136, sinkhorn epsilon 6.199195496265758e-14\n",
      "Iteration  198\n",
      "Training: loss 4.632715225219727, covariance difference 1.0178608894348145\n",
      "Validation: loss 5.632007200785353, covariance difference 8.656689975401623, sinkhorn epsilon 0.0\n",
      "Iteration  199\n",
      "Training: loss 4.592495918273926, covariance difference 1.0099643468856812\n",
      "Validation: loss 5.581700911848469, covariance difference 8.499994927813686, sinkhorn epsilon 2.7696923575672305e-15\n",
      "Iteration  200\n",
      "Training: loss 4.5423359870910645, covariance difference 1.0007036924362183\n",
      "Validation: loss 5.6220145056396245, covariance difference 8.571733097579077, sinkhorn epsilon 0.0\n",
      "Iteration  201\n",
      "Training: loss 4.582448482513428, covariance difference 1.0090478658676147\n",
      "Validation: loss 5.70135090600774, covariance difference 8.765168600345145, sinkhorn epsilon 0.0\n",
      "Iteration  202\n",
      "Training: loss 4.662003517150879, covariance difference 1.0239245891571045\n",
      "Validation: loss 5.698037106078333, covariance difference 8.441058479817976, sinkhorn epsilon 3.823910170129089e-14\n",
      "Iteration  203\n",
      "Training: loss 4.658432960510254, covariance difference 1.0226430892944336\n",
      "Validation: loss 5.704582997589094, covariance difference 8.690853261372713, sinkhorn epsilon 0.0\n",
      "Iteration  204\n",
      "Training: loss 4.665116310119629, covariance difference 1.0239797830581665\n",
      "Validation: loss 5.677895300901798, covariance difference 8.54717554590129, sinkhorn epsilon 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  205\n",
      "Training: loss 4.638387203216553, covariance difference 1.0186784267425537\n",
      "Validation: loss 5.631267731330201, covariance difference 8.565605957946905, sinkhorn epsilon 0.0\n",
      "Iteration  206\n",
      "Training: loss 4.59186315536499, covariance difference 1.0104889869689941\n",
      "Validation: loss 5.671927685031521, covariance difference 8.723095612964235, sinkhorn epsilon 0.0\n",
      "Iteration  207\n",
      "Training: loss 4.632365703582764, covariance difference 1.0160123109817505\n",
      "Validation: loss 5.594455173023865, covariance difference 8.523721884270346, sinkhorn epsilon 1.6883935406531138e-14\n",
      "Iteration  208\n",
      "Training: loss 4.554947376251221, covariance difference 1.003982424736023\n",
      "Validation: loss 5.717117167364895, covariance difference 8.588390175761752, sinkhorn epsilon 1.509597619914649e-14\n",
      "Iteration  209\n",
      "Training: loss 4.677537441253662, covariance difference 1.0265024900436401\n",
      "Validation: loss 5.671721115350661, covariance difference 8.57556652490919, sinkhorn epsilon 0.0\n",
      "Iteration  210\n",
      "Training: loss 4.632201671600342, covariance difference 1.0171791315078735\n",
      "Validation: loss 5.6732862459541336, covariance difference 8.50954669651129, sinkhorn epsilon 1.867153216847534e-15\n",
      "Iteration  211\n",
      "Training: loss 4.633762836456299, covariance difference 1.0184526443481445\n",
      "Validation: loss 5.60315654715037, covariance difference 8.32511360406758, sinkhorn epsilon 0.0\n",
      "Iteration  212\n",
      "Training: loss 4.563587188720703, covariance difference 1.0062192678451538\n",
      "Validation: loss 5.7039019829863875, covariance difference 8.631663842512456, sinkhorn epsilon 0.0\n",
      "Iteration  213\n",
      "Training: loss 4.6643829345703125, covariance difference 1.0238996744155884\n",
      "Validation: loss 5.663145931209211, covariance difference 8.441924127325283, sinkhorn epsilon 0.0\n",
      "Iteration  214\n",
      "Training: loss 4.623561859130859, covariance difference 1.0166469812393188\n",
      "Validation: loss 5.554473673363674, covariance difference 8.441518945788646, sinkhorn epsilon 0.0\n",
      "Iteration  215\n",
      "Training: loss 4.514833450317383, covariance difference 0.9961734414100647\n",
      "Validation: loss 5.58186592473612, covariance difference 8.538134172025755, sinkhorn epsilon 0.0\n",
      "Iteration  216\n",
      "Training: loss 4.542400360107422, covariance difference 1.0013244152069092\n",
      "Validation: loss 5.7190729922296075, covariance difference 8.768123275149101, sinkhorn epsilon 0.0\n",
      "Iteration  217\n",
      "Training: loss 4.679421424865723, covariance difference 1.0259699821472168\n",
      "Validation: loss 5.707596951808566, covariance difference 8.741679641478692, sinkhorn epsilon 0.0\n",
      "Iteration  218\n",
      "Training: loss 4.668012619018555, covariance difference 1.0232446193695068\n",
      "Validation: loss 5.663954366850118, covariance difference 8.627335658708937, sinkhorn epsilon 0.0\n",
      "Iteration  219\n",
      "Training: loss 4.6244683265686035, covariance difference 1.0165659189224243\n",
      "Validation: loss 5.732034460639715, covariance difference 8.492829433386309, sinkhorn epsilon 1.647083508049705e-14\n",
      "Iteration  220\n",
      "Training: loss 4.6924638748168945, covariance difference 1.0299465656280518\n",
      "Validation: loss 5.729214817629471, covariance difference 8.988019371443555, sinkhorn epsilon 0.0\n",
      "Iteration  221\n",
      "Training: loss 4.689626693725586, covariance difference 1.028703212738037\n",
      "Validation: loss 5.671232317104526, covariance difference 8.48449716136213, sinkhorn epsilon 0.0\n",
      "Iteration  222\n",
      "Training: loss 4.631656169891357, covariance difference 1.0154939889907837\n",
      "Validation: loss 5.665852162771327, covariance difference 8.306349487257366, sinkhorn epsilon 0.0\n",
      "Iteration  223\n",
      "Training: loss 4.6262640953063965, covariance difference 1.014735460281372\n",
      "Validation: loss 5.653040183794047, covariance difference 8.613436759547408, sinkhorn epsilon 0.0\n",
      "Iteration  224\n",
      "Training: loss 4.61342716217041, covariance difference 1.013278841972351\n",
      "Validation: loss 5.648898270290088, covariance difference 8.762944664111883, sinkhorn epsilon 2.191785542409678e-14\n",
      "Iteration  225\n",
      "Training: loss 4.609401226043701, covariance difference 1.0131362676620483\n",
      "Validation: loss 5.68828561187557, covariance difference 8.769220346867854, sinkhorn epsilon 0.0\n",
      "Iteration  226\n",
      "Training: loss 4.648683547973633, covariance difference 1.0202138423919678\n",
      "Validation: loss 5.66133740296035, covariance difference 8.684947893946001, sinkhorn epsilon 0.0\n",
      "Iteration  227\n",
      "Training: loss 4.621750831604004, covariance difference 1.0156561136245728\n",
      "Validation: loss 5.675063009968728, covariance difference 8.679149940828518, sinkhorn epsilon 0.0\n",
      "Iteration  228\n",
      "Training: loss 4.635579586029053, covariance difference 1.0176862478256226\n",
      "Validation: loss 5.573648514864026, covariance difference 8.436126179052858, sinkhorn epsilon 8.070205827919004e-15\n",
      "Iteration  229\n",
      "Training: loss 4.534080505371094, covariance difference 0.9993807673454285\n",
      "Validation: loss 5.652805986478856, covariance difference 8.593950405108247, sinkhorn epsilon 1.894564713382084e-14\n",
      "Iteration  230\n",
      "Training: loss 4.613219261169434, covariance difference 1.014615774154663\n",
      "Validation: loss 5.608503575845525, covariance difference 8.704939313594972, sinkhorn epsilon 0.0\n",
      "Iteration  231\n",
      "Training: loss 4.5689005851745605, covariance difference 1.0065100193023682\n",
      "Validation: loss 5.605634255959973, covariance difference 8.59599999685721, sinkhorn epsilon 0.0\n",
      "Iteration  232\n",
      "Training: loss 4.56601095199585, covariance difference 1.0063283443450928\n",
      "Validation: loss 5.664065552596456, covariance difference 8.718789968551786, sinkhorn epsilon 0.0\n",
      "Iteration  233\n",
      "Training: loss 4.624521255493164, covariance difference 1.015385627746582\n",
      "Validation: loss 5.687481822691382, covariance difference 8.549920013662819, sinkhorn epsilon 5.108231597965783e-15\n",
      "Iteration  234\n",
      "Training: loss 4.648025035858154, covariance difference 1.0192731618881226\n",
      "Validation: loss 5.637902907299303, covariance difference 8.558426874456526, sinkhorn epsilon 0.0\n",
      "Iteration  235\n",
      "Training: loss 4.598322868347168, covariance difference 1.0110690593719482\n",
      "Validation: loss 5.677841524726448, covariance difference 8.737203289559252, sinkhorn epsilon 0.0\n",
      "Iteration  236\n",
      "Training: loss 4.638222694396973, covariance difference 1.0181843042373657\n",
      "Validation: loss 5.656394695725609, covariance difference 8.758697859172091, sinkhorn epsilon 0.0\n",
      "Iteration  237\n",
      "Training: loss 4.616839408874512, covariance difference 1.015496015548706\n",
      "Validation: loss 5.619085799182071, covariance difference 8.48271017752212, sinkhorn epsilon 2.787788172383552e-14\n",
      "Iteration  238\n",
      "Training: loss 4.579520225524902, covariance difference 1.0088506937026978\n",
      "Validation: loss 5.632176730219235, covariance difference 8.576040787782668, sinkhorn epsilon 0.0\n",
      "Iteration  239\n",
      "Training: loss 4.592565536499023, covariance difference 1.0096057653427124\n",
      "Validation: loss 5.73670659689247, covariance difference 8.688876850458795, sinkhorn epsilon 0.0\n",
      "Iteration  240\n",
      "Training: loss 4.697091102600098, covariance difference 1.0290330648422241\n",
      "Validation: loss 5.6950631435037415, covariance difference 8.719305038561128, sinkhorn epsilon 7.126662328653812e-15\n",
      "Iteration  241\n",
      "Training: loss 4.655494689941406, covariance difference 1.0204304456710815\n",
      "Validation: loss 5.669137607215147, covariance difference 8.537247395467851, sinkhorn epsilon 0.0\n",
      "Iteration  242\n",
      "Training: loss 4.629509925842285, covariance difference 1.0164368152618408\n",
      "Validation: loss 5.720541486968744, covariance difference 8.533058837399633, sinkhorn epsilon 1.7485575838981465e-14\n",
      "Iteration  243\n",
      "Training: loss 4.680924415588379, covariance difference 1.0268778800964355\n",
      "Validation: loss 5.65813091170485, covariance difference 8.472028400576589, sinkhorn epsilon 0.0\n",
      "Iteration  244\n",
      "Training: loss 4.618494033813477, covariance difference 1.014508605003357\n",
      "Validation: loss 5.725440744285642, covariance difference 8.859543271624503, sinkhorn epsilon 3.7868809928176436e-14\n",
      "Iteration  245\n",
      "Training: loss 4.685798645019531, covariance difference 1.0281932353973389\n",
      "Validation: loss 5.638927558626481, covariance difference 8.452778068727747, sinkhorn epsilon 2.5129729758391106e-14\n",
      "Iteration  246\n",
      "Training: loss 4.599315643310547, covariance difference 1.012736201286316\n",
      "Validation: loss 5.743239592773313, covariance difference 8.877707078046448, sinkhorn epsilon 2.5609792377633276e-14\n",
      "Iteration  247\n",
      "Training: loss 4.703680992126465, covariance difference 1.0301570892333984\n",
      "Validation: loss 5.671485951299582, covariance difference 8.797525996669533, sinkhorn epsilon 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  248\n",
      "Training: loss 4.6318769454956055, covariance difference 1.0186843872070312\n",
      "Validation: loss 5.654061651197998, covariance difference 8.783468862733022, sinkhorn epsilon 0.0\n",
      "Iteration  249\n",
      "Training: loss 4.614522933959961, covariance difference 1.0138154029846191\n",
      "Validation: loss 5.6815384812616205, covariance difference 8.82592615553488, sinkhorn epsilon 0.0\n",
      "Iteration  250\n",
      "Training: loss 4.641951560974121, covariance difference 1.0189980268478394\n",
      "Validation: loss 5.69497785202163, covariance difference 8.660216480978043, sinkhorn epsilon 2.7755575615628914e-16\n",
      "Iteration  251\n",
      "Training: loss 4.655397415161133, covariance difference 1.021240472793579\n",
      "Validation: loss 5.597419341068727, covariance difference 8.335463259036404, sinkhorn epsilon 0.0\n",
      "Iteration  252\n",
      "Training: loss 4.557807445526123, covariance difference 1.0023467540740967\n",
      "Validation: loss 5.640736576528682, covariance difference 8.650619968226842, sinkhorn epsilon 0.0\n",
      "Iteration  253\n",
      "Training: loss 4.601183891296387, covariance difference 1.0128451585769653\n",
      "Validation: loss 5.6942593467864455, covariance difference 8.547691229173378, sinkhorn epsilon 0.0\n",
      "Iteration  254\n",
      "Training: loss 4.654659271240234, covariance difference 1.0214763879776\n",
      "Validation: loss 5.605233932829677, covariance difference 8.666545440649319, sinkhorn epsilon 0.0\n",
      "Iteration  255\n",
      "Training: loss 4.565624713897705, covariance difference 1.00715172290802\n",
      "Validation: loss 5.619020864260439, covariance difference 8.581335315487655, sinkhorn epsilon 1.669834280494982e-14\n",
      "Iteration  256\n",
      "Training: loss 4.579476356506348, covariance difference 1.0088653564453125\n",
      "Validation: loss 5.695595825239531, covariance difference 8.485962786315858, sinkhorn epsilon 7.537910715616708e-14\n",
      "Iteration  257\n",
      "Training: loss 4.655996799468994, covariance difference 1.0227571725845337\n",
      "Validation: loss 5.7056056869116984, covariance difference 8.757138730160785, sinkhorn epsilon 2.2611327915303733e-14\n",
      "Iteration  258\n",
      "Training: loss 4.665937423706055, covariance difference 1.0241395235061646\n",
      "Validation: loss 5.736789485768667, covariance difference 8.813611784677333, sinkhorn epsilon 7.54947168134736e-15\n",
      "Iteration  259\n",
      "Training: loss 4.697277069091797, covariance difference 1.0299267768859863\n",
      "Validation: loss 5.663544501656521, covariance difference 8.647525303294742, sinkhorn epsilon 0.0\n",
      "Iteration  260\n",
      "Training: loss 4.623937606811523, covariance difference 1.0165106058120728\n",
      "Validation: loss 5.611601979090927, covariance difference 8.406007047935386, sinkhorn epsilon 1.4814925208390282e-14\n",
      "Iteration  261\n",
      "Training: loss 4.572015762329102, covariance difference 1.0068638324737549\n",
      "Validation: loss 5.675987262975633, covariance difference 8.755390682219774, sinkhorn epsilon 2.3150682441067343e-14\n",
      "Iteration  262\n",
      "Training: loss 4.636322498321533, covariance difference 1.019188642501831\n",
      "Validation: loss 5.755237268497337, covariance difference 8.950508308964798, sinkhorn epsilon 1.475872733429673e-14\n",
      "Iteration  263\n",
      "Training: loss 4.71562385559082, covariance difference 1.0324320793151855\n",
      "Validation: loss 5.679506650847789, covariance difference 8.708476675022755, sinkhorn epsilon 0.0\n",
      "Iteration  264\n",
      "Training: loss 4.639873504638672, covariance difference 1.0204756259918213\n",
      "Validation: loss 5.589022539150789, covariance difference 8.39848430948551, sinkhorn epsilon 2.2869121808284515e-14\n",
      "Iteration  265\n",
      "Training: loss 4.549375534057617, covariance difference 1.0033613443374634\n",
      "Validation: loss 5.584619789829617, covariance difference 8.281953037204364, sinkhorn epsilon 4.67932594735434e-14\n",
      "Iteration  266\n",
      "Training: loss 4.5449676513671875, covariance difference 1.0009739398956299\n",
      "Validation: loss 5.68531696714018, covariance difference 8.468789668245835, sinkhorn epsilon 3.8450277166254926e-14\n",
      "Iteration  267\n",
      "Training: loss 4.6457719802856445, covariance difference 1.0194987058639526\n",
      "Validation: loss 5.641080066891421, covariance difference 8.633182134879801, sinkhorn epsilon 0.0\n",
      "Iteration  268\n",
      "Training: loss 4.601498603820801, covariance difference 1.010487675666809\n",
      "Validation: loss 5.58008876228285, covariance difference 8.693069067779813, sinkhorn epsilon 0.0\n",
      "Iteration  269\n",
      "Training: loss 4.540456771850586, covariance difference 1.0007755756378174\n",
      "Validation: loss 5.592720753583231, covariance difference 8.590529944355566, sinkhorn epsilon 0.0\n",
      "Iteration  270\n",
      "Training: loss 4.553074836730957, covariance difference 1.0055667161941528\n",
      "Validation: loss 5.687801394230493, covariance difference 8.632202777940527, sinkhorn epsilon 0.0\n",
      "Iteration  271\n",
      "Training: loss 4.648211479187012, covariance difference 1.0194085836410522\n",
      "Validation: loss 5.667933174779093, covariance difference 8.585928683742644, sinkhorn epsilon 7.216449660063518e-16\n",
      "Iteration  272\n",
      "Training: loss 4.628300666809082, covariance difference 1.01461923122406\n",
      "Validation: loss 5.68858461093534, covariance difference 8.758732846047439, sinkhorn epsilon 0.0\n",
      "Iteration  273\n",
      "Training: loss 4.648956775665283, covariance difference 1.0199583768844604\n",
      "Validation: loss 5.643629524490489, covariance difference 8.430073070971995, sinkhorn epsilon 0.0\n",
      "Iteration  274\n",
      "Training: loss 4.604022026062012, covariance difference 1.0120608806610107\n",
      "Validation: loss 5.624874440105808, covariance difference 8.430979475726325, sinkhorn epsilon 3.722560073523199e-14\n",
      "Iteration  275\n",
      "Training: loss 4.585277080535889, covariance difference 1.0084724426269531\n",
      "Validation: loss 5.683852693926766, covariance difference 8.612091083347611, sinkhorn epsilon 0.0\n",
      "Iteration  276\n",
      "Training: loss 4.644272804260254, covariance difference 1.0206308364868164\n",
      "Validation: loss 5.609604364686323, covariance difference 8.538258717930272, sinkhorn epsilon 0.0\n",
      "Iteration  277\n",
      "Training: loss 4.570009231567383, covariance difference 1.0069732666015625\n",
      "Validation: loss 5.643018478670121, covariance difference 8.791688139382412, sinkhorn epsilon 2.0594854050155433e-14\n",
      "Iteration  278\n",
      "Training: loss 4.603429794311523, covariance difference 1.0124106407165527\n",
      "Validation: loss 5.52663237640105, covariance difference 8.44277235185482, sinkhorn epsilon 2.4174004164104343e-14\n",
      "Iteration  279\n",
      "Training: loss 4.487062454223633, covariance difference 0.9898720383644104\n",
      "Validation: loss 5.709897424118062, covariance difference 8.552291077638397, sinkhorn epsilon 2.3243768389991874e-14\n",
      "Iteration  280\n",
      "Training: loss 4.670266628265381, covariance difference 1.0261895656585693\n",
      "Validation: loss 5.616946392804962, covariance difference 8.574033206132087, sinkhorn epsilon 0.0\n",
      "Iteration  281\n",
      "Training: loss 4.577384948730469, covariance difference 1.0074920654296875\n",
      "Validation: loss 5.664184731674821, covariance difference 8.52148953610102, sinkhorn epsilon 0.0\n",
      "Iteration  282\n",
      "Training: loss 4.624561309814453, covariance difference 1.0168546438217163\n",
      "Validation: loss 5.657420495996133, covariance difference 8.39559922263003, sinkhorn epsilon 0.0\n",
      "Iteration  283\n",
      "Training: loss 4.617785930633545, covariance difference 1.016026496887207\n",
      "Validation: loss 5.599564684514566, covariance difference 8.421154742087502, sinkhorn epsilon 0.0\n",
      "Iteration  284\n",
      "Training: loss 4.559909820556641, covariance difference 1.006535291671753\n",
      "Validation: loss 5.622740537984571, covariance difference 8.40955690910731, sinkhorn epsilon 3.8766564910232925e-14\n",
      "Iteration  285\n",
      "Training: loss 4.58308219909668, covariance difference 1.0079245567321777\n",
      "Validation: loss 5.690040758632113, covariance difference 8.482372480582114, sinkhorn epsilon 1.2484377283653704e-14\n",
      "Iteration  286\n",
      "Training: loss 4.650437831878662, covariance difference 1.0211882591247559\n",
      "Validation: loss 5.562905789545442, covariance difference 8.484286380414568, sinkhorn epsilon 0.0\n",
      "Iteration  287\n",
      "Training: loss 4.523331642150879, covariance difference 0.9965329766273499\n",
      "Validation: loss 5.597508973105194, covariance difference 8.542014519990492, sinkhorn epsilon 0.0\n",
      "Iteration  288\n",
      "Training: loss 4.557913303375244, covariance difference 1.0046424865722656\n",
      "Validation: loss 5.621099952955044, covariance difference 8.620901374883585, sinkhorn epsilon 0.0\n",
      "Iteration  289\n",
      "Training: loss 4.5814528465271, covariance difference 1.0090810060501099\n",
      "Validation: loss 5.597542155220502, covariance difference 8.516125951907647, sinkhorn epsilon 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  290\n",
      "Training: loss 4.557942867279053, covariance difference 1.0034726858139038\n",
      "Validation: loss 5.708275632379922, covariance difference 8.685317176686425, sinkhorn epsilon 0.0\n",
      "Iteration  291\n",
      "Training: loss 4.668619632720947, covariance difference 1.0245782136917114\n",
      "Validation: loss 5.65262525742923, covariance difference 8.43408835069422, sinkhorn epsilon 2.020662463048932e-14\n",
      "Iteration  292\n",
      "Training: loss 4.612985134124756, covariance difference 1.0135142803192139\n",
      "Validation: loss 5.726120526287836, covariance difference 8.752543376608795, sinkhorn epsilon 0.0\n",
      "Iteration  293\n",
      "Training: loss 4.686507225036621, covariance difference 1.0283892154693604\n",
      "Validation: loss 5.543553467073899, covariance difference 8.531758017688926, sinkhorn epsilon 7.02758602885423e-14\n",
      "Iteration  294\n",
      "Training: loss 4.503936767578125, covariance difference 0.9947043657302856\n",
      "Validation: loss 5.76126001072569, covariance difference 8.833920030718106, sinkhorn epsilon 0.0\n",
      "Iteration  295\n",
      "Training: loss 4.721681594848633, covariance difference 1.034233570098877\n",
      "Validation: loss 5.641060043366558, covariance difference 8.500017288449717, sinkhorn epsilon 4.382517012853931e-14\n",
      "Iteration  296\n",
      "Training: loss 4.601489067077637, covariance difference 1.012473225593567\n",
      "Validation: loss 5.68973663991264, covariance difference 8.575947048918104, sinkhorn epsilon 0.0\n",
      "Iteration  297\n",
      "Training: loss 4.650184154510498, covariance difference 1.0203464031219482\n",
      "Validation: loss 5.6612363704411885, covariance difference 8.480518789249938, sinkhorn epsilon 0.0\n",
      "Iteration  298\n",
      "Training: loss 4.621592044830322, covariance difference 1.015971302986145\n",
      "Validation: loss 5.642203880282394, covariance difference 8.596974623339795, sinkhorn epsilon 2.9690744842641677e-14\n",
      "Iteration  299\n",
      "Training: loss 4.602625370025635, covariance difference 1.0118083953857422\n",
      "Validation: loss 5.584915851527633, covariance difference 8.448960560950285, sinkhorn epsilon 0.0\n",
      "Iteration  300\n",
      "Training: loss 4.545348167419434, covariance difference 1.004237174987793\n",
      "Validation: loss 5.603907079867269, covariance difference 8.568224333677376, sinkhorn epsilon 0.0\n",
      "Iteration  301\n",
      "Training: loss 4.564273834228516, covariance difference 1.0061941146850586\n",
      "Validation: loss 5.590911351964261, covariance difference 8.460787239493158, sinkhorn epsilon 1.0960950847691301e-14\n",
      "Iteration  302\n",
      "Training: loss 4.551255702972412, covariance difference 1.0043607950210571\n",
      "Validation: loss 5.607682508074251, covariance difference 8.490122284305896, sinkhorn epsilon 0.0\n",
      "Iteration  303\n",
      "Training: loss 4.568033695220947, covariance difference 1.0047990083694458\n",
      "Validation: loss 5.715432571328235, covariance difference 8.749667857979334, sinkhorn epsilon 0.0\n",
      "Iteration  304\n",
      "Training: loss 4.675785064697266, covariance difference 1.0261789560317993\n",
      "Validation: loss 5.652274047670308, covariance difference 8.45635097649454, sinkhorn epsilon 1.4815474920215196e-14\n",
      "Iteration  305\n",
      "Training: loss 4.612664222717285, covariance difference 1.012987732887268\n",
      "Validation: loss 5.592816591206358, covariance difference 8.21475643280837, sinkhorn epsilon 2.243931833093904e-14\n",
      "Iteration  306\n",
      "Training: loss 4.553183555603027, covariance difference 1.004215955734253\n",
      "Validation: loss 5.703253554899046, covariance difference 8.761356506988855, sinkhorn epsilon 0.0\n",
      "Iteration  307\n",
      "Training: loss 4.663619518280029, covariance difference 1.0239758491516113\n",
      "Validation: loss 5.732910013666352, covariance difference 8.44741705053888, sinkhorn epsilon 0.0\n",
      "Iteration  308\n",
      "Training: loss 4.693237781524658, covariance difference 1.0274956226348877\n",
      "Validation: loss 5.68205197709197, covariance difference 8.838340219002415, sinkhorn epsilon 0.0\n",
      "Iteration  309\n",
      "Training: loss 4.642444610595703, covariance difference 1.0197830200195312\n",
      "Validation: loss 5.762178797015271, covariance difference 8.771642265409982, sinkhorn epsilon 1.6183588855631097e-14\n",
      "Iteration  310\n",
      "Training: loss 4.722537517547607, covariance difference 1.032954454421997\n",
      "Validation: loss 5.614215495435435, covariance difference 8.6894473131967, sinkhorn epsilon 0.0\n",
      "Iteration  311\n",
      "Training: loss 4.574528694152832, covariance difference 1.0070444345474243\n",
      "Validation: loss 5.648856549275437, covariance difference 8.586815699094956, sinkhorn epsilon 0.0\n",
      "Iteration  312\n",
      "Training: loss 4.609226226806641, covariance difference 1.0136077404022217\n",
      "Validation: loss 5.629514579336482, covariance difference 8.553231790490782, sinkhorn epsilon 0.0\n",
      "Iteration  313\n",
      "Training: loss 4.589865207672119, covariance difference 1.010636329650879\n",
      "Validation: loss 5.62899795611439, covariance difference 8.72640111875402, sinkhorn epsilon 3.089378099219494e-14\n",
      "Iteration  314\n",
      "Training: loss 4.5893402099609375, covariance difference 1.0098851919174194\n",
      "Validation: loss 5.576330033313156, covariance difference 8.391524608195585, sinkhorn epsilon 0.0\n",
      "Iteration  315\n",
      "Training: loss 4.536661148071289, covariance difference 1.0016593933105469\n",
      "Validation: loss 5.694681570599767, covariance difference 8.672883143668031, sinkhorn epsilon 3.129521190692708e-14\n",
      "Iteration  316\n",
      "Training: loss 4.655073165893555, covariance difference 1.0222234725952148\n",
      "Validation: loss 5.602486038465937, covariance difference 8.574686620339293, sinkhorn epsilon 0.0\n",
      "Iteration  317\n",
      "Training: loss 4.562844276428223, covariance difference 1.0043063163757324\n",
      "Validation: loss 5.714462128503427, covariance difference 8.743477740433379, sinkhorn epsilon 0.0\n",
      "Iteration  318\n",
      "Training: loss 4.674888610839844, covariance difference 1.0255566835403442\n",
      "Validation: loss 5.667106567620186, covariance difference 8.672318461796522, sinkhorn epsilon 1.6034765750703964e-14\n",
      "Iteration  319\n",
      "Training: loss 4.627500057220459, covariance difference 1.0177935361862183\n",
      "Validation: loss 5.735335560776381, covariance difference 8.596247988498664, sinkhorn epsilon 1.2949354030783474e-14\n",
      "Iteration  320\n",
      "Training: loss 4.695716857910156, covariance difference 1.0293465852737427\n",
      "Validation: loss 5.6176740414454125, covariance difference 8.410857668166527, sinkhorn epsilon 0.0\n",
      "Iteration  321\n",
      "Training: loss 4.578032493591309, covariance difference 1.006847620010376\n",
      "Validation: loss 5.655627621896871, covariance difference 8.773936240147318, sinkhorn epsilon 0.0\n",
      "Iteration  322\n",
      "Training: loss 4.6159443855285645, covariance difference 1.0151431560516357\n",
      "Validation: loss 5.691934229126188, covariance difference 8.63898838451776, sinkhorn epsilon 0.0\n",
      "Iteration  323\n",
      "Training: loss 4.652337551116943, covariance difference 1.0210461616516113\n",
      "Validation: loss 5.69347729551469, covariance difference 8.553478302828836, sinkhorn epsilon 0.0\n",
      "Iteration  324\n",
      "Training: loss 4.653787612915039, covariance difference 1.020132303237915\n",
      "Validation: loss 5.711370306352348, covariance difference 8.60211111531303, sinkhorn epsilon 0.0\n",
      "Iteration  325\n",
      "Training: loss 4.671801567077637, covariance difference 1.024488091468811\n",
      "Validation: loss 5.648026514471576, covariance difference 8.521473748549825, sinkhorn epsilon 7.86729432766579e-15\n",
      "Iteration  326\n",
      "Training: loss 4.608394622802734, covariance difference 1.0136677026748657\n",
      "Validation: loss 5.698214075308209, covariance difference 8.492161361789442, sinkhorn epsilon 0.0\n",
      "Iteration  327\n",
      "Training: loss 4.6585540771484375, covariance difference 1.0235167741775513\n",
      "Validation: loss 5.627469679978249, covariance difference 8.508605989320298, sinkhorn epsilon 0.0\n",
      "Iteration  328\n",
      "Training: loss 4.5878143310546875, covariance difference 1.0089550018310547\n",
      "Validation: loss 5.655330185716577, covariance difference 8.568264730962001, sinkhorn epsilon 2.7107009548502396e-14\n",
      "Iteration  329\n",
      "Training: loss 4.615656852722168, covariance difference 1.0141955614089966\n",
      "Validation: loss 5.6194274986970205, covariance difference 8.461003482533588, sinkhorn epsilon 0.0\n",
      "Iteration  330\n",
      "Training: loss 4.579772472381592, covariance difference 1.007615089416504\n",
      "Validation: loss 5.6256589313601, covariance difference 8.640660205406895, sinkhorn epsilon 3.974781793780016e-15\n",
      "Iteration  331\n",
      "Training: loss 4.58599853515625, covariance difference 1.0080324411392212\n",
      "Validation: loss 5.716266641367723, covariance difference 8.79869399828148, sinkhorn epsilon 0.0\n",
      "Iteration  332\n",
      "Training: loss 4.676641464233398, covariance difference 1.026660680770874\n",
      "Validation: loss 5.680801505530749, covariance difference 8.725852964814036, sinkhorn epsilon 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  333\n",
      "Training: loss 4.641175270080566, covariance difference 1.018979787826538\n",
      "Validation: loss 5.6315552528710215, covariance difference 8.35673373411183, sinkhorn epsilon 0.0\n",
      "Iteration  334\n",
      "Training: loss 4.591884613037109, covariance difference 1.0118480920791626\n",
      "Validation: loss 5.69756154863766, covariance difference 8.657832775534692, sinkhorn epsilon 0.0\n",
      "Iteration  335\n",
      "Training: loss 4.657880783081055, covariance difference 1.0222474336624146\n",
      "Validation: loss 5.656895129250253, covariance difference 8.513175572059916, sinkhorn epsilon 0.0\n",
      "Iteration  336\n",
      "Training: loss 4.617242813110352, covariance difference 1.0152517557144165\n",
      "Validation: loss 5.708651447765379, covariance difference 8.793573406942299, sinkhorn epsilon 3.0087887424417924e-14\n",
      "Iteration  337\n",
      "Training: loss 4.669002532958984, covariance difference 1.024549961090088\n",
      "Validation: loss 5.628297718484702, covariance difference 8.875060853697088, sinkhorn epsilon 0.0\n",
      "Iteration  338\n",
      "Training: loss 4.588665008544922, covariance difference 1.0080866813659668\n",
      "Validation: loss 5.646928855805291, covariance difference 8.554743099114791, sinkhorn epsilon 0.0\n",
      "Iteration  339\n",
      "Training: loss 4.607220649719238, covariance difference 1.013321042060852\n",
      "Validation: loss 5.597027366102099, covariance difference 8.59441664985425, sinkhorn epsilon 0.0\n",
      "Iteration  340\n",
      "Training: loss 4.5573906898498535, covariance difference 1.0044715404510498\n",
      "Validation: loss 5.696708158088528, covariance difference 8.708292992615357, sinkhorn epsilon 1.900132446892974e-14\n",
      "Iteration  341\n",
      "Training: loss 4.657061576843262, covariance difference 1.0213490724563599\n",
      "Validation: loss 5.725328770520031, covariance difference 8.789269825002467, sinkhorn epsilon 0.0\n",
      "Iteration  342\n",
      "Training: loss 4.685665130615234, covariance difference 1.0261212587356567\n",
      "Validation: loss 5.657961337108011, covariance difference 8.718470300212507, sinkhorn epsilon 0.0\n",
      "Iteration  343\n",
      "Training: loss 4.618287086486816, covariance difference 1.0152238607406616\n",
      "Validation: loss 5.671758165525205, covariance difference 8.303571998667534, sinkhorn epsilon 3.6022256777346254e-14\n",
      "Iteration  344\n",
      "Training: loss 4.632109642028809, covariance difference 1.0169271230697632\n",
      "Validation: loss 5.636962547954312, covariance difference 8.64554737821558, sinkhorn epsilon 0.0\n",
      "Iteration  345\n",
      "Training: loss 4.5973100662231445, covariance difference 1.012115716934204\n",
      "Validation: loss 5.594305980211471, covariance difference 8.713698558312055, sinkhorn epsilon 0.0\n",
      "Iteration  346\n",
      "Training: loss 4.554628372192383, covariance difference 1.0041680335998535\n",
      "Validation: loss 5.690257345458724, covariance difference 8.657596304712676, sinkhorn epsilon 2.3595205728315617e-14\n",
      "Iteration  347\n",
      "Training: loss 4.650601863861084, covariance difference 1.0221426486968994\n",
      "Validation: loss 5.581823355846677, covariance difference 8.416243297221516, sinkhorn epsilon 1.67003453431424e-14\n",
      "Iteration  348\n",
      "Training: loss 4.542178153991699, covariance difference 1.000670075416565\n",
      "Validation: loss 5.662796616836289, covariance difference 8.492978051516648, sinkhorn epsilon 0.0\n",
      "Iteration  349\n",
      "Training: loss 4.623128890991211, covariance difference 1.0151243209838867\n",
      "Validation: loss 5.710979730817334, covariance difference 8.727601528461248, sinkhorn epsilon 0.0\n",
      "Iteration  350\n",
      "Training: loss 4.671322345733643, covariance difference 1.0232257843017578\n",
      "Validation: loss 5.64666455842938, covariance difference 8.669021448871739, sinkhorn epsilon 1.782651779094581e-14\n",
      "Iteration  351\n",
      "Training: loss 4.6069865226745605, covariance difference 1.013553261756897\n",
      "Validation: loss 5.634975594064418, covariance difference 8.48799621587306, sinkhorn epsilon 0.0\n",
      "Iteration  352\n",
      "Training: loss 4.595270156860352, covariance difference 1.0095288753509521\n",
      "Validation: loss 5.7571920310908755, covariance difference 8.926391774307268, sinkhorn epsilon 1.2129655505716826e-14\n",
      "Iteration  353\n",
      "Training: loss 4.717537879943848, covariance difference 1.0328737497329712\n",
      "Validation: loss 5.6166714329047345, covariance difference 8.469750465518288, sinkhorn epsilon 0.0\n",
      "Iteration  354\n",
      "Training: loss 4.576999664306641, covariance difference 1.0076922178268433\n",
      "Validation: loss 5.598610079069769, covariance difference 8.507061837372836, sinkhorn epsilon 0.0\n",
      "Iteration  355\n",
      "Training: loss 4.558940887451172, covariance difference 1.0032789707183838\n",
      "Validation: loss 5.688565447051565, covariance difference 8.645660527555307, sinkhorn epsilon 0.0\n",
      "Iteration  356\n",
      "Training: loss 4.649031639099121, covariance difference 1.0194478034973145\n",
      "Validation: loss 5.6729285078050244, covariance difference 8.571515299435532, sinkhorn epsilon 0.0\n",
      "Iteration  357\n",
      "Training: loss 4.633321762084961, covariance difference 1.016441822052002\n",
      "Validation: loss 5.654602146313136, covariance difference 8.50526576134314, sinkhorn epsilon 0.0\n",
      "Iteration  358\n",
      "Training: loss 4.614932060241699, covariance difference 1.0148975849151611\n",
      "Validation: loss 5.637675432821543, covariance difference 8.66299320811759, sinkhorn epsilon 0.0\n",
      "Iteration  359\n",
      "Training: loss 4.598092079162598, covariance difference 1.0122467279434204\n",
      "Validation: loss 5.690022537122356, covariance difference 8.726125740078496, sinkhorn epsilon 0.0\n",
      "Iteration  360\n",
      "Training: loss 4.650373935699463, covariance difference 1.020175814628601\n",
      "Validation: loss 5.692680611758524, covariance difference 8.64618988992974, sinkhorn epsilon 3.447584442969991e-14\n",
      "Iteration  361\n",
      "Training: loss 4.653036117553711, covariance difference 1.0212010145187378\n",
      "Validation: loss 5.675415431787286, covariance difference 8.717806323044831, sinkhorn epsilon 0.0\n",
      "Iteration  362\n",
      "Training: loss 4.635777473449707, covariance difference 1.0186820030212402\n",
      "Validation: loss 5.762662882556408, covariance difference 8.570914157412423, sinkhorn epsilon 0.0\n",
      "Iteration  363\n",
      "Training: loss 4.723015785217285, covariance difference 1.032991647720337\n",
      "Validation: loss 5.678194250209085, covariance difference 8.845781705948646, sinkhorn epsilon 3.5049346163195534e-14\n",
      "Iteration  364\n",
      "Training: loss 4.638555526733398, covariance difference 1.020346999168396\n",
      "Validation: loss 5.643000994235502, covariance difference 8.458254211351104, sinkhorn epsilon 2.47312648013246e-14\n",
      "Iteration  365\n",
      "Training: loss 4.603338241577148, covariance difference 1.0125929117202759\n",
      "Validation: loss 5.627231519026908, covariance difference 8.514320609711511, sinkhorn epsilon 0.0\n",
      "Iteration  366\n",
      "Training: loss 4.587584495544434, covariance difference 1.0088950395584106\n",
      "Validation: loss 5.578084160880797, covariance difference 8.613446089385159, sinkhorn epsilon 0.0\n",
      "Iteration  367\n",
      "Training: loss 4.53842830657959, covariance difference 0.9984066486358643\n",
      "Validation: loss 5.634138797697498, covariance difference 8.173994905448964, sinkhorn epsilon 3.956941359163634e-14\n",
      "Iteration  368\n",
      "Training: loss 4.594491958618164, covariance difference 1.0122528076171875\n",
      "Validation: loss 5.6841636967594535, covariance difference 8.612665288652227, sinkhorn epsilon 0.0\n",
      "Iteration  369\n",
      "Training: loss 4.644539833068848, covariance difference 1.0201386213302612\n",
      "Validation: loss 5.64104740806285, covariance difference 8.50943179877772, sinkhorn epsilon 0.0\n",
      "Iteration  370\n",
      "Training: loss 4.601412773132324, covariance difference 1.0118203163146973\n",
      "Validation: loss 5.592140053968042, covariance difference 8.48842989551543, sinkhorn epsilon 1.5780086321490673e-14\n",
      "Iteration  371\n",
      "Training: loss 4.5525007247924805, covariance difference 1.0021593570709229\n",
      "Validation: loss 5.689085543956485, covariance difference 8.812178831141345, sinkhorn epsilon 0.0\n",
      "Iteration  372\n",
      "Training: loss 4.6494140625, covariance difference 1.019736886024475\n",
      "Validation: loss 5.650246718418349, covariance difference 8.6650262035588, sinkhorn epsilon 0.0\n",
      "Iteration  373\n",
      "Training: loss 4.610581398010254, covariance difference 1.0138459205627441\n",
      "Validation: loss 5.665459616818428, covariance difference 8.572454698088247, sinkhorn epsilon 0.0\n",
      "Iteration  374\n",
      "Training: loss 4.625816345214844, covariance difference 1.0168383121490479\n",
      "Validation: loss 5.631649787262967, covariance difference 8.352715758651174, sinkhorn epsilon 0.0\n",
      "Iteration  375\n",
      "Training: loss 4.592011451721191, covariance difference 1.0096992254257202\n",
      "Validation: loss 5.616133819735069, covariance difference 8.598415548637158, sinkhorn epsilon 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  376\n",
      "Training: loss 4.576467037200928, covariance difference 1.0076779127120972\n",
      "Validation: loss 5.638075502776429, covariance difference 8.359610556371349, sinkhorn epsilon 0.0\n",
      "Iteration  377\n",
      "Training: loss 4.598459243774414, covariance difference 1.0105631351470947\n",
      "Validation: loss 5.659557350333561, covariance difference 8.67711748132375, sinkhorn epsilon 1.2604317752140005e-14\n",
      "Iteration  378\n",
      "Training: loss 4.619948387145996, covariance difference 1.0136280059814453\n",
      "Validation: loss 5.683719491359874, covariance difference 8.585086915499096, sinkhorn epsilon 0.0\n",
      "Iteration  379\n",
      "Training: loss 4.644008159637451, covariance difference 1.0210132598876953\n",
      "Validation: loss 5.6613586274156855, covariance difference 8.39235800234239, sinkhorn epsilon 2.235463423612763e-14\n",
      "Iteration  380\n",
      "Training: loss 4.621697425842285, covariance difference 1.0162386894226074\n",
      "Validation: loss 5.692022619870388, covariance difference 8.764671549627604, sinkhorn epsilon 2.2270758453788372e-14\n",
      "Iteration  381\n",
      "Training: loss 4.652356147766113, covariance difference 1.021445393562317\n",
      "Validation: loss 5.644153442410839, covariance difference 8.52033938470806, sinkhorn epsilon 9.105563102092456e-16\n",
      "Iteration  382\n",
      "Training: loss 4.604616165161133, covariance difference 1.0147557258605957\n",
      "Validation: loss 5.5907524515018086, covariance difference 8.552897996557615, sinkhorn epsilon 0.0\n",
      "Iteration  383\n",
      "Training: loss 4.5510759353637695, covariance difference 1.002239465713501\n",
      "Validation: loss 5.726146636436665, covariance difference 8.674038031546205, sinkhorn epsilon 0.0\n",
      "Iteration  384\n",
      "Training: loss 4.686494827270508, covariance difference 1.028450608253479\n",
      "Validation: loss 5.649594334025627, covariance difference 8.472893340064566, sinkhorn epsilon 0.0\n",
      "Iteration  385\n",
      "Training: loss 4.609956741333008, covariance difference 1.0131781101226807\n",
      "Validation: loss 5.6226392499900175, covariance difference 8.63261194689075, sinkhorn epsilon 1.9801041897752015e-14\n",
      "Iteration  386\n",
      "Training: loss 4.583016872406006, covariance difference 1.0077147483825684\n",
      "Validation: loss 5.645722763064571, covariance difference 8.668181894760966, sinkhorn epsilon 0.0\n",
      "Iteration  387\n",
      "Training: loss 4.606066703796387, covariance difference 1.0124027729034424\n",
      "Validation: loss 5.5865333711739025, covariance difference 8.527545307308998, sinkhorn epsilon 4.460029430294055e-14\n",
      "Iteration  388\n",
      "Training: loss 4.5468597412109375, covariance difference 1.0012438297271729\n",
      "Validation: loss 5.60770633200061, covariance difference 8.623374571335912, sinkhorn epsilon 0.0\n",
      "Iteration  389\n",
      "Training: loss 4.568158149719238, covariance difference 1.0054984092712402\n",
      "Validation: loss 5.717088684484315, covariance difference 8.707246202418625, sinkhorn epsilon 4.308999370383705e-15\n",
      "Iteration  390\n",
      "Training: loss 4.677510738372803, covariance difference 1.0253700017929077\n",
      "Validation: loss 5.643752795184294, covariance difference 8.556246887812295, sinkhorn epsilon 0.0\n",
      "Iteration  391\n",
      "Training: loss 4.604102611541748, covariance difference 1.0123347043991089\n",
      "Validation: loss 5.5856228957078065, covariance difference 8.664837687878466, sinkhorn epsilon 0.0\n",
      "Iteration  392\n",
      "Training: loss 4.545971870422363, covariance difference 1.0012015104293823\n",
      "Validation: loss 5.726772162180037, covariance difference 8.634616806072199, sinkhorn epsilon 0.0\n",
      "Iteration  393\n",
      "Training: loss 4.687102317810059, covariance difference 1.0286344289779663\n",
      "Validation: loss 5.673345483285991, covariance difference 8.712977525515779, sinkhorn epsilon 1.9235355887250747e-14\n",
      "Iteration  394\n",
      "Training: loss 4.6337409019470215, covariance difference 1.0175395011901855\n",
      "Validation: loss 5.599915809932926, covariance difference 8.673741982441426, sinkhorn epsilon 0.0\n",
      "Iteration  395\n",
      "Training: loss 4.560257434844971, covariance difference 1.0042399168014526\n",
      "Validation: loss 5.616602369690383, covariance difference 8.880538489303609, sinkhorn epsilon 0.0\n",
      "Iteration  396\n",
      "Training: loss 4.576935768127441, covariance difference 1.0079331398010254\n",
      "Validation: loss 5.617846307876086, covariance difference 8.63087424870957, sinkhorn epsilon 0.0\n",
      "Iteration  397\n",
      "Training: loss 4.5782012939453125, covariance difference 1.0078394412994385\n",
      "Validation: loss 5.682245772643638, covariance difference 8.828046519268792, sinkhorn epsilon 0.0\n",
      "Iteration  398\n",
      "Training: loss 4.642529487609863, covariance difference 1.0180288553237915\n",
      "Validation: loss 5.7190259711613, covariance difference 8.75086634722905, sinkhorn epsilon 0.0\n",
      "Iteration  399\n",
      "Training: loss 4.679344654083252, covariance difference 1.027061104774475\n",
      "Validation: loss 5.682059526795442, covariance difference 8.59014646389181, sinkhorn epsilon 0.0\n",
      "Iteration  400\n",
      "Training: loss 4.642393112182617, covariance difference 1.0184526443481445\n",
      "Validation: loss 5.691641358424711, covariance difference 8.810439576319883, sinkhorn epsilon 0.0\n",
      "Iteration  401\n",
      "Training: loss 4.651983261108398, covariance difference 1.0216635465621948\n",
      "Validation: loss 5.594338717662685, covariance difference 8.660176109046876, sinkhorn epsilon 0.0\n",
      "Iteration  402\n",
      "Training: loss 4.554707050323486, covariance difference 1.002246379852295\n",
      "Validation: loss 5.573430788235591, covariance difference 8.451702896115656, sinkhorn epsilon 0.0\n",
      "Iteration  403\n",
      "Training: loss 4.533713340759277, covariance difference 0.9979994297027588\n",
      "Validation: loss 5.677544393867659, covariance difference 8.565839403522174, sinkhorn epsilon 1.454795506495277e-14\n",
      "Iteration  404\n",
      "Training: loss 4.6379475593566895, covariance difference 1.0185436010360718\n",
      "Validation: loss 5.654440969154528, covariance difference 8.553498457420815, sinkhorn epsilon 0.0\n",
      "Iteration  405\n",
      "Training: loss 4.6147942543029785, covariance difference 1.0160815715789795\n",
      "Validation: loss 5.711706009546354, covariance difference 8.818954343849168, sinkhorn epsilon 0.0\n",
      "Iteration  406\n",
      "Training: loss 4.672060489654541, covariance difference 1.0254963636398315\n",
      "Validation: loss 5.717299133354997, covariance difference 8.874662088400314, sinkhorn epsilon 0.0\n",
      "Iteration  407\n",
      "Training: loss 4.6775736808776855, covariance difference 1.0259560346603394\n",
      "Validation: loss 5.734011948655443, covariance difference 8.816082621759024, sinkhorn epsilon 0.0\n",
      "Iteration  408\n",
      "Training: loss 4.694362163543701, covariance difference 1.0270390510559082\n",
      "Validation: loss 5.651126334329843, covariance difference 8.478750538598783, sinkhorn epsilon 0.0\n",
      "Iteration  409\n",
      "Training: loss 4.611506462097168, covariance difference 1.0156329870224\n",
      "Validation: loss 5.644659415937454, covariance difference 8.454462643660309, sinkhorn epsilon 0.0\n",
      "Iteration  410\n",
      "Training: loss 4.604979038238525, covariance difference 1.0132880210876465\n",
      "Validation: loss 5.5985279621208415, covariance difference 8.409312314424483, sinkhorn epsilon 6.621619527037897e-15\n",
      "Iteration  411\n",
      "Training: loss 4.558844566345215, covariance difference 1.0049078464508057\n",
      "Validation: loss 5.6332147864840305, covariance difference 8.471267062825191, sinkhorn epsilon 0.0\n",
      "Iteration  412\n",
      "Training: loss 4.593574047088623, covariance difference 1.0125726461410522\n",
      "Validation: loss 5.615306055608428, covariance difference 8.630672629580419, sinkhorn epsilon 5.3383951092162876e-14\n",
      "Iteration  413\n",
      "Training: loss 4.575650215148926, covariance difference 1.0072596073150635\n",
      "Validation: loss 5.640178750223306, covariance difference 8.356672159742878, sinkhorn epsilon 0.0\n",
      "Iteration  414\n",
      "Training: loss 4.6005425453186035, covariance difference 1.0110621452331543\n",
      "Validation: loss 5.642755630176416, covariance difference 8.564380138449922, sinkhorn epsilon 0.0\n",
      "Iteration  415\n",
      "Training: loss 4.603123188018799, covariance difference 1.0135655403137207\n",
      "Validation: loss 5.754914915404687, covariance difference 8.527311967483838, sinkhorn epsilon 0.0\n",
      "Iteration  416\n",
      "Training: loss 4.7152299880981445, covariance difference 1.0326316356658936\n",
      "Validation: loss 5.6190860259644175, covariance difference 8.446773940432458, sinkhorn epsilon 1.6474783204841118e-14\n",
      "Iteration  417\n",
      "Training: loss 4.579399108886719, covariance difference 1.0086437463760376\n",
      "Validation: loss 5.686383867662536, covariance difference 8.784878734946826, sinkhorn epsilon 3.091696525292072e-14\n",
      "Iteration  418\n",
      "Training: loss 4.646740436553955, covariance difference 1.021074652671814\n",
      "Validation: loss 5.605356571066483, covariance difference 8.53645266361772, sinkhorn epsilon 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  419\n",
      "Training: loss 4.5656962394714355, covariance difference 1.0055696964263916\n",
      "Validation: loss 5.604607486700438, covariance difference 8.416787883206146, sinkhorn epsilon 6.797396266227845e-15\n",
      "Iteration  420\n",
      "Training: loss 4.564939022064209, covariance difference 1.0051424503326416\n",
      "Validation: loss 5.662804182052431, covariance difference 8.77162787949235, sinkhorn epsilon 0.0\n",
      "Iteration  421\n",
      "Training: loss 4.623089790344238, covariance difference 1.0161088705062866\n",
      "Validation: loss 5.755954083997851, covariance difference 8.672152218058038, sinkhorn epsilon 0.0\n",
      "Iteration  422\n",
      "Training: loss 4.716254711151123, covariance difference 1.0317517518997192\n",
      "Validation: loss 5.6672862891937426, covariance difference 8.790623434566793, sinkhorn epsilon 0.0\n",
      "Iteration  423\n",
      "Training: loss 4.627608776092529, covariance difference 1.0174018144607544\n",
      "Validation: loss 5.684734375826005, covariance difference 8.720558819005296, sinkhorn epsilon 3.6573900349046364e-14\n",
      "Iteration  424\n",
      "Training: loss 4.64507532119751, covariance difference 1.0195900201797485\n",
      "Validation: loss 5.683787401235584, covariance difference 8.704028062896995, sinkhorn epsilon 1.1566378866070753e-14\n",
      "Iteration  425\n",
      "Training: loss 4.644078254699707, covariance difference 1.0219463109970093\n",
      "Validation: loss 5.630217505798036, covariance difference 8.530691339064495, sinkhorn epsilon 3.7535414339629077e-14\n",
      "Iteration  426\n",
      "Training: loss 4.5905375480651855, covariance difference 1.010595440864563\n",
      "Validation: loss 5.735968037592701, covariance difference 8.880856761035915, sinkhorn epsilon 2.823779580823063e-14\n",
      "Iteration  427\n",
      "Training: loss 4.696249008178711, covariance difference 1.0280661582946777\n",
      "Validation: loss 5.645277297998311, covariance difference 8.469383943195426, sinkhorn epsilon 0.0\n",
      "Iteration  428\n",
      "Training: loss 4.605600357055664, covariance difference 1.0097209215164185\n",
      "Validation: loss 5.684360640496775, covariance difference 8.59886043283525, sinkhorn epsilon 4.363741602026358e-14\n",
      "Iteration  429\n",
      "Training: loss 4.644690990447998, covariance difference 1.0201668739318848\n",
      "Validation: loss 5.681732937956595, covariance difference 8.574032853922, sinkhorn epsilon 0.0\n",
      "Iteration  430\n",
      "Training: loss 4.642055511474609, covariance difference 1.0188792943954468\n",
      "Validation: loss 5.571660468380072, covariance difference 8.45812364032183, sinkhorn epsilon 3.054094765324754e-14\n",
      "Iteration  431\n",
      "Training: loss 4.531950950622559, covariance difference 1.0015528202056885\n",
      "Validation: loss 5.632105593953929, covariance difference 8.370936419957589, sinkhorn epsilon 3.608152924210884e-14\n",
      "Iteration  432\n",
      "Training: loss 4.592452049255371, covariance difference 1.0086103677749634\n",
      "Validation: loss 5.670628287225864, covariance difference 8.529337551179093, sinkhorn epsilon 0.0\n",
      "Iteration  433\n",
      "Training: loss 4.630965709686279, covariance difference 1.0180158615112305\n",
      "Validation: loss 5.612198920995427, covariance difference 8.422405885213452, sinkhorn epsilon 0.0\n",
      "Iteration  434\n",
      "Training: loss 4.572540283203125, covariance difference 1.0090818405151367\n",
      "Validation: loss 5.623658010834024, covariance difference 8.566748545967082, sinkhorn epsilon 3.4629306903894204e-14\n",
      "Iteration  435\n",
      "Training: loss 4.583982467651367, covariance difference 1.0088742971420288\n",
      "Validation: loss 5.653067067939916, covariance difference 8.626832142491544, sinkhorn epsilon 2.4159720947945635e-14\n",
      "Iteration  436\n",
      "Training: loss 4.613375663757324, covariance difference 1.0144131183624268\n",
      "Validation: loss 5.674663252724752, covariance difference 8.605771787393682, sinkhorn epsilon 5.904754861718236e-15\n",
      "Iteration  437\n",
      "Training: loss 4.635014533996582, covariance difference 1.016771674156189\n",
      "Validation: loss 5.5860173224395835, covariance difference 8.505791364944438, sinkhorn epsilon 0.0\n",
      "Iteration  438\n",
      "Training: loss 4.546349048614502, covariance difference 1.0045998096466064\n",
      "Validation: loss 5.776786727452612, covariance difference 8.903562429537294, sinkhorn epsilon 3.5266167556811317e-14\n",
      "Iteration  439\n",
      "Training: loss 4.737114906311035, covariance difference 1.0365289449691772\n",
      "Validation: loss 5.582377984615254, covariance difference 8.46538305459202, sinkhorn epsilon 0.0\n",
      "Iteration  440\n",
      "Training: loss 4.5427045822143555, covariance difference 1.0006614923477173\n",
      "Validation: loss 5.70100137262285, covariance difference 8.624268835743754, sinkhorn epsilon 0.0\n",
      "Iteration  441\n",
      "Training: loss 4.661371231079102, covariance difference 1.0248085260391235\n",
      "Validation: loss 5.723118893066316, covariance difference 8.606919580635223, sinkhorn epsilon 0.0\n",
      "Iteration  442\n",
      "Training: loss 4.68344259262085, covariance difference 1.0256317853927612\n",
      "Validation: loss 5.644658961176774, covariance difference 8.747657602613353, sinkhorn epsilon 0.0\n",
      "Iteration  443\n",
      "Training: loss 4.6049394607543945, covariance difference 1.0129170417785645\n",
      "Validation: loss 5.758045263275131, covariance difference 8.738921342136166, sinkhorn epsilon 0.0\n",
      "Iteration  444\n",
      "Training: loss 4.718332767486572, covariance difference 1.0319666862487793\n",
      "Validation: loss 5.6031073954771795, covariance difference 8.54336546667739, sinkhorn epsilon 0.0\n",
      "Iteration  445\n",
      "Training: loss 4.563386917114258, covariance difference 1.005623698234558\n",
      "Validation: loss 5.625373583165272, covariance difference 8.565172154475402, sinkhorn epsilon 0.0\n",
      "Iteration  446\n",
      "Training: loss 4.5856523513793945, covariance difference 1.0101187229156494\n",
      "Validation: loss 5.687607319997675, covariance difference 8.691104129198395, sinkhorn epsilon 0.0\n",
      "Iteration  447\n",
      "Training: loss 4.6479105949401855, covariance difference 1.020717740058899\n",
      "Validation: loss 5.713828385821721, covariance difference 8.681218404877669, sinkhorn epsilon 0.0\n",
      "Iteration  448\n",
      "Training: loss 4.674108982086182, covariance difference 1.0229823589324951\n",
      "Validation: loss 5.651447028111502, covariance difference 8.726673561162695, sinkhorn epsilon 0.0\n",
      "Iteration  449\n",
      "Training: loss 4.611732006072998, covariance difference 1.0134918689727783\n",
      "Validation: loss 5.592088438205186, covariance difference 8.433798946855108, sinkhorn epsilon 0.0\n",
      "Iteration  450\n",
      "Training: loss 4.5523762702941895, covariance difference 1.00242018699646\n",
      "Validation: loss 5.620152420544345, covariance difference 8.659736136875768, sinkhorn epsilon 1.6083935709251907e-14\n",
      "Iteration  451\n",
      "Training: loss 4.580502510070801, covariance difference 1.0068987607955933\n",
      "Validation: loss 5.695684503780002, covariance difference 8.60106526296345, sinkhorn epsilon 0.0\n",
      "Iteration  452\n",
      "Training: loss 4.655972003936768, covariance difference 1.02190363407135\n",
      "Validation: loss 5.602865914745722, covariance difference 8.57502585939879, sinkhorn epsilon 0.0\n",
      "Iteration  453\n",
      "Training: loss 4.563206195831299, covariance difference 1.0034747123718262\n",
      "Validation: loss 5.65493719373059, covariance difference 8.53483224359726, sinkhorn epsilon 0.0\n",
      "Iteration  454\n",
      "Training: loss 4.615220069885254, covariance difference 1.0144551992416382\n",
      "Validation: loss 5.640985449485265, covariance difference 8.649235846735884, sinkhorn epsilon 0.0\n",
      "Iteration  455\n",
      "Training: loss 4.601274490356445, covariance difference 1.0105912685394287\n",
      "Validation: loss 5.683540150810159, covariance difference 8.609035843903706, sinkhorn epsilon 3.6307748533621564e-14\n",
      "Iteration  456\n",
      "Training: loss 4.643922805786133, covariance difference 1.0191137790679932\n",
      "Validation: loss 5.694995437196054, covariance difference 8.773301366875938, sinkhorn epsilon 0.0\n",
      "Iteration  457\n",
      "Training: loss 4.655269622802734, covariance difference 1.0211248397827148\n",
      "Validation: loss 5.650947349341199, covariance difference 8.62929877699923, sinkhorn epsilon 4.214107049714365e-14\n",
      "Iteration  458\n",
      "Training: loss 4.61126708984375, covariance difference 1.0141396522521973\n",
      "Validation: loss 5.6998796167443215, covariance difference 8.680975356329666, sinkhorn epsilon 0.0\n",
      "Iteration  459\n",
      "Training: loss 4.660208702087402, covariance difference 1.022760033607483\n",
      "Validation: loss 5.6455517439546306, covariance difference 8.532348144085512, sinkhorn epsilon 0.0\n",
      "Iteration  460\n",
      "Training: loss 4.605898857116699, covariance difference 1.0127522945404053\n",
      "Validation: loss 5.6064715551343305, covariance difference 8.483932596469119, sinkhorn epsilon 4.2506197683974966e-14\n",
      "Iteration  461\n",
      "Training: loss 4.566800594329834, covariance difference 1.007317304611206\n",
      "Validation: loss 5.674986678112562, covariance difference 8.568503324966393, sinkhorn epsilon 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  462\n",
      "Training: loss 4.6353349685668945, covariance difference 1.0186821222305298\n",
      "Validation: loss 5.665833072220584, covariance difference 8.584670710224618, sinkhorn epsilon 0.0\n",
      "Iteration  463\n",
      "Training: loss 4.626162528991699, covariance difference 1.0168852806091309\n",
      "Validation: loss 5.713864720562167, covariance difference 8.760242753268546, sinkhorn epsilon 4.763515635410573e-14\n",
      "Iteration  464\n",
      "Training: loss 4.674139976501465, covariance difference 1.0249325037002563\n",
      "Validation: loss 5.694390686850541, covariance difference 8.699009520293156, sinkhorn epsilon 0.0\n",
      "Iteration  465\n",
      "Training: loss 4.654669761657715, covariance difference 1.020561695098877\n",
      "Validation: loss 5.6371355296812, covariance difference 8.786578274027917, sinkhorn epsilon 0.0\n",
      "Iteration  466\n",
      "Training: loss 4.597466945648193, covariance difference 1.0099207162857056\n",
      "Validation: loss 5.578419110333762, covariance difference 8.460721328916598, sinkhorn epsilon 0.0\n",
      "Iteration  467\n",
      "Training: loss 4.538693904876709, covariance difference 0.9999464750289917\n",
      "Validation: loss 5.664407531580874, covariance difference 8.668100093633653, sinkhorn epsilon 3.7179861087971255e-14\n",
      "Iteration  468\n",
      "Training: loss 4.624732971191406, covariance difference 1.0181493759155273\n",
      "Validation: loss 5.5988545425451015, covariance difference 8.36755484334243, sinkhorn epsilon 0.0\n",
      "Iteration  469\n",
      "Training: loss 4.559192657470703, covariance difference 1.004769206047058\n",
      "Validation: loss 5.6497376523758955, covariance difference 8.616819736944938, sinkhorn epsilon 0.0\n",
      "Iteration  470\n",
      "Training: loss 4.610018730163574, covariance difference 1.0142030715942383\n",
      "Validation: loss 5.58846346569355, covariance difference 8.257536130069264, sinkhorn epsilon 3.540831923693871e-14\n",
      "Iteration  471\n",
      "Training: loss 4.548794746398926, covariance difference 1.000364899635315\n",
      "Validation: loss 5.600846701384249, covariance difference 8.609492527409907, sinkhorn epsilon 0.0\n",
      "Iteration  472\n",
      "Training: loss 4.561129570007324, covariance difference 1.0041424036026\n",
      "Validation: loss 5.620889023878713, covariance difference 8.503308528775804, sinkhorn epsilon 0.0\n",
      "Iteration  473\n",
      "Training: loss 4.581214427947998, covariance difference 1.0097426176071167\n",
      "Validation: loss 5.667146296126094, covariance difference 8.761467953400345, sinkhorn epsilon 2.028617385698122e-14\n",
      "Iteration  474\n",
      "Training: loss 4.6274638175964355, covariance difference 1.0154187679290771\n",
      "Validation: loss 5.6795638761310245, covariance difference 8.68957392330041, sinkhorn epsilon 0.0\n",
      "Iteration  475\n",
      "Training: loss 4.639892578125, covariance difference 1.0175830125808716\n",
      "Validation: loss 5.635455525294298, covariance difference 8.566534280265234, sinkhorn epsilon 0.0\n",
      "Iteration  476\n",
      "Training: loss 4.595727920532227, covariance difference 1.0104410648345947\n",
      "Validation: loss 5.675877886334776, covariance difference 8.550164668254983, sinkhorn epsilon 0.0\n",
      "Iteration  477\n",
      "Training: loss 4.636167526245117, covariance difference 1.019269347190857\n",
      "Validation: loss 5.665404277326219, covariance difference 8.65147411537377, sinkhorn epsilon 1.7021988099941503e-14\n",
      "Iteration  478\n",
      "Training: loss 4.62574577331543, covariance difference 1.01524019241333\n",
      "Validation: loss 5.634412089232919, covariance difference 8.62661241044132, sinkhorn epsilon 0.0\n",
      "Iteration  479\n",
      "Training: loss 4.594728946685791, covariance difference 1.0116430521011353\n",
      "Validation: loss 5.705132346176806, covariance difference 8.642024256686605, sinkhorn epsilon 3.9504846568818904e-14\n",
      "Iteration  480\n",
      "Training: loss 4.665477752685547, covariance difference 1.0245285034179688\n",
      "Validation: loss 5.676633790714069, covariance difference 8.635092632459838, sinkhorn epsilon 1.765652334766013e-14\n",
      "Iteration  481\n",
      "Training: loss 4.636989593505859, covariance difference 1.0178643465042114\n",
      "Validation: loss 5.616218333806145, covariance difference 8.603165935536532, sinkhorn epsilon 0.0\n",
      "Iteration  482\n",
      "Training: loss 4.576505661010742, covariance difference 1.0091991424560547\n",
      "Validation: loss 5.6091768002802835, covariance difference 8.457382964220018, sinkhorn epsilon 1.6447093388701494e-14\n",
      "Iteration  483\n",
      "Training: loss 4.569511413574219, covariance difference 1.0089836120605469\n",
      "Validation: loss 5.686291379457951, covariance difference 8.793464857478826, sinkhorn epsilon 0.0\n",
      "Iteration  484\n",
      "Training: loss 4.646618366241455, covariance difference 1.020440936088562\n",
      "Validation: loss 5.629296806107767, covariance difference 8.467837920725593, sinkhorn epsilon 0.0\n",
      "Iteration  485\n",
      "Training: loss 4.589581489562988, covariance difference 1.0103641748428345\n",
      "Validation: loss 5.537917271499069, covariance difference 8.393106096168408, sinkhorn epsilon 0.0\n",
      "Iteration  486\n",
      "Training: loss 4.4982075691223145, covariance difference 0.993118405342102\n",
      "Validation: loss 5.5922790338428925, covariance difference 8.620311423303624, sinkhorn epsilon 9.537004456993652e-16\n",
      "Iteration  487\n",
      "Training: loss 4.552656650543213, covariance difference 1.0028316974639893\n",
      "Validation: loss 5.6621835535359155, covariance difference 8.670424123150427, sinkhorn epsilon 0.0\n",
      "Iteration  488\n",
      "Training: loss 4.622512340545654, covariance difference 1.01396644115448\n",
      "Validation: loss 5.600345479321986, covariance difference 8.671423395683181, sinkhorn epsilon 0.0\n",
      "Iteration  489\n",
      "Training: loss 4.560672760009766, covariance difference 1.0044572353363037\n",
      "Validation: loss 5.672351171135829, covariance difference 8.559129524522861, sinkhorn epsilon 2.7403361749645594e-14\n",
      "Iteration  490\n",
      "Training: loss 4.632638454437256, covariance difference 1.0185548067092896\n",
      "Validation: loss 5.6252386400085195, covariance difference 8.70511606234258, sinkhorn epsilon 0.0\n",
      "Iteration  491\n",
      "Training: loss 4.58552360534668, covariance difference 1.0093673467636108\n",
      "Validation: loss 5.76373842121504, covariance difference 8.895159807070613, sinkhorn epsilon 3.3176437180548824e-14\n",
      "Iteration  492\n",
      "Training: loss 4.7240705490112305, covariance difference 1.036326289176941\n",
      "Validation: loss 5.622408737010119, covariance difference 8.473347028292945, sinkhorn epsilon 0.0\n",
      "Iteration  493\n",
      "Training: loss 4.582685470581055, covariance difference 1.0086489915847778\n",
      "Validation: loss 5.6756474839764355, covariance difference 8.658175584905633, sinkhorn epsilon 0.0\n",
      "Iteration  494\n",
      "Training: loss 4.635944843292236, covariance difference 1.0199781656265259\n",
      "Validation: loss 5.6703839553739686, covariance difference 8.584312095590146, sinkhorn epsilon 9.200582907048387e-14\n",
      "Iteration  495\n",
      "Training: loss 4.63067626953125, covariance difference 1.0176194906234741\n",
      "Validation: loss 5.5769188632871245, covariance difference 8.545490698068196, sinkhorn epsilon 0.0\n",
      "Iteration  496\n",
      "Training: loss 4.53723669052124, covariance difference 0.9997681379318237\n",
      "Validation: loss 5.654350800312596, covariance difference 8.56067992699284, sinkhorn epsilon 0.0\n",
      "Iteration  497\n",
      "Training: loss 4.614628791809082, covariance difference 1.0134493112564087\n",
      "Validation: loss 5.666527255658406, covariance difference 8.587303539988776, sinkhorn epsilon 4.274358644806853e-15\n",
      "Iteration  498\n",
      "Training: loss 4.626803874969482, covariance difference 1.0182955265045166\n",
      "Validation: loss 5.661440664932721, covariance difference 8.513155780665976, sinkhorn epsilon 0.0\n",
      "Iteration  499\n",
      "Training: loss 4.621786117553711, covariance difference 1.0167444944381714\n",
      "Validation: loss 5.69288421328608, covariance difference 8.716251851977743, sinkhorn epsilon 0.0\n",
      "Iteration  500\n",
      "Training: loss 4.6531982421875, covariance difference 1.0215041637420654\n",
      "Validation: loss 5.66696427310365, covariance difference 8.417516077766441, sinkhorn epsilon 0.0\n",
      "Iteration  501\n",
      "Training: loss 4.627248764038086, covariance difference 1.0166631937026978\n",
      "Validation: loss 5.708437119300069, covariance difference 8.738526015935586, sinkhorn epsilon 0.0\n",
      "Iteration  502\n",
      "Training: loss 4.668765068054199, covariance difference 1.024764060974121\n",
      "Validation: loss 5.642525497939606, covariance difference 8.602481146313062, sinkhorn epsilon 0.0\n",
      "Iteration  503\n",
      "Training: loss 4.6028828620910645, covariance difference 1.0117835998535156\n",
      "Validation: loss 5.692005246753735, covariance difference 8.952563281335172, sinkhorn epsilon 0.0\n",
      "Iteration  504\n",
      "Training: loss 4.652299880981445, covariance difference 1.0234606266021729\n",
      "Validation: loss 5.688390172854185, covariance difference 8.638412911035699, sinkhorn epsilon 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  505\n",
      "Training: loss 4.648674964904785, covariance difference 1.01896071434021\n",
      "Validation: loss 5.5780977720477924, covariance difference 8.464779849132116, sinkhorn epsilon 0.0\n",
      "Iteration  506\n",
      "Training: loss 4.538417816162109, covariance difference 0.9997079372406006\n",
      "Validation: loss 5.64992700234092, covariance difference 8.462382307449936, sinkhorn epsilon 0.0\n",
      "Iteration  507\n",
      "Training: loss 4.610258102416992, covariance difference 1.0121285915374756\n",
      "Validation: loss 5.713109637360956, covariance difference 8.70979034451732, sinkhorn epsilon 0.0\n",
      "Iteration  508\n",
      "Training: loss 4.673429489135742, covariance difference 1.0248637199401855\n",
      "Validation: loss 5.613147180930433, covariance difference 8.363876334731849, sinkhorn epsilon 0.0\n",
      "Iteration  509\n",
      "Training: loss 4.573431015014648, covariance difference 1.0079879760742188\n",
      "Validation: loss 5.600694270815746, covariance difference 8.605542765635356, sinkhorn epsilon 0.0\n",
      "Iteration  510\n",
      "Training: loss 4.561015605926514, covariance difference 1.0036834478378296\n",
      "Validation: loss 5.661516293906067, covariance difference 8.680924837333327, sinkhorn epsilon 0.0\n",
      "Iteration  511\n",
      "Training: loss 4.621813774108887, covariance difference 1.0146652460098267\n",
      "Validation: loss 5.6428306818678795, covariance difference 8.6517983456381, sinkhorn epsilon 0.0\n",
      "Iteration  512\n",
      "Training: loss 4.603160858154297, covariance difference 1.010353446006775\n",
      "Validation: loss 5.621577727489129, covariance difference 8.673973854558838, sinkhorn epsilon 1.7465250758975608e-14\n",
      "Iteration  513\n",
      "Training: loss 4.581907272338867, covariance difference 1.0104347467422485\n",
      "Validation: loss 5.664135973015742, covariance difference 8.485193842215999, sinkhorn epsilon 0.0\n",
      "Iteration  514\n",
      "Training: loss 4.624454498291016, covariance difference 1.0181679725646973\n",
      "Validation: loss 5.689752078785851, covariance difference 8.593619471958146, sinkhorn epsilon 1.151081266984899e-15\n",
      "Iteration  515\n",
      "Training: loss 4.650094985961914, covariance difference 1.0197293758392334\n",
      "Validation: loss 5.613532550002325, covariance difference 8.6319358551749, sinkhorn epsilon 0.0\n",
      "Iteration  516\n",
      "Training: loss 4.573805809020996, covariance difference 1.0072021484375\n",
      "Validation: loss 5.6617756919139115, covariance difference 8.586482812477362, sinkhorn epsilon 0.0\n",
      "Iteration  517\n",
      "Training: loss 4.622095584869385, covariance difference 1.015272855758667\n",
      "Validation: loss 5.676458869696937, covariance difference 8.932233784737102, sinkhorn epsilon 0.0\n",
      "Iteration  518\n",
      "Training: loss 4.636733531951904, covariance difference 1.0180405378341675\n",
      "Validation: loss 5.616247301025977, covariance difference 8.66442571193763, sinkhorn epsilon 1.6402828591788785e-14\n",
      "Iteration  519\n",
      "Training: loss 4.576560020446777, covariance difference 1.0075507164001465\n",
      "Validation: loss 5.633775122292166, covariance difference 8.379802150154324, sinkhorn epsilon 0.0\n",
      "Iteration  520\n",
      "Training: loss 4.594109058380127, covariance difference 1.0098720788955688\n",
      "Validation: loss 5.669403719845881, covariance difference 8.784256687335496, sinkhorn epsilon 0.0\n",
      "Iteration  521\n",
      "Training: loss 4.629683017730713, covariance difference 1.0183244943618774\n",
      "Validation: loss 5.746412265132197, covariance difference 8.686051627842334, sinkhorn epsilon 0.0\n",
      "Iteration  522\n",
      "Training: loss 4.70668888092041, covariance difference 1.0334923267364502\n",
      "Validation: loss 5.656580238065997, covariance difference 8.607163239432195, sinkhorn epsilon 0.0\n",
      "Iteration  523\n",
      "Training: loss 4.616858005523682, covariance difference 1.0154485702514648\n",
      "Validation: loss 5.579369052545066, covariance difference 8.71834261168053, sinkhorn epsilon 0.0\n",
      "Iteration  524\n",
      "Training: loss 4.53968620300293, covariance difference 1.0004727840423584\n",
      "Validation: loss 5.621731758612568, covariance difference 8.5945822060002, sinkhorn epsilon 0.0\n",
      "Iteration  525\n",
      "Training: loss 4.582016944885254, covariance difference 1.0083892345428467\n",
      "Validation: loss 5.662137281941439, covariance difference 8.732675394425403, sinkhorn epsilon 0.0\n",
      "Iteration  526\n",
      "Training: loss 4.6224212646484375, covariance difference 1.0159459114074707\n",
      "Validation: loss 5.656962818513259, covariance difference 8.521299008326825, sinkhorn epsilon 0.0\n",
      "Iteration  527\n",
      "Training: loss 4.617262840270996, covariance difference 1.015055775642395\n",
      "Validation: loss 5.640300122474414, covariance difference 8.647003264946026, sinkhorn epsilon 0.0\n",
      "Iteration  528\n",
      "Training: loss 4.600581645965576, covariance difference 1.0113743543624878\n",
      "Validation: loss 5.694923854679046, covariance difference 8.604622122407477, sinkhorn epsilon 4.74444078108956e-14\n",
      "Iteration  529\n",
      "Training: loss 4.65526008605957, covariance difference 1.020300269126892\n",
      "Validation: loss 5.718899915902494, covariance difference 9.063919842808584, sinkhorn epsilon 0.0\n",
      "Iteration  530\n",
      "Training: loss 4.679244041442871, covariance difference 1.025761604309082\n",
      "Validation: loss 5.623163585469893, covariance difference 8.721096499574736, sinkhorn epsilon 0.0\n",
      "Iteration  531\n",
      "Training: loss 4.583504676818848, covariance difference 1.0075838565826416\n",
      "Validation: loss 5.651455186046725, covariance difference 8.480030504002594, sinkhorn epsilon 0.0\n",
      "Iteration  532\n",
      "Training: loss 4.611729621887207, covariance difference 1.0136080980300903\n",
      "Validation: loss 5.734517481764365, covariance difference 8.714442596845355, sinkhorn epsilon 0.0\n",
      "Iteration  533\n",
      "Training: loss 4.6948089599609375, covariance difference 1.0293736457824707\n",
      "Validation: loss 5.656238545740837, covariance difference 8.441582572424315, sinkhorn epsilon 0.0\n",
      "Iteration  534\n",
      "Training: loss 4.616509914398193, covariance difference 1.0151466131210327\n",
      "Validation: loss 5.643069527624638, covariance difference 8.513342619138664, sinkhorn epsilon 1.7353402179689277e-14\n",
      "Iteration  535\n",
      "Training: loss 4.60338830947876, covariance difference 1.0109397172927856\n",
      "Validation: loss 5.691202208631638, covariance difference 8.707903824659468, sinkhorn epsilon 0.0\n",
      "Iteration  536\n",
      "Training: loss 4.651518821716309, covariance difference 1.0206549167633057\n",
      "Validation: loss 5.6971087207205455, covariance difference 8.6790520880986, sinkhorn epsilon 4.307563888027537e-14\n",
      "Iteration  537\n",
      "Training: loss 4.657388687133789, covariance difference 1.0230364799499512\n",
      "Validation: loss 5.702460883225654, covariance difference 8.666642796359582, sinkhorn epsilon 0.0\n",
      "Iteration  538\n",
      "Training: loss 4.6627349853515625, covariance difference 1.0230321884155273\n",
      "Validation: loss 5.664231352823023, covariance difference 8.648068745722204, sinkhorn epsilon 0.0\n",
      "Iteration  539\n",
      "Training: loss 4.62450647354126, covariance difference 1.0167440176010132\n",
      "Validation: loss 5.623278859078671, covariance difference 8.426011812604928, sinkhorn epsilon 8.210900218621957e-14\n",
      "Iteration  540\n",
      "Training: loss 4.58355188369751, covariance difference 1.008684754371643\n",
      "Validation: loss 5.727626154131123, covariance difference 8.982225548731503, sinkhorn epsilon 0.0\n",
      "Iteration  541\n",
      "Training: loss 4.687943458557129, covariance difference 1.0270835161209106\n",
      "Validation: loss 5.653581573213417, covariance difference 8.692853618456017, sinkhorn epsilon 0.0\n",
      "Iteration  542\n",
      "Training: loss 4.613853931427002, covariance difference 1.0161206722259521\n",
      "Validation: loss 5.758701759648461, covariance difference 8.953989648899194, sinkhorn epsilon 0.0\n",
      "Iteration  543\n",
      "Training: loss 4.718974590301514, covariance difference 1.0323675870895386\n",
      "Validation: loss 5.626394338608442, covariance difference 8.663254951215421, sinkhorn epsilon 0.0\n",
      "Iteration  544\n",
      "Training: loss 4.586671829223633, covariance difference 1.0106256008148193\n",
      "Validation: loss 5.663392678459825, covariance difference 8.691932460180361, sinkhorn epsilon 0.0\n",
      "Iteration  545\n",
      "Training: loss 4.623684883117676, covariance difference 1.0159258842468262\n",
      "Validation: loss 5.673848446480431, covariance difference 8.76931765291155, sinkhorn epsilon 2.959688706757091e-14\n",
      "Iteration  546\n",
      "Training: loss 4.634133815765381, covariance difference 1.0189902782440186\n",
      "Validation: loss 5.733164305549868, covariance difference 8.659475969815515, sinkhorn epsilon 0.0\n",
      "Iteration  547\n",
      "Training: loss 4.693470001220703, covariance difference 1.0293468236923218\n",
      "Validation: loss 5.662339972779618, covariance difference 8.667566387933846, sinkhorn epsilon 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  548\n",
      "Training: loss 4.622625350952148, covariance difference 1.015315294265747\n",
      "Validation: loss 5.718545000259541, covariance difference 8.756841621122877, sinkhorn epsilon 1.9403103940978842e-14\n",
      "Iteration  549\n",
      "Training: loss 4.678881645202637, covariance difference 1.0254535675048828\n",
      "Validation: loss 5.618414321028862, covariance difference 8.489007717441478, sinkhorn epsilon 2.7755575615628914e-16\n",
      "Iteration  550\n",
      "Training: loss 4.578693389892578, covariance difference 1.0080944299697876\n",
      "Validation: loss 5.682071824480224, covariance difference 8.699044007700392, sinkhorn epsilon 0.0\n",
      "Iteration  551\n",
      "Training: loss 4.642379283905029, covariance difference 1.0197913646697998\n",
      "Validation: loss 5.648935943675383, covariance difference 8.50240321480629, sinkhorn epsilon 0.0\n",
      "Iteration  552\n",
      "Training: loss 4.609225749969482, covariance difference 1.0139063596725464\n",
      "Validation: loss 5.7037929541307975, covariance difference 8.841863620880117, sinkhorn epsilon 0.0\n",
      "Iteration  553\n",
      "Training: loss 4.664104461669922, covariance difference 1.0241585969924927\n",
      "Validation: loss 5.657992521538096, covariance difference 8.732364554619528, sinkhorn epsilon 0.0\n",
      "Iteration  554\n",
      "Training: loss 4.618329048156738, covariance difference 1.014375925064087\n",
      "Validation: loss 5.654887105823991, covariance difference 8.66797878049362, sinkhorn epsilon 0.0\n",
      "Iteration  555\n",
      "Training: loss 4.6151838302612305, covariance difference 1.0152267217636108\n",
      "Validation: loss 5.792446452148322, covariance difference 8.903185419188175, sinkhorn epsilon 0.0\n",
      "Iteration  556\n",
      "Training: loss 4.752728462219238, covariance difference 1.0386488437652588\n",
      "Validation: loss 5.714268857014137, covariance difference 8.761992400971069, sinkhorn epsilon 0.0\n",
      "Iteration  557\n",
      "Training: loss 4.6745991706848145, covariance difference 1.0250229835510254\n",
      "Validation: loss 5.576549837101925, covariance difference 8.586687490141939, sinkhorn epsilon 0.0\n",
      "Iteration  558\n",
      "Training: loss 4.536830902099609, covariance difference 0.9997863173484802\n",
      "Validation: loss 5.668158419779179, covariance difference 8.3152533423626, sinkhorn epsilon 0.0\n",
      "Iteration  559\n",
      "Training: loss 4.628448009490967, covariance difference 1.0170503854751587\n",
      "Validation: loss 5.580839826550458, covariance difference 8.431245634351944, sinkhorn epsilon 0.0\n",
      "Iteration  560\n",
      "Training: loss 4.541150093078613, covariance difference 0.999269425868988\n",
      "Validation: loss 5.605359457382915, covariance difference 8.31260366379594, sinkhorn epsilon 3.953211181638e-14\n",
      "Iteration  561\n",
      "Training: loss 4.565637588500977, covariance difference 1.0040651559829712\n",
      "Validation: loss 5.696931186665034, covariance difference 8.626814430485373, sinkhorn epsilon 4.469690957826467e-14\n",
      "Iteration  562\n",
      "Training: loss 4.6572136878967285, covariance difference 1.0220890045166016\n",
      "Validation: loss 5.665399396155734, covariance difference 8.60195717214916, sinkhorn epsilon 0.0\n",
      "Iteration  563\n",
      "Training: loss 4.625695705413818, covariance difference 1.0178312063217163\n",
      "Validation: loss 5.623033668597641, covariance difference 8.725301125501426, sinkhorn epsilon 2.5955264008157306e-14\n",
      "Iteration  564\n",
      "Training: loss 4.583305835723877, covariance difference 1.0122050046920776\n",
      "Validation: loss 5.697552262248351, covariance difference 8.680943297550774, sinkhorn epsilon 0.0\n",
      "Iteration  565\n",
      "Training: loss 4.657864093780518, covariance difference 1.0221842527389526\n",
      "Validation: loss 5.662350912326067, covariance difference 8.457146170082538, sinkhorn epsilon 0.0\n",
      "Iteration  566\n",
      "Training: loss 4.622621059417725, covariance difference 1.0154588222503662\n",
      "Validation: loss 5.570985175156185, covariance difference 8.47334455874646, sinkhorn epsilon 0.0\n",
      "Iteration  567\n",
      "Training: loss 4.531266689300537, covariance difference 1.0025978088378906\n",
      "Validation: loss 5.6956015356951575, covariance difference 8.578314051009075, sinkhorn epsilon 9.185147794273239e-14\n",
      "Iteration  568\n",
      "Training: loss 4.655917644500732, covariance difference 1.02144455909729\n",
      "Validation: loss 5.636824555018925, covariance difference 8.25946714200432, sinkhorn epsilon 0.0\n",
      "Iteration  569\n",
      "Training: loss 4.597100257873535, covariance difference 1.0097075700759888\n",
      "Validation: loss 5.6307587209028735, covariance difference 8.622098352220139, sinkhorn epsilon 1.9188669329063413e-14\n",
      "Iteration  570\n",
      "Training: loss 4.59109354019165, covariance difference 1.010367751121521\n",
      "Validation: loss 5.646838787917462, covariance difference 8.565608397559059, sinkhorn epsilon 0.0\n",
      "Iteration  571\n",
      "Training: loss 4.607110977172852, covariance difference 1.015140414237976\n",
      "Validation: loss 5.610486210954577, covariance difference 8.642282179030406, sinkhorn epsilon 0.0\n",
      "Iteration  572\n",
      "Training: loss 4.570761203765869, covariance difference 1.0061570405960083\n",
      "Validation: loss 5.6577954913224655, covariance difference 8.739379512009728, sinkhorn epsilon 1.644008225210687e-14\n",
      "Iteration  573\n",
      "Training: loss 4.618079662322998, covariance difference 1.0157426595687866\n",
      "Validation: loss 5.634222419617539, covariance difference 8.56468852486021, sinkhorn epsilon 1.5434849077327246e-14\n",
      "Iteration  574\n",
      "Training: loss 4.594512462615967, covariance difference 1.0096476078033447\n",
      "Validation: loss 5.699229672301842, covariance difference 8.646177812747343, sinkhorn epsilon 0.0\n",
      "Iteration  575\n",
      "Training: loss 4.659503936767578, covariance difference 1.024422287940979\n",
      "Validation: loss 5.619188357840406, covariance difference 8.608205195104086, sinkhorn epsilon 0.0\n",
      "Iteration  576\n",
      "Training: loss 4.579468250274658, covariance difference 1.0085322856903076\n",
      "Validation: loss 5.643081808738032, covariance difference 8.445140755611938, sinkhorn epsilon 2.220446049250313e-16\n",
      "Iteration  577\n",
      "Training: loss 4.603379726409912, covariance difference 1.01304292678833\n",
      "Validation: loss 5.595714986822266, covariance difference 8.503014578873723, sinkhorn epsilon 0.0\n",
      "Iteration  578\n",
      "Training: loss 4.556004047393799, covariance difference 1.0050632953643799\n",
      "Validation: loss 5.647841642278539, covariance difference 8.722701731763378, sinkhorn epsilon 4.347108778700795e-14\n",
      "Iteration  579\n",
      "Training: loss 4.608156681060791, covariance difference 1.0145448446273804\n",
      "Validation: loss 5.582546095460961, covariance difference 8.462108024000816, sinkhorn epsilon 0.0\n",
      "Iteration  580\n",
      "Training: loss 4.542829990386963, covariance difference 1.0025027990341187\n",
      "Validation: loss 5.657996030917197, covariance difference 8.754652529870626, sinkhorn epsilon 0.0\n",
      "Iteration  581\n",
      "Training: loss 4.618322372436523, covariance difference 1.0147472620010376\n",
      "Validation: loss 5.663597989290536, covariance difference 8.758527929846812, sinkhorn epsilon 0.0\n",
      "Iteration  582\n",
      "Training: loss 4.623920917510986, covariance difference 1.017580509185791\n",
      "Validation: loss 5.738437432281527, covariance difference 8.542159261171522, sinkhorn epsilon 0.0\n",
      "Iteration  583\n",
      "Training: loss 4.698737144470215, covariance difference 1.0297197103500366\n",
      "Validation: loss 5.667909091752164, covariance difference 8.681157291206587, sinkhorn epsilon 0.0\n",
      "Iteration  584\n",
      "Training: loss 4.628204345703125, covariance difference 1.0175800323486328\n",
      "Validation: loss 5.680607483696559, covariance difference 8.635761865173944, sinkhorn epsilon 0.0\n",
      "Iteration  585\n",
      "Training: loss 4.640917778015137, covariance difference 1.0186915397644043\n",
      "Validation: loss 5.58350447242595, covariance difference 8.462340514093507, sinkhorn epsilon 3.398923087244636e-14\n",
      "Iteration  586\n",
      "Training: loss 4.543816566467285, covariance difference 1.0021008253097534\n",
      "Validation: loss 5.6472230823940865, covariance difference 8.630069320932336, sinkhorn epsilon 0.0\n",
      "Iteration  587\n",
      "Training: loss 4.607501029968262, covariance difference 1.0139487981796265\n",
      "Validation: loss 5.572799069651185, covariance difference 8.472307794284266, sinkhorn epsilon 0.0\n",
      "Iteration  588\n",
      "Training: loss 4.5330729484558105, covariance difference 1.0011241436004639\n",
      "Validation: loss 5.700074555233249, covariance difference 8.537012950552484, sinkhorn epsilon 0.0\n",
      "Iteration  589\n",
      "Training: loss 4.66035270690918, covariance difference 1.0214780569076538\n",
      "Validation: loss 5.6654767651194575, covariance difference 8.835510413925634, sinkhorn epsilon 4.0509813608705204e-14\n",
      "Iteration  590\n",
      "Training: loss 4.625752925872803, covariance difference 1.0163906812667847\n",
      "Validation: loss 5.684273571356698, covariance difference 8.718743095362068, sinkhorn epsilon 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  591\n",
      "Training: loss 4.644547462463379, covariance difference 1.020066499710083\n",
      "Validation: loss 5.607548423641105, covariance difference 8.535403497014173, sinkhorn epsilon 0.0\n",
      "Iteration  592\n",
      "Training: loss 4.567818641662598, covariance difference 1.0061454772949219\n",
      "Validation: loss 5.693768827505476, covariance difference 8.692009140345114, sinkhorn epsilon 0.0\n",
      "Iteration  593\n",
      "Training: loss 4.654041290283203, covariance difference 1.020741581916809\n",
      "Validation: loss 5.664134757219619, covariance difference 8.392552415955748, sinkhorn epsilon 0.0\n",
      "Iteration  594\n",
      "Training: loss 4.624410629272461, covariance difference 1.0197947025299072\n",
      "Validation: loss 5.652229337606033, covariance difference 8.503686814890486, sinkhorn epsilon 0.0\n",
      "Iteration  595\n",
      "Training: loss 4.612526893615723, covariance difference 1.0102659463882446\n",
      "Validation: loss 5.672295268028156, covariance difference 8.740303688812844, sinkhorn epsilon 0.0\n",
      "Iteration  596\n",
      "Training: loss 4.632616996765137, covariance difference 1.0189390182495117\n",
      "Validation: loss 5.6254626469598215, covariance difference 8.554203267480005, sinkhorn epsilon 0.0\n",
      "Iteration  597\n",
      "Training: loss 4.585747241973877, covariance difference 1.010066270828247\n",
      "Validation: loss 5.559130226142174, covariance difference 8.332574985512148, sinkhorn epsilon 0.0\n",
      "Iteration  598\n",
      "Training: loss 4.519420623779297, covariance difference 0.9976120591163635\n",
      "Validation: loss 5.753173339348108, covariance difference 8.89788229173279, sinkhorn epsilon 0.0\n",
      "Iteration  599\n",
      "Training: loss 4.713463306427002, covariance difference 1.0315794944763184\n",
      "Validation: loss 5.636523690808262, covariance difference 8.434961079026133, sinkhorn epsilon 0.0\n",
      "Iteration  600\n",
      "Training: loss 4.596802711486816, covariance difference 1.0111091136932373\n",
      "Validation: loss 5.683170185946297, covariance difference 8.756256141816017, sinkhorn epsilon 0.0\n",
      "Iteration  601\n",
      "Training: loss 4.643447399139404, covariance difference 1.0198029279708862\n",
      "Validation: loss 5.6820685120985495, covariance difference 8.593925639292829, sinkhorn epsilon 0.0\n",
      "Iteration  602\n",
      "Training: loss 4.6423492431640625, covariance difference 1.0183292627334595\n",
      "Validation: loss 5.6440381645586255, covariance difference 8.518302663640961, sinkhorn epsilon 0.0\n",
      "Iteration  603\n",
      "Training: loss 4.60437536239624, covariance difference 1.0128905773162842\n",
      "Validation: loss 5.705237570711311, covariance difference 8.804318426829607, sinkhorn epsilon 0.0\n",
      "Iteration  604\n",
      "Training: loss 4.665584087371826, covariance difference 1.0232365131378174\n",
      "Validation: loss 5.639290716494023, covariance difference 8.532230787064016, sinkhorn epsilon 6.937856468060774e-14\n",
      "Iteration  605\n",
      "Training: loss 4.599564552307129, covariance difference 1.0125181674957275\n",
      "Validation: loss 5.6841687454751275, covariance difference 8.527092073966296, sinkhorn epsilon 0.0\n",
      "Iteration  606\n",
      "Training: loss 4.644441604614258, covariance difference 1.018786072731018\n",
      "Validation: loss 5.628932232439225, covariance difference 8.57451613764847, sinkhorn epsilon 0.0\n",
      "Iteration  607\n",
      "Training: loss 4.589212894439697, covariance difference 1.0099718570709229\n",
      "Validation: loss 5.753567863966364, covariance difference 8.550055686693526, sinkhorn epsilon 6.294503699287743e-15\n",
      "Iteration  608\n",
      "Training: loss 4.713911056518555, covariance difference 1.0333548784255981\n",
      "Validation: loss 5.639226364604381, covariance difference 8.707907288815884, sinkhorn epsilon 0.0\n",
      "Iteration  609\n",
      "Training: loss 4.599501132965088, covariance difference 1.010524034500122\n",
      "Validation: loss 5.6383836255715085, covariance difference 8.580872839161573, sinkhorn epsilon 0.0\n",
      "Iteration  610\n",
      "Training: loss 4.598662376403809, covariance difference 1.0124709606170654\n",
      "Validation: loss 5.584458286667946, covariance difference 8.524483968088383, sinkhorn epsilon 0.0\n",
      "Iteration  611\n",
      "Training: loss 4.544763088226318, covariance difference 1.001814842224121\n",
      "Validation: loss 5.690040434219028, covariance difference 8.554847799489838, sinkhorn epsilon 0.0\n",
      "Iteration  612\n",
      "Training: loss 4.65032958984375, covariance difference 1.0199753046035767\n",
      "Validation: loss 5.6494004997361795, covariance difference 8.489927994231094, sinkhorn epsilon 0.0\n",
      "Iteration  613\n",
      "Training: loss 4.609683990478516, covariance difference 1.0144093036651611\n",
      "Validation: loss 5.603442765978672, covariance difference 8.492064227777224, sinkhorn epsilon 0.0\n",
      "Iteration  614\n",
      "Training: loss 4.563712120056152, covariance difference 1.0041488409042358\n",
      "Validation: loss 5.590753160816234, covariance difference 8.628878464041266, sinkhorn epsilon 5.5393668508917293e-14\n",
      "Iteration  615\n",
      "Training: loss 4.551079273223877, covariance difference 1.0036648511886597\n",
      "Validation: loss 5.673973234481261, covariance difference 8.695319972388488, sinkhorn epsilon 0.0\n",
      "Iteration  616\n",
      "Training: loss 4.634250640869141, covariance difference 1.0161542892456055\n",
      "Validation: loss 5.6373499408004, covariance difference 8.698117752677723, sinkhorn epsilon 0.0\n",
      "Iteration  617\n",
      "Training: loss 4.597635746002197, covariance difference 1.0120726823806763\n",
      "Validation: loss 5.644369095586613, covariance difference 8.447296759645203, sinkhorn epsilon 4.8223693844721225e-14\n",
      "Iteration  618\n",
      "Training: loss 4.604689598083496, covariance difference 1.011145830154419\n",
      "Validation: loss 5.622455470677509, covariance difference 8.432984565497879, sinkhorn epsilon 4.885900829039739e-15\n",
      "Iteration  619\n",
      "Training: loss 4.582730293273926, covariance difference 1.007834553718567\n",
      "Validation: loss 5.633990275655835, covariance difference 8.706438003011566, sinkhorn epsilon 0.0\n",
      "Iteration  620\n",
      "Training: loss 4.594274044036865, covariance difference 1.0111101865768433\n",
      "Validation: loss 5.626823201295416, covariance difference 8.756727337141898, sinkhorn epsilon 0.0\n",
      "Iteration  621\n",
      "Training: loss 4.587100028991699, covariance difference 1.0107612609863281\n",
      "Validation: loss 5.694370347331726, covariance difference 8.58931569560537, sinkhorn epsilon 3.0525539139097987e-14\n",
      "Iteration  622\n",
      "Training: loss 4.654676914215088, covariance difference 1.0204232931137085\n",
      "Validation: loss 5.656458000519686, covariance difference 8.66104966936736, sinkhorn epsilon 0.0\n",
      "Iteration  623\n",
      "Training: loss 4.616730690002441, covariance difference 1.014029860496521\n",
      "Validation: loss 5.608628716506025, covariance difference 8.532266317436664, sinkhorn epsilon 0.0\n",
      "Iteration  624\n",
      "Training: loss 4.568932056427002, covariance difference 1.0059362649917603\n",
      "Validation: loss 5.610562031621491, covariance difference 8.391055260769399, sinkhorn epsilon 0.0\n",
      "Iteration  625\n",
      "Training: loss 4.570843696594238, covariance difference 1.0077482461929321\n",
      "Validation: loss 5.612993074720615, covariance difference 8.546080645526121, sinkhorn epsilon 3.750839532936221e-14\n",
      "Iteration  626\n",
      "Training: loss 4.573266506195068, covariance difference 1.0067278146743774\n",
      "Validation: loss 5.6447986902531255, covariance difference 8.678605027916444, sinkhorn epsilon 0.0\n",
      "Iteration  627\n",
      "Training: loss 4.605085372924805, covariance difference 1.0125616788864136\n",
      "Validation: loss 5.694093339434517, covariance difference 8.753304234249505, sinkhorn epsilon 0.0\n",
      "Iteration  628\n",
      "Training: loss 4.654417514801025, covariance difference 1.0238168239593506\n",
      "Validation: loss 5.637316478300683, covariance difference 8.470280705992037, sinkhorn epsilon 0.0\n",
      "Iteration  629\n",
      "Training: loss 4.597609996795654, covariance difference 1.0112425088882446\n",
      "Validation: loss 5.610092526559109, covariance difference 8.463378234592813, sinkhorn epsilon 0.0\n",
      "Iteration  630\n",
      "Training: loss 4.5704240798950195, covariance difference 1.006700038909912\n",
      "Validation: loss 5.662325868513984, covariance difference 8.602304019491378, sinkhorn epsilon 0.0\n",
      "Iteration  631\n",
      "Training: loss 4.622654914855957, covariance difference 1.018152117729187\n",
      "Validation: loss 5.6871094124568655, covariance difference 8.556731488263008, sinkhorn epsilon 0.0\n",
      "Iteration  632\n",
      "Training: loss 4.647380828857422, covariance difference 1.0213614702224731\n",
      "Validation: loss 5.680711350020274, covariance difference 8.579621334901773, sinkhorn epsilon 0.0\n",
      "Iteration  633\n",
      "Training: loss 4.641000747680664, covariance difference 1.0198028087615967\n",
      "Validation: loss 5.702519339755624, covariance difference 8.633746203694828, sinkhorn epsilon 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  634\n",
      "Training: loss 4.662838935852051, covariance difference 1.0224896669387817\n",
      "Validation: loss 5.65793251115006, covariance difference 8.489466766056559, sinkhorn epsilon 6.786623833034424e-14\n",
      "Iteration  635\n",
      "Training: loss 4.618200778961182, covariance difference 1.0153669118881226\n",
      "Validation: loss 5.645265026936673, covariance difference 8.653193007894714, sinkhorn epsilon 0.0\n",
      "Iteration  636\n",
      "Training: loss 4.605588436126709, covariance difference 1.0121148824691772\n",
      "Validation: loss 5.588026652120675, covariance difference 8.87560630814199, sinkhorn epsilon 3.982691198160024e-15\n",
      "Iteration  637\n",
      "Training: loss 4.548305988311768, covariance difference 1.0046846866607666\n",
      "Validation: loss 5.531289339878679, covariance difference 8.369632822454488, sinkhorn epsilon 0.0\n",
      "Iteration  638\n",
      "Training: loss 4.491608142852783, covariance difference 0.9918979406356812\n",
      "Validation: loss 5.666717929306085, covariance difference 8.613922415291121, sinkhorn epsilon 5.1982670611394335e-15\n",
      "Iteration  639\n",
      "Training: loss 4.626993656158447, covariance difference 1.0157454013824463\n",
      "Validation: loss 5.664863508431443, covariance difference 8.615024242514435, sinkhorn epsilon 0.0\n",
      "Iteration  640\n",
      "Training: loss 4.625151634216309, covariance difference 1.0169264078140259\n",
      "Validation: loss 5.598405087543753, covariance difference 8.744140931669596, sinkhorn epsilon 4.4360666312292204e-14\n",
      "Iteration  641\n",
      "Training: loss 4.558676719665527, covariance difference 1.004136562347412\n",
      "Validation: loss 5.625590182837412, covariance difference 8.66431624023092, sinkhorn epsilon 0.0\n",
      "Iteration  642\n",
      "Training: loss 4.585962772369385, covariance difference 1.010370135307312\n",
      "Validation: loss 5.680928522747967, covariance difference 8.632995269865848, sinkhorn epsilon 1.8080110753130428e-14\n",
      "Iteration  643\n",
      "Training: loss 4.641213417053223, covariance difference 1.018103837966919\n",
      "Validation: loss 5.631401962250315, covariance difference 8.678340304960777, sinkhorn epsilon 0.0\n",
      "Iteration  644\n",
      "Training: loss 4.591676712036133, covariance difference 1.0105396509170532\n",
      "Validation: loss 5.640026659642197, covariance difference 8.62381916909732, sinkhorn epsilon 0.0\n",
      "Iteration  645\n",
      "Training: loss 4.600306510925293, covariance difference 1.0126181840896606\n",
      "Validation: loss 5.578206601969072, covariance difference 8.620034656579207, sinkhorn epsilon 0.0\n",
      "Iteration  646\n",
      "Training: loss 4.538485527038574, covariance difference 1.0001908540725708\n",
      "Validation: loss 5.632430837088712, covariance difference 8.647393804802677, sinkhorn epsilon 0.0\n",
      "Iteration  647\n",
      "Training: loss 4.5927414894104, covariance difference 1.0113489627838135\n",
      "Validation: loss 5.551704276983881, covariance difference 8.579259202796267, sinkhorn epsilon 0.0\n",
      "Iteration  648\n",
      "Training: loss 4.5120015144348145, covariance difference 0.9971648454666138\n",
      "Validation: loss 5.6551792374287295, covariance difference 8.408502361979922, sinkhorn epsilon 0.0\n",
      "Iteration  649\n",
      "Training: loss 4.615455627441406, covariance difference 1.0152095556259155\n",
      "Validation: loss 5.640597545989305, covariance difference 8.579379342192219, sinkhorn epsilon 0.0\n",
      "Iteration  650\n",
      "Training: loss 4.600873947143555, covariance difference 1.0117229223251343\n",
      "Validation: loss 5.672267431057522, covariance difference 8.631994811560478, sinkhorn epsilon 0.0\n",
      "Iteration  651\n",
      "Training: loss 4.632537841796875, covariance difference 1.018577218055725\n",
      "Validation: loss 5.600268122326091, covariance difference 8.44634149157529, sinkhorn epsilon 4.149690368774224e-14\n",
      "Iteration  652\n",
      "Training: loss 4.5605387687683105, covariance difference 1.0067030191421509\n",
      "Validation: loss 5.5495693824184436, covariance difference 8.508031309028466, sinkhorn epsilon 0.0\n",
      "Iteration  653\n",
      "Training: loss 4.509852409362793, covariance difference 0.9959970712661743\n",
      "Validation: loss 5.7613508324219485, covariance difference 8.721952044835438, sinkhorn epsilon 0.0\n",
      "Iteration  654\n",
      "Training: loss 4.721683979034424, covariance difference 1.0331273078918457\n",
      "Validation: loss 5.659550651199722, covariance difference 8.697030149175756, sinkhorn epsilon 0.0\n",
      "Iteration  655\n",
      "Training: loss 4.619829177856445, covariance difference 1.0172096490859985\n",
      "Validation: loss 5.654591459296879, covariance difference 8.265720248715924, sinkhorn epsilon 0.0\n",
      "Iteration  656\n",
      "Training: loss 4.614877700805664, covariance difference 1.0141383409500122\n",
      "Validation: loss 5.604281577650472, covariance difference 8.531721693016454, sinkhorn epsilon 0.0\n",
      "Iteration  657\n",
      "Training: loss 4.564558029174805, covariance difference 1.0053590536117554\n",
      "Validation: loss 5.626964825051474, covariance difference 8.708256045212686, sinkhorn epsilon 0.0\n",
      "Iteration  658\n",
      "Training: loss 4.587244033813477, covariance difference 1.0089737176895142\n",
      "Validation: loss 5.682311061129461, covariance difference 8.675722381168017, sinkhorn epsilon 0.0\n",
      "Iteration  659\n",
      "Training: loss 4.642620086669922, covariance difference 1.0216431617736816\n",
      "Validation: loss 5.673566876906365, covariance difference 8.559257416751901, sinkhorn epsilon 1.6607272161164375e-14\n",
      "Iteration  660\n",
      "Training: loss 4.633833408355713, covariance difference 1.0199788808822632\n",
      "Validation: loss 5.595709319897376, covariance difference 8.594589510550186, sinkhorn epsilon 0.0\n",
      "Iteration  661\n",
      "Training: loss 4.555988788604736, covariance difference 1.005197525024414\n",
      "Validation: loss 5.7234280873847245, covariance difference 8.645712663783748, sinkhorn epsilon 0.0\n",
      "Iteration  662\n",
      "Training: loss 4.6836981773376465, covariance difference 1.025863528251648\n",
      "Validation: loss 5.7039123910547485, covariance difference 8.886457404691269, sinkhorn epsilon 0.0\n",
      "Iteration  663\n",
      "Training: loss 4.664198875427246, covariance difference 1.0227910280227661\n",
      "Validation: loss 5.694162360612154, covariance difference 8.636692930569273, sinkhorn epsilon 0.0\n",
      "Iteration  664\n",
      "Training: loss 4.654432773590088, covariance difference 1.0227891206741333\n",
      "Validation: loss 5.579063033817289, covariance difference 8.277405981834852, sinkhorn epsilon 0.0\n",
      "Iteration  665\n",
      "Training: loss 4.539340496063232, covariance difference 1.0013619661331177\n",
      "Validation: loss 5.667444394156993, covariance difference 8.712359030453301, sinkhorn epsilon 0.0\n",
      "Iteration  666\n",
      "Training: loss 4.627730846405029, covariance difference 1.0166181325912476\n",
      "Validation: loss 5.727738492029062, covariance difference 8.961341068782097, sinkhorn epsilon 0.0\n",
      "Iteration  667\n",
      "Training: loss 4.688027381896973, covariance difference 1.0272542238235474\n",
      "Validation: loss 5.597608909970175, covariance difference 8.43217818614586, sinkhorn epsilon 0.0\n",
      "Iteration  668\n",
      "Training: loss 4.55789852142334, covariance difference 1.0045647621154785\n",
      "Validation: loss 5.691378716007362, covariance difference 8.603816973630147, sinkhorn epsilon 0.0\n",
      "Iteration  669\n",
      "Training: loss 4.65164852142334, covariance difference 1.0211118459701538\n",
      "Validation: loss 5.655144985863395, covariance difference 8.848303882842819, sinkhorn epsilon 3.551323549815541e-14\n",
      "Iteration  670\n",
      "Training: loss 4.615419387817383, covariance difference 1.0150245428085327\n",
      "Validation: loss 5.621131707670572, covariance difference 8.50620560522127, sinkhorn epsilon 0.0\n",
      "Iteration  671\n",
      "Training: loss 4.581407070159912, covariance difference 1.0075842142105103\n",
      "Validation: loss 5.6729721340829995, covariance difference 8.487518167660793, sinkhorn epsilon 0.0\n",
      "Iteration  672\n",
      "Training: loss 4.633262634277344, covariance difference 1.0190540552139282\n",
      "Validation: loss 5.666697801190946, covariance difference 8.729141276441268, sinkhorn epsilon 0.0\n",
      "Iteration  673\n",
      "Training: loss 4.6269707679748535, covariance difference 1.015336036682129\n",
      "Validation: loss 5.611403419275179, covariance difference 8.46851868297848, sinkhorn epsilon 0.0\n",
      "Iteration  674\n",
      "Training: loss 4.571719169616699, covariance difference 1.008047342300415\n",
      "Validation: loss 5.6402347522850365, covariance difference 8.68992765018679, sinkhorn epsilon 0.0\n",
      "Iteration  675\n",
      "Training: loss 4.600522994995117, covariance difference 1.0104845762252808\n",
      "Validation: loss 5.688812804099139, covariance difference 8.498113607641832, sinkhorn epsilon 0.0\n",
      "Iteration  676\n",
      "Training: loss 4.649089336395264, covariance difference 1.0199205875396729\n",
      "Validation: loss 5.750519119541817, covariance difference 8.830806947180564, sinkhorn epsilon 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  677\n",
      "Training: loss 4.71079158782959, covariance difference 1.0335195064544678\n",
      "Validation: loss 5.5877938237111895, covariance difference 8.617967904283434, sinkhorn epsilon 0.0\n",
      "Iteration  678\n",
      "Training: loss 4.548069000244141, covariance difference 1.0023391246795654\n",
      "Validation: loss 5.634497502016245, covariance difference 8.692365940944084, sinkhorn epsilon 0.0\n",
      "Iteration  679\n",
      "Training: loss 4.5947723388671875, covariance difference 1.0088133811950684\n",
      "Validation: loss 5.677589618476334, covariance difference 8.67566282506595, sinkhorn epsilon 0.0\n",
      "Iteration  680\n",
      "Training: loss 4.637866020202637, covariance difference 1.0179439783096313\n",
      "Validation: loss 5.652958114610573, covariance difference 8.64565542210968, sinkhorn epsilon 0.0\n",
      "Iteration  681\n",
      "Training: loss 4.613238334655762, covariance difference 1.013990879058838\n",
      "Validation: loss 5.724999399593418, covariance difference 9.070997798398805, sinkhorn epsilon 0.0\n",
      "Iteration  682\n",
      "Training: loss 4.685274124145508, covariance difference 1.027980923652649\n",
      "Validation: loss 5.621560473498851, covariance difference 8.83814056416489, sinkhorn epsilon 0.0\n",
      "Iteration  683\n",
      "Training: loss 4.581846237182617, covariance difference 1.0071231126785278\n",
      "Validation: loss 5.635113231475709, covariance difference 8.56030189151423, sinkhorn epsilon 2.911615365377975e-14\n",
      "Iteration  684\n",
      "Training: loss 4.595395088195801, covariance difference 1.0111116170883179\n",
      "Validation: loss 5.699180013493214, covariance difference 8.74108636870272, sinkhorn epsilon 0.0\n",
      "Iteration  685\n",
      "Training: loss 4.659451484680176, covariance difference 1.021008014678955\n",
      "Validation: loss 5.675736242656301, covariance difference 8.663899902594455, sinkhorn epsilon 0.0\n",
      "Iteration  686\n",
      "Training: loss 4.636008262634277, covariance difference 1.0193983316421509\n",
      "Validation: loss 5.67520215800255, covariance difference 8.605876592727633, sinkhorn epsilon 0.0\n",
      "Iteration  687\n",
      "Training: loss 4.635480880737305, covariance difference 1.01933753490448\n",
      "Validation: loss 5.686485185979415, covariance difference 8.542911883936325, sinkhorn epsilon 0.0\n",
      "Iteration  688\n",
      "Training: loss 4.646759033203125, covariance difference 1.01873779296875\n",
      "Validation: loss 5.70784278785942, covariance difference 8.621599523647621, sinkhorn epsilon 0.0\n",
      "Iteration  689\n",
      "Training: loss 4.66811466217041, covariance difference 1.0236471891403198\n",
      "Validation: loss 5.725368588125406, covariance difference 8.640189026773452, sinkhorn epsilon 0.0\n",
      "Iteration  690\n",
      "Training: loss 4.6856369972229, covariance difference 1.0274323225021362\n",
      "Validation: loss 5.676709113724346, covariance difference 8.67356044952037, sinkhorn epsilon 8.668392783883347e-14\n",
      "Iteration  691\n",
      "Training: loss 4.6370439529418945, covariance difference 1.01934814453125\n",
      "Validation: loss 5.6385938010530365, covariance difference 8.812262593973559, sinkhorn epsilon 0.0\n",
      "Iteration  692\n",
      "Training: loss 4.598905086517334, covariance difference 1.0117367506027222\n",
      "Validation: loss 5.67237431356101, covariance difference 8.68104203362579, sinkhorn epsilon 0.0\n",
      "Iteration  693\n",
      "Training: loss 4.6326446533203125, covariance difference 1.0172357559204102\n",
      "Validation: loss 5.615880652299566, covariance difference 8.669139101018521, sinkhorn epsilon 0.0\n",
      "Iteration  694\n",
      "Training: loss 4.576170444488525, covariance difference 1.005196213722229\n",
      "Validation: loss 5.6650867908280365, covariance difference 8.589535471494518, sinkhorn epsilon 0.0\n",
      "Iteration  695\n",
      "Training: loss 4.625368118286133, covariance difference 1.0179256200790405\n",
      "Validation: loss 5.648520428014856, covariance difference 8.801490145335203, sinkhorn epsilon 0.0\n",
      "Iteration  696\n",
      "Training: loss 4.608789443969727, covariance difference 1.0132592916488647\n",
      "Validation: loss 5.66190006714776, covariance difference 8.518799116673977, sinkhorn epsilon 0.0\n",
      "Iteration  697\n",
      "Training: loss 4.622168064117432, covariance difference 1.0164077281951904\n",
      "Validation: loss 5.7555091905698115, covariance difference 8.817580435663439, sinkhorn epsilon 0.0\n",
      "Iteration  698\n",
      "Training: loss 4.715782165527344, covariance difference 1.0323318243026733\n",
      "Validation: loss 5.624626960313076, covariance difference 8.675841037421312, sinkhorn epsilon 1.6851911087919604e-14\n",
      "Iteration  699\n",
      "Training: loss 4.584912300109863, covariance difference 1.0084284543991089\n",
      "Validation: loss 5.635726671695003, covariance difference 8.337707286008401, sinkhorn epsilon 0.0\n",
      "Iteration  700\n",
      "Training: loss 4.596011161804199, covariance difference 1.010367751121521\n",
      "Validation: loss 5.6615215445515865, covariance difference 8.775008714277678, sinkhorn epsilon 3.257246982380821e-14\n",
      "Iteration  701\n",
      "Training: loss 4.621795177459717, covariance difference 1.015696406364441\n",
      "Validation: loss 5.558328772784152, covariance difference 8.493777069190827, sinkhorn epsilon 3.371110232248057e-14\n",
      "Iteration  702\n",
      "Training: loss 4.518606185913086, covariance difference 0.9970285892486572\n",
      "Validation: loss 5.623759799191024, covariance difference 8.6707944939692, sinkhorn epsilon 0.0\n",
      "Iteration  703\n",
      "Training: loss 4.584043502807617, covariance difference 1.009761929512024\n",
      "Validation: loss 5.681426877213738, covariance difference 8.566097084297091, sinkhorn epsilon 0.0\n",
      "Iteration  704\n",
      "Training: loss 4.641716957092285, covariance difference 1.020209789276123\n",
      "Validation: loss 5.613046567629363, covariance difference 8.442331089307157, sinkhorn epsilon 8.750686208398956e-15\n",
      "Iteration  705\n",
      "Training: loss 4.573406219482422, covariance difference 1.0067470073699951\n",
      "Validation: loss 5.61580388974374, covariance difference 8.551800126124165, sinkhorn epsilon 0.0\n",
      "Iteration  706\n",
      "Training: loss 4.576132774353027, covariance difference 1.0071038007736206\n",
      "Validation: loss 5.649471344568981, covariance difference 8.472620172765486, sinkhorn epsilon 2.2464599743910357e-14\n",
      "Iteration  707\n",
      "Training: loss 4.609772682189941, covariance difference 1.0144221782684326\n",
      "Validation: loss 5.644675026458092, covariance difference 8.631940901632174, sinkhorn epsilon 0.0\n",
      "Iteration  708\n",
      "Training: loss 4.604955673217773, covariance difference 1.013895034790039\n",
      "Validation: loss 5.616405166180368, covariance difference 8.756997943582359, sinkhorn epsilon 0.0\n",
      "Iteration  709\n",
      "Training: loss 4.5766921043396, covariance difference 1.0065709352493286\n",
      "Validation: loss 5.6052455001413115, covariance difference 8.71538704131875, sinkhorn epsilon 8.747023824104772e-14\n",
      "Iteration  710\n",
      "Training: loss 4.565520286560059, covariance difference 1.0047199726104736\n",
      "Validation: loss 5.646625714559219, covariance difference 8.42260552409387, sinkhorn epsilon 0.0\n",
      "Iteration  711\n",
      "Training: loss 4.606911659240723, covariance difference 1.0133131742477417\n",
      "Validation: loss 5.679284307625907, covariance difference 8.62944782078902, sinkhorn epsilon 0.0\n",
      "Iteration  712\n",
      "Training: loss 4.639553070068359, covariance difference 1.0193122625350952\n",
      "Validation: loss 5.71101600877939, covariance difference 8.861164681677467, sinkhorn epsilon 0.0\n",
      "Iteration  713\n",
      "Training: loss 4.671290397644043, covariance difference 1.0254813432693481\n",
      "Validation: loss 5.6810825921989485, covariance difference 8.5726206679984, sinkhorn epsilon 0.0\n",
      "Iteration  714\n",
      "Training: loss 4.641351699829102, covariance difference 1.0176939964294434\n",
      "Validation: loss 5.6137658591037995, covariance difference 8.421923866654566, sinkhorn epsilon 0.0\n",
      "Iteration  715\n",
      "Training: loss 4.574036598205566, covariance difference 1.0076624155044556\n",
      "Validation: loss 5.741367782990893, covariance difference 8.746312876927504, sinkhorn epsilon 1.9868228424352532e-14\n",
      "Iteration  716\n",
      "Training: loss 4.701642990112305, covariance difference 1.031363606452942\n",
      "Validation: loss 5.708660178573088, covariance difference 8.654660521282674, sinkhorn epsilon 0.0\n",
      "Iteration  717\n",
      "Training: loss 4.668930530548096, covariance difference 1.0253080129623413\n",
      "Validation: loss 5.623118418684314, covariance difference 8.508097236386503, sinkhorn epsilon 0.0\n",
      "Iteration  718\n",
      "Training: loss 4.583404541015625, covariance difference 1.0109694004058838\n",
      "Validation: loss 5.693991118091902, covariance difference 8.648075777349675, sinkhorn epsilon 0.0\n",
      "Iteration  719\n",
      "Training: loss 4.654262065887451, covariance difference 1.0225509405136108\n",
      "Validation: loss 5.617197472093296, covariance difference 8.432241845906018, sinkhorn epsilon 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  720\n",
      "Training: loss 4.577469825744629, covariance difference 1.0071486234664917\n",
      "Validation: loss 5.6953209866961965, covariance difference 9.022040680119439, sinkhorn epsilon 3.6594278101599136e-14\n",
      "Iteration  721\n",
      "Training: loss 4.655596733093262, covariance difference 1.024678349494934\n",
      "Validation: loss 5.669439687965394, covariance difference 8.553174063973639, sinkhorn epsilon 0.0\n",
      "Iteration  722\n",
      "Training: loss 4.629772186279297, covariance difference 1.0170814990997314\n",
      "Validation: loss 5.716074009494311, covariance difference 8.645833344575834, sinkhorn epsilon 1.5611908171216087e-14\n",
      "Iteration  723\n",
      "Training: loss 4.6763482093811035, covariance difference 1.0251007080078125\n",
      "Validation: loss 5.6193635986565456, covariance difference 8.358245535156243, sinkhorn epsilon 0.0\n",
      "Iteration  724\n",
      "Training: loss 4.579641342163086, covariance difference 1.007895827293396\n",
      "Validation: loss 5.6353131466551565, covariance difference 8.841804821364958, sinkhorn epsilon 0.0\n",
      "Iteration  725\n",
      "Training: loss 4.595584869384766, covariance difference 1.012296199798584\n",
      "Validation: loss 5.595389513994794, covariance difference 8.578704769883146, sinkhorn epsilon 1.7897943349082508e-14\n",
      "Iteration  726\n",
      "Training: loss 4.555665969848633, covariance difference 1.0035632848739624\n",
      "Validation: loss 5.655292019201772, covariance difference 8.7365637648067, sinkhorn epsilon 3.066889519531369e-14\n",
      "Iteration  727\n",
      "Training: loss 4.615628242492676, covariance difference 1.0159927606582642\n",
      "Validation: loss 5.640272692566011, covariance difference 8.569302136835017, sinkhorn epsilon 0.0\n",
      "Iteration  728\n",
      "Training: loss 4.6005682945251465, covariance difference 1.0121171474456787\n",
      "Validation: loss 5.7169443712518015, covariance difference 8.859498988414455, sinkhorn epsilon 0.0\n",
      "Iteration  729\n",
      "Training: loss 4.677214622497559, covariance difference 1.0274696350097656\n",
      "Validation: loss 5.697792057233158, covariance difference 8.392406492227733, sinkhorn epsilon 0.0\n",
      "Iteration  730\n",
      "Training: loss 4.6580729484558105, covariance difference 1.0211163759231567\n",
      "Validation: loss 5.740098838891356, covariance difference 8.684961952858934, sinkhorn epsilon 2.582555297436817e-14\n",
      "Iteration  731\n",
      "Training: loss 4.700386047363281, covariance difference 1.0278536081314087\n",
      "Validation: loss 5.702343959695093, covariance difference 8.528018205388413, sinkhorn epsilon 0.0\n",
      "Iteration  732\n",
      "Training: loss 4.662621021270752, covariance difference 1.0222619771957397\n",
      "Validation: loss 5.670490158480029, covariance difference 8.68002046540646, sinkhorn epsilon 2.9736061053929224e-14\n",
      "Iteration  733\n",
      "Training: loss 4.630764007568359, covariance difference 1.01836097240448\n",
      "Validation: loss 5.624706999262065, covariance difference 8.680222796149963, sinkhorn epsilon 0.0\n",
      "Iteration  734\n",
      "Training: loss 4.584980010986328, covariance difference 1.0091813802719116\n",
      "Validation: loss 5.6671261332548255, covariance difference 8.74612391589629, sinkhorn epsilon 0.0\n",
      "Iteration  735\n",
      "Training: loss 4.627396583557129, covariance difference 1.0181421041488647\n",
      "Validation: loss 5.584213407941638, covariance difference 8.472795888778911, sinkhorn epsilon 0.0\n",
      "Iteration  736\n",
      "Training: loss 4.544525146484375, covariance difference 1.0032553672790527\n",
      "Validation: loss 5.607081580586026, covariance difference 8.548880621611282, sinkhorn epsilon 4.52307023187431e-15\n",
      "Iteration  737\n",
      "Training: loss 4.567350387573242, covariance difference 1.005995512008667\n",
      "Validation: loss 5.670489307809688, covariance difference 8.707240295486015, sinkhorn epsilon 0.0\n",
      "Iteration  738\n",
      "Training: loss 4.630764961242676, covariance difference 1.0158690214157104\n",
      "Validation: loss 5.64167830523287, covariance difference 8.868863045111613, sinkhorn epsilon 4.231824339913732e-15\n",
      "Iteration  739\n",
      "Training: loss 4.60195255279541, covariance difference 1.0134227275848389\n",
      "Validation: loss 5.6583524313268345, covariance difference 8.593686827149813, sinkhorn epsilon 0.0\n",
      "Iteration  740\n",
      "Training: loss 4.618622779846191, covariance difference 1.0155590772628784\n",
      "Validation: loss 5.661441564017823, covariance difference 8.53095247197607, sinkhorn epsilon 0.0\n",
      "Iteration  741\n",
      "Training: loss 4.6217122077941895, covariance difference 1.0154601335525513\n",
      "Validation: loss 5.659670865387247, covariance difference 8.482787627289783, sinkhorn epsilon 0.0\n",
      "Iteration  742\n",
      "Training: loss 4.619948387145996, covariance difference 1.0147733688354492\n",
      "Validation: loss 5.687610650730241, covariance difference 8.730066132024426, sinkhorn epsilon 0.0\n",
      "Iteration  743\n",
      "Training: loss 4.647881031036377, covariance difference 1.0200800895690918\n",
      "Validation: loss 5.699313510228915, covariance difference 8.87444117543552, sinkhorn epsilon 3.351422779666403e-14\n",
      "Iteration  744\n",
      "Training: loss 4.659584999084473, covariance difference 1.0233023166656494\n",
      "Validation: loss 5.696819393554775, covariance difference 8.78771426725301, sinkhorn epsilon 0.0\n",
      "Iteration  745\n",
      "Training: loss 4.657129287719727, covariance difference 1.0228601694107056\n",
      "Validation: loss 5.556360955673057, covariance difference 8.252078401069113, sinkhorn epsilon 0.0\n",
      "Iteration  746\n",
      "Training: loss 4.516630172729492, covariance difference 0.9968643188476562\n",
      "Validation: loss 5.646752917604417, covariance difference 8.545925939282911, sinkhorn epsilon 0.0\n",
      "Iteration  747\n",
      "Training: loss 4.607062339782715, covariance difference 1.012495994567871\n",
      "Validation: loss 5.697451946234828, covariance difference 8.612522256883539, sinkhorn epsilon 0.0\n",
      "Iteration  748\n",
      "Training: loss 4.6577229499816895, covariance difference 1.022831916809082\n",
      "Validation: loss 5.655457499457296, covariance difference 8.453475267252617, sinkhorn epsilon 0.0\n",
      "Iteration  749\n",
      "Training: loss 4.615726470947266, covariance difference 1.0129939317703247\n",
      "Validation: loss 5.679643040476909, covariance difference 8.74660723930903, sinkhorn epsilon 2.6053618028830217e-14\n",
      "Iteration  750\n",
      "Training: loss 4.639914512634277, covariance difference 1.018649697303772\n",
      "Validation: loss 5.744199567992576, covariance difference 8.805516103316682, sinkhorn epsilon 1.7535745973756247e-14\n",
      "Iteration  751\n",
      "Training: loss 4.7044830322265625, covariance difference 1.0318732261657715\n",
      "Validation: loss 5.606839242884429, covariance difference 8.450993930409412, sinkhorn epsilon 0.0\n",
      "Iteration  752\n",
      "Training: loss 4.567148208618164, covariance difference 1.005096673965454\n",
      "Validation: loss 5.619781822573981, covariance difference 8.595071088738163, sinkhorn epsilon 0.0\n",
      "Iteration  753\n",
      "Training: loss 4.580057144165039, covariance difference 1.0088989734649658\n",
      "Validation: loss 5.678927541654987, covariance difference 8.90067080227215, sinkhorn epsilon 0.0\n",
      "Iteration  754\n",
      "Training: loss 4.6392059326171875, covariance difference 1.0194363594055176\n",
      "Validation: loss 5.753415862009841, covariance difference 8.464776049766673, sinkhorn epsilon 0.0\n",
      "Iteration  755\n",
      "Training: loss 4.713735580444336, covariance difference 1.0310457944869995\n",
      "Validation: loss 5.692277771830815, covariance difference 8.825438823549971, sinkhorn epsilon 0.0\n",
      "Iteration  756\n",
      "Training: loss 4.65257453918457, covariance difference 1.0210044384002686\n",
      "Validation: loss 5.6795215804475525, covariance difference 8.741147109414474, sinkhorn epsilon 0.0\n",
      "Iteration  757\n",
      "Training: loss 4.639794826507568, covariance difference 1.0202398300170898\n",
      "Validation: loss 5.700826091675763, covariance difference 8.688070188578491, sinkhorn epsilon 0.0\n",
      "Iteration  758\n",
      "Training: loss 4.66111946105957, covariance difference 1.0237228870391846\n",
      "Validation: loss 5.694012314926399, covariance difference 8.483221714492469, sinkhorn epsilon 9.092567285597886e-14\n",
      "Iteration  759\n",
      "Training: loss 4.6542863845825195, covariance difference 1.0221428871154785\n",
      "Validation: loss 5.582776499938502, covariance difference 8.473000390739285, sinkhorn epsilon 0.0\n",
      "Iteration  760\n",
      "Training: loss 4.543045997619629, covariance difference 1.004299521446228\n",
      "Validation: loss 5.666672294248558, covariance difference 8.498074438043481, sinkhorn epsilon 0.0\n",
      "Iteration  761\n",
      "Training: loss 4.6269426345825195, covariance difference 1.0160638093948364\n",
      "Validation: loss 5.6022712288358, covariance difference 8.594034067339937, sinkhorn epsilon 0.0\n",
      "Iteration  762\n",
      "Training: loss 4.562535762786865, covariance difference 1.0064998865127563\n",
      "Validation: loss 5.6319826873245, covariance difference 8.710023927461245, sinkhorn epsilon 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  763\n",
      "Training: loss 4.592255592346191, covariance difference 1.0125632286071777\n",
      "Validation: loss 5.652887839129089, covariance difference 8.57956132676302, sinkhorn epsilon 0.0\n",
      "Iteration  764\n",
      "Training: loss 4.613192558288574, covariance difference 1.013480544090271\n",
      "Validation: loss 5.597637562757393, covariance difference 8.637414122661776, sinkhorn epsilon 0.0\n",
      "Iteration  765\n",
      "Training: loss 4.557921409606934, covariance difference 1.003028392791748\n",
      "Validation: loss 5.716067323693102, covariance difference 8.859470534700307, sinkhorn epsilon 0.0\n",
      "Iteration  766\n",
      "Training: loss 4.676337242126465, covariance difference 1.0258656740188599\n",
      "Validation: loss 5.5384208286234236, covariance difference 8.729822910785884, sinkhorn epsilon 0.0\n",
      "Iteration  767\n",
      "Training: loss 4.4986982345581055, covariance difference 0.9943745136260986\n",
      "Validation: loss 5.740454755758909, covariance difference 8.780625811782476, sinkhorn epsilon 0.0\n",
      "Iteration  768\n",
      "Training: loss 4.70072603225708, covariance difference 1.0275542736053467\n",
      "Validation: loss 5.662654111288095, covariance difference 8.58637301104444, sinkhorn epsilon 0.0\n",
      "Iteration  769\n",
      "Training: loss 4.622932434082031, covariance difference 1.0158270597457886\n",
      "Validation: loss 5.65896696843199, covariance difference 8.758917636692967, sinkhorn epsilon 0.0\n",
      "Iteration  770\n",
      "Training: loss 4.619245529174805, covariance difference 1.0170272588729858\n",
      "Validation: loss 5.5802593162406655, covariance difference 8.615897985233701, sinkhorn epsilon 0.0\n",
      "Iteration  771\n",
      "Training: loss 4.540526866912842, covariance difference 1.0009841918945312\n",
      "Validation: loss 5.654041015401663, covariance difference 8.648575252946724, sinkhorn epsilon 0.0\n",
      "Iteration  772\n",
      "Training: loss 4.614321708679199, covariance difference 1.014425277709961\n",
      "Validation: loss 5.700668635745689, covariance difference 8.765054369703247, sinkhorn epsilon 0.0\n",
      "Iteration  773\n",
      "Training: loss 4.6609416007995605, covariance difference 1.0225318670272827\n",
      "Validation: loss 5.573632818735836, covariance difference 8.24221316405802, sinkhorn epsilon 0.0\n",
      "Iteration  774\n",
      "Training: loss 4.533903121948242, covariance difference 0.9980199337005615\n",
      "Validation: loss 5.59885912450652, covariance difference 8.323530826333466, sinkhorn epsilon 0.0\n",
      "Iteration  775\n",
      "Training: loss 4.559129238128662, covariance difference 1.0044504404067993\n",
      "Validation: loss 5.66656015949572, covariance difference 8.767806583128044, sinkhorn epsilon 3.268663562929292e-14\n",
      "Iteration  776\n",
      "Training: loss 4.626832962036133, covariance difference 1.0149058103561401\n",
      "Validation: loss 5.707178129788777, covariance difference 8.75044113621526, sinkhorn epsilon 0.0\n",
      "Iteration  777\n",
      "Training: loss 4.667452335357666, covariance difference 1.02482271194458\n",
      "Validation: loss 5.584961570226852, covariance difference 8.46277985671955, sinkhorn epsilon 0.0\n",
      "Iteration  778\n",
      "Training: loss 4.545242786407471, covariance difference 1.0004624128341675\n",
      "Validation: loss 5.563941875333563, covariance difference 8.471159610913764, sinkhorn epsilon 0.0\n",
      "Iteration  779\n",
      "Training: loss 4.524230480194092, covariance difference 0.9992197751998901\n",
      "Validation: loss 5.7897439459849505, covariance difference 8.747375304908102, sinkhorn epsilon 0.0\n",
      "Iteration  780\n",
      "Training: loss 4.750028610229492, covariance difference 1.0381805896759033\n",
      "Validation: loss 5.72521970023821, covariance difference 8.887978159936335, sinkhorn epsilon 0.0\n",
      "Iteration  781\n",
      "Training: loss 4.685489654541016, covariance difference 1.0257245302200317\n",
      "Validation: loss 5.640458878345098, covariance difference 8.316691598975536, sinkhorn epsilon 0.0\n",
      "Iteration  782\n",
      "Training: loss 4.6007304191589355, covariance difference 1.0131573677062988\n",
      "Validation: loss 5.64530454333485, covariance difference 8.482954090378302, sinkhorn epsilon 0.0\n",
      "Iteration  783\n",
      "Training: loss 4.605576038360596, covariance difference 1.0135743618011475\n",
      "Validation: loss 5.640251927161453, covariance difference 8.621127738335678, sinkhorn epsilon 0.0\n",
      "Iteration  784\n",
      "Training: loss 4.600552558898926, covariance difference 1.0113109350204468\n",
      "Validation: loss 5.716866331830987, covariance difference 8.841366643198935, sinkhorn epsilon 0.0\n",
      "Iteration  785\n",
      "Training: loss 4.677140235900879, covariance difference 1.025421380996704\n",
      "Validation: loss 5.654967012399812, covariance difference 8.537685480331328, sinkhorn epsilon 0.0\n",
      "Iteration  786\n",
      "Training: loss 4.615240573883057, covariance difference 1.0150638818740845\n",
      "Validation: loss 5.598138647611929, covariance difference 8.455433130378152, sinkhorn epsilon 0.0\n",
      "Iteration  787\n",
      "Training: loss 4.558408260345459, covariance difference 1.00356125831604\n",
      "Validation: loss 5.658954855966746, covariance difference 8.633053543788629, sinkhorn epsilon 0.0\n",
      "Iteration  788\n",
      "Training: loss 4.619243621826172, covariance difference 1.012509822845459\n",
      "Validation: loss 5.599755245284275, covariance difference 8.538428745181404, sinkhorn epsilon 0.0\n",
      "Iteration  789\n",
      "Training: loss 4.56002950668335, covariance difference 1.004780650138855\n",
      "Validation: loss 5.64912802461945, covariance difference 8.590251827586712, sinkhorn epsilon 0.0\n",
      "Iteration  790\n",
      "Training: loss 4.609396934509277, covariance difference 1.0152990818023682\n",
      "Validation: loss 5.716015410081379, covariance difference 8.692528595070334, sinkhorn epsilon 0.0\n",
      "Iteration  791\n",
      "Training: loss 4.6762895584106445, covariance difference 1.0264369249343872\n",
      "Validation: loss 5.6447924873221815, covariance difference 8.80376974744217, sinkhorn epsilon 0.0\n",
      "Iteration  792\n",
      "Training: loss 4.605062961578369, covariance difference 1.0137118101119995\n",
      "Validation: loss 5.702074687274049, covariance difference 8.696484435922725, sinkhorn epsilon 0.0\n",
      "Iteration  793\n",
      "Training: loss 4.662355899810791, covariance difference 1.0239869356155396\n",
      "Validation: loss 5.654869546829609, covariance difference 8.429718712573628, sinkhorn epsilon 0.0\n",
      "Iteration  794\n",
      "Training: loss 4.615142345428467, covariance difference 1.0140784978866577\n",
      "Validation: loss 5.638871719946202, covariance difference 8.571895948865889, sinkhorn epsilon 0.0\n",
      "Iteration  795\n",
      "Training: loss 4.599146842956543, covariance difference 1.0121536254882812\n",
      "Validation: loss 5.65845455028294, covariance difference 8.451797609289354, sinkhorn epsilon 0.0\n",
      "Iteration  796\n",
      "Training: loss 4.618725776672363, covariance difference 1.0158956050872803\n",
      "Validation: loss 5.621803334381031, covariance difference 8.535093053773453, sinkhorn epsilon 0.0\n",
      "Iteration  797\n",
      "Training: loss 4.582073211669922, covariance difference 1.0067195892333984\n",
      "Validation: loss 5.638766235515812, covariance difference 8.59996802931352, sinkhorn epsilon 0.0\n",
      "Iteration  798\n",
      "Training: loss 4.599035263061523, covariance difference 1.0119017362594604\n",
      "Validation: loss 5.633428808515825, covariance difference 8.667451175317323, sinkhorn epsilon 0.0\n",
      "Iteration  799\n",
      "Training: loss 4.593717575073242, covariance difference 1.0101608037948608\n",
      "Validation: loss 5.681738699834769, covariance difference 8.824268060514024, sinkhorn epsilon 0.0\n",
      "Iteration  800\n",
      "Training: loss 4.64201545715332, covariance difference 1.0201181173324585\n",
      "Validation: loss 5.720268902790368, covariance difference 8.906833850232973, sinkhorn epsilon 0.0\n",
      "Iteration  801\n",
      "Training: loss 4.680591583251953, covariance difference 1.0265862941741943\n",
      "Validation: loss 5.628499206695837, covariance difference 8.605212247970039, sinkhorn epsilon 1.5496843438779238e-14\n",
      "Iteration  802\n",
      "Training: loss 4.588769912719727, covariance difference 1.010558843612671\n",
      "Validation: loss 5.655520743678064, covariance difference 8.657636390671172, sinkhorn epsilon 0.0\n",
      "Iteration  803\n",
      "Training: loss 4.615823745727539, covariance difference 1.014786958694458\n",
      "Validation: loss 5.5723769747175895, covariance difference 8.590084199999612, sinkhorn epsilon 5.89268573445723e-14\n",
      "Iteration  804\n",
      "Training: loss 4.532654762268066, covariance difference 0.9986366629600525\n",
      "Validation: loss 5.705916943823723, covariance difference 8.49024650792749, sinkhorn epsilon 0.0\n",
      "Iteration  805\n",
      "Training: loss 4.666186332702637, covariance difference 1.0232620239257812\n",
      "Validation: loss 5.659814079340364, covariance difference 8.660336789248516, sinkhorn epsilon 0.0\n",
      "Iteration  806\n",
      "Training: loss 4.620084285736084, covariance difference 1.0147502422332764\n",
      "Validation: loss 5.616370564380835, covariance difference 8.57606868801058, sinkhorn epsilon 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  807\n",
      "Training: loss 4.5766472816467285, covariance difference 1.006906509399414\n",
      "Validation: loss 5.758333156687272, covariance difference 9.108014981170673, sinkhorn epsilon 0.0\n",
      "Iteration  808\n",
      "Training: loss 4.718606948852539, covariance difference 1.034880518913269\n",
      "Validation: loss 5.6986514132227795, covariance difference 8.543886756685819, sinkhorn epsilon 3.603097807722504e-14\n",
      "Iteration  809\n",
      "Training: loss 4.6589226722717285, covariance difference 1.0234177112579346\n",
      "Validation: loss 5.644554264046159, covariance difference 8.449469334108594, sinkhorn epsilon 0.0\n",
      "Iteration  810\n",
      "Training: loss 4.604824066162109, covariance difference 1.011985421180725\n",
      "Validation: loss 5.644088443473453, covariance difference 8.473394741157755, sinkhorn epsilon 0.0\n",
      "Iteration  811\n",
      "Training: loss 4.604368209838867, covariance difference 1.0114836692810059\n",
      "Validation: loss 5.611257129939268, covariance difference 8.504760705504252, sinkhorn epsilon 0.0\n",
      "Iteration  812\n",
      "Training: loss 4.571530818939209, covariance difference 1.005987286567688\n",
      "Validation: loss 5.651681173176412, covariance difference 8.768006305710717, sinkhorn epsilon 0.0\n",
      "Iteration  813\n",
      "Training: loss 4.61197566986084, covariance difference 1.0137958526611328\n",
      "Validation: loss 5.620235727881747, covariance difference 8.632491748449407, sinkhorn epsilon 0.0\n",
      "Iteration  814\n",
      "Training: loss 4.580515384674072, covariance difference 1.0079227685928345\n",
      "Validation: loss 5.669100785246281, covariance difference 8.628545058939741, sinkhorn epsilon 6.8442922115884356e-15\n",
      "Iteration  815\n",
      "Training: loss 4.629389762878418, covariance difference 1.0167908668518066\n",
      "Validation: loss 5.73870462290206, covariance difference 8.939004787060394, sinkhorn epsilon 1.8503511062880787e-14\n",
      "Iteration  816\n",
      "Training: loss 4.698975563049316, covariance difference 1.0301904678344727\n",
      "Validation: loss 5.6073670350140015, covariance difference 8.55750634234701, sinkhorn epsilon 0.0\n",
      "Iteration  817\n",
      "Training: loss 4.567648410797119, covariance difference 1.0063703060150146\n",
      "Validation: loss 5.644958780972119, covariance difference 8.502339221606745, sinkhorn epsilon 0.0\n",
      "Iteration  818\n",
      "Training: loss 4.6052727699279785, covariance difference 1.0125643014907837\n",
      "Validation: loss 5.617092896135629, covariance difference 8.459470028624569, sinkhorn epsilon 0.0\n",
      "Iteration  819\n",
      "Training: loss 4.577362060546875, covariance difference 1.0075362920761108\n",
      "Validation: loss 5.572537093592706, covariance difference 8.794205849887991, sinkhorn epsilon 3.9445752874321905e-14\n",
      "Iteration  820\n",
      "Training: loss 4.532820224761963, covariance difference 0.9987230896949768\n",
      "Validation: loss 5.711491793313424, covariance difference 8.650108735213308, sinkhorn epsilon 3.1763297479150127e-14\n",
      "Iteration  821\n",
      "Training: loss 4.671774387359619, covariance difference 1.026411771774292\n",
      "Validation: loss 5.720042907474873, covariance difference 8.953644069533583, sinkhorn epsilon 0.0\n",
      "Iteration  822\n",
      "Training: loss 4.680352210998535, covariance difference 1.024499535560608\n",
      "Validation: loss 5.659744572094847, covariance difference 8.457937405573581, sinkhorn epsilon 3.314329274056479e-14\n",
      "Iteration  823\n",
      "Training: loss 4.620021820068359, covariance difference 1.015890121459961\n",
      "Validation: loss 5.648602640572465, covariance difference 8.62388951635236, sinkhorn epsilon 0.0\n",
      "Iteration  824\n",
      "Training: loss 4.608878135681152, covariance difference 1.0133228302001953\n",
      "Validation: loss 5.631252300675955, covariance difference 8.506217671075277, sinkhorn epsilon 0.0\n",
      "Iteration  825\n",
      "Training: loss 4.591525077819824, covariance difference 1.0106106996536255\n",
      "Validation: loss 5.634081705318458, covariance difference 8.603593076393121, sinkhorn epsilon 0.0\n",
      "Iteration  826\n",
      "Training: loss 4.5943498611450195, covariance difference 1.0113203525543213\n",
      "Validation: loss 5.682646301496289, covariance difference 8.95487945764355, sinkhorn epsilon 0.0\n",
      "Iteration  827\n",
      "Training: loss 4.642915725708008, covariance difference 1.0188313722610474\n",
      "Validation: loss 5.623886500724145, covariance difference 8.715506729546458, sinkhorn epsilon 4.830996595061325e-14\n",
      "Iteration  828\n",
      "Training: loss 4.5841569900512695, covariance difference 1.007419228553772\n",
      "Validation: loss 5.680444213661598, covariance difference 8.725756933175548, sinkhorn epsilon 8.054733916031638e-14\n",
      "Iteration  829\n",
      "Training: loss 4.640719413757324, covariance difference 1.0213037729263306\n",
      "Validation: loss 5.655912390771913, covariance difference 8.411145134530887, sinkhorn epsilon 0.0\n",
      "Iteration  830\n",
      "Training: loss 4.616183757781982, covariance difference 1.0141537189483643\n",
      "Validation: loss 5.591303252368158, covariance difference 8.427721542666944, sinkhorn epsilon 0.0\n",
      "Iteration  831\n",
      "Training: loss 4.551582336425781, covariance difference 1.0059765577316284\n",
      "Validation: loss 5.684080612356677, covariance difference 8.723593428697635, sinkhorn epsilon 0.0\n",
      "Iteration  832\n",
      "Training: loss 4.644352436065674, covariance difference 1.01924729347229\n",
      "Validation: loss 5.696607880104578, covariance difference 8.684594931332294, sinkhorn epsilon 0.0\n",
      "Iteration  833\n",
      "Training: loss 4.656881809234619, covariance difference 1.022054672241211\n",
      "Validation: loss 5.685409249757732, covariance difference 8.794372483462496, sinkhorn epsilon 0.0\n",
      "Iteration  834\n",
      "Training: loss 4.645687103271484, covariance difference 1.021407127380371\n",
      "Validation: loss 5.691234219435671, covariance difference 8.728319179275479, sinkhorn epsilon 2.109213465206363e-15\n",
      "Iteration  835\n",
      "Training: loss 4.6515045166015625, covariance difference 1.0198609828948975\n",
      "Validation: loss 5.664301275985901, covariance difference 8.66059411332036, sinkhorn epsilon 0.0\n",
      "Iteration  836\n",
      "Training: loss 4.624575614929199, covariance difference 1.015001654624939\n",
      "Validation: loss 5.634840851905623, covariance difference 8.404489065798067, sinkhorn epsilon 0.0\n",
      "Iteration  837\n",
      "Training: loss 4.595111846923828, covariance difference 1.011884331703186\n",
      "Validation: loss 5.698153786221521, covariance difference 8.766438290333081, sinkhorn epsilon 1.6734646153896695e-14\n",
      "Iteration  838\n",
      "Training: loss 4.658426761627197, covariance difference 1.0221302509307861\n",
      "Validation: loss 5.643933527884274, covariance difference 8.408446614381667, sinkhorn epsilon 0.0\n",
      "Iteration  839\n",
      "Training: loss 4.604202747344971, covariance difference 1.0159763097763062\n",
      "Validation: loss 5.629091646710413, covariance difference 8.594986860396597, sinkhorn epsilon 0.0\n",
      "Iteration  840\n",
      "Training: loss 4.589373588562012, covariance difference 1.0108872652053833\n",
      "Validation: loss 5.68750286855299, covariance difference 8.731359808768568, sinkhorn epsilon 0.0\n",
      "Iteration  841\n",
      "Training: loss 4.647799015045166, covariance difference 1.02077317237854\n",
      "Validation: loss 5.612413895935281, covariance difference 8.571381582243488, sinkhorn epsilon 0.0\n",
      "Iteration  842\n",
      "Training: loss 4.572690010070801, covariance difference 1.0064234733581543\n",
      "Validation: loss 5.593981614131211, covariance difference 8.63319853451375, sinkhorn epsilon 0.0\n",
      "Iteration  843\n",
      "Training: loss 4.5542683601379395, covariance difference 1.0044842958450317\n",
      "Validation: loss 5.698068339394088, covariance difference 8.7294459884945, sinkhorn epsilon 0.0\n",
      "Iteration  844\n",
      "Training: loss 4.658344268798828, covariance difference 1.020835280418396\n",
      "Validation: loss 5.605395711772681, covariance difference 8.543433502472828, sinkhorn epsilon 2.5027847147588354e-14\n",
      "Iteration  845\n",
      "Training: loss 4.5656843185424805, covariance difference 1.005427598953247\n",
      "Validation: loss 5.617447398106942, covariance difference 8.590181768948264, sinkhorn epsilon 0.0\n",
      "Iteration  846\n",
      "Training: loss 4.577716827392578, covariance difference 1.0072476863861084\n",
      "Validation: loss 5.686715090934598, covariance difference 8.672396518139376, sinkhorn epsilon 0.0\n",
      "Iteration  847\n",
      "Training: loss 4.646992206573486, covariance difference 1.019972324371338\n",
      "Validation: loss 5.603077596670209, covariance difference 8.391705007548186, sinkhorn epsilon 0.0\n",
      "Iteration  848\n",
      "Training: loss 4.563345909118652, covariance difference 1.005928635597229\n",
      "Validation: loss 5.578020326423408, covariance difference 8.58917907067447, sinkhorn epsilon 0.0\n",
      "Iteration  849\n",
      "Training: loss 4.5382981300354, covariance difference 1.0023249387741089\n",
      "Validation: loss 5.661344863849324, covariance difference 8.684060163402703, sinkhorn epsilon 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  850\n",
      "Training: loss 4.621614456176758, covariance difference 1.015218734741211\n",
      "Validation: loss 5.634169089374057, covariance difference 8.674514315770754, sinkhorn epsilon 0.0\n",
      "Iteration  851\n",
      "Training: loss 4.594452857971191, covariance difference 1.0114357471466064\n",
      "Validation: loss 5.673894531174916, covariance difference 8.58177844511117, sinkhorn epsilon 2.6970454582184114e-14\n",
      "Iteration  852\n",
      "Training: loss 4.634173393249512, covariance difference 1.0163490772247314\n",
      "Validation: loss 5.585145484658286, covariance difference 8.585097226059442, sinkhorn epsilon 6.842870371144435e-14\n",
      "Iteration  853\n",
      "Training: loss 4.545416355133057, covariance difference 1.0022469758987427\n",
      "Validation: loss 5.661196648686355, covariance difference 8.489750994932953, sinkhorn epsilon 0.0\n",
      "Iteration  854\n",
      "Training: loss 4.62147331237793, covariance difference 1.0147473812103271\n",
      "Validation: loss 5.621094120995642, covariance difference 8.44497551607029, sinkhorn epsilon 0.0\n",
      "Iteration  855\n",
      "Training: loss 4.58136510848999, covariance difference 1.0081535577774048\n",
      "Validation: loss 5.67236220095912, covariance difference 8.615730808213733, sinkhorn epsilon 0.0\n",
      "Iteration  856\n",
      "Training: loss 4.632638931274414, covariance difference 1.0191494226455688\n",
      "Validation: loss 5.62760854111267, covariance difference 8.395953793813662, sinkhorn epsilon 0.0\n",
      "Iteration  857\n",
      "Training: loss 4.58788537979126, covariance difference 1.0097917318344116\n",
      "Validation: loss 5.653733710792043, covariance difference 8.623944206395933, sinkhorn epsilon 0.0\n",
      "Iteration  858\n",
      "Training: loss 4.614004135131836, covariance difference 1.0138771533966064\n",
      "Validation: loss 5.666100492626079, covariance difference 8.619616829772792, sinkhorn epsilon 0.0\n",
      "Iteration  859\n",
      "Training: loss 4.626383304595947, covariance difference 1.0157594680786133\n",
      "Validation: loss 5.6640078440955115, covariance difference 8.59715810457806, sinkhorn epsilon 7.32322099091138e-15\n",
      "Iteration  860\n",
      "Training: loss 4.624279499053955, covariance difference 1.0143442153930664\n",
      "Validation: loss 5.662602364205569, covariance difference 8.604480194663328, sinkhorn epsilon 0.0\n",
      "Iteration  861\n",
      "Training: loss 4.6228742599487305, covariance difference 1.015934705734253\n",
      "Validation: loss 5.704833822551365, covariance difference 8.711001211225287, sinkhorn epsilon 0.0\n",
      "Iteration  862\n",
      "Training: loss 4.665102958679199, covariance difference 1.0246378183364868\n",
      "Validation: loss 5.719794350197035, covariance difference 8.675411619373083, sinkhorn epsilon 0.0\n",
      "Iteration  863\n",
      "Training: loss 4.680066108703613, covariance difference 1.0246474742889404\n",
      "Validation: loss 5.6511553660613, covariance difference 8.568590187697279, sinkhorn epsilon 0.0\n",
      "Iteration  864\n",
      "Training: loss 4.6114301681518555, covariance difference 1.0140621662139893\n",
      "Validation: loss 5.674078679095285, covariance difference 8.688114419450502, sinkhorn epsilon 0.0\n",
      "Iteration  865\n",
      "Training: loss 4.6343488693237305, covariance difference 1.0165953636169434\n",
      "Validation: loss 5.688643509350756, covariance difference 8.650191524753259, sinkhorn epsilon 0.0\n",
      "Iteration  866\n",
      "Training: loss 4.6489481925964355, covariance difference 1.0207219123840332\n",
      "Validation: loss 5.700609553722909, covariance difference 8.523964315522935, sinkhorn epsilon 0.0\n",
      "Iteration  867\n",
      "Training: loss 4.660881996154785, covariance difference 1.023182988166809\n",
      "Validation: loss 5.567745728248161, covariance difference 8.40665062067834, sinkhorn epsilon 0.0\n",
      "Iteration  868\n",
      "Training: loss 4.528014659881592, covariance difference 0.9978106617927551\n",
      "Validation: loss 5.632758160296494, covariance difference 8.662479736539487, sinkhorn epsilon 3.9515269127003543e-14\n",
      "Iteration  869\n",
      "Training: loss 4.593029022216797, covariance difference 1.0106862783432007\n",
      "Validation: loss 5.716926186288845, covariance difference 8.659239396157831, sinkhorn epsilon 7.026262397152443e-15\n",
      "Iteration  870\n",
      "Training: loss 4.677197456359863, covariance difference 1.0270212888717651\n",
      "Validation: loss 5.618762598813259, covariance difference 8.593487681268005, sinkhorn epsilon 0.0\n",
      "Iteration  871\n",
      "Training: loss 4.579035758972168, covariance difference 1.0060701370239258\n",
      "Validation: loss 5.708194810353614, covariance difference 8.419094954922466, sinkhorn epsilon 0.0\n",
      "Iteration  872\n",
      "Training: loss 4.668484210968018, covariance difference 1.0249042510986328\n",
      "Validation: loss 5.668018398286792, covariance difference 8.81574621691474, sinkhorn epsilon 0.0\n",
      "Iteration  873\n",
      "Training: loss 4.62829065322876, covariance difference 1.0188993215560913\n",
      "Validation: loss 5.674183033830111, covariance difference 8.655356653778004, sinkhorn epsilon 0.0\n",
      "Iteration  874\n",
      "Training: loss 4.634460926055908, covariance difference 1.0189402103424072\n",
      "Validation: loss 5.673826509704302, covariance difference 8.575630704000234, sinkhorn epsilon 0.0\n",
      "Iteration  875\n",
      "Training: loss 4.634095191955566, covariance difference 1.017775297164917\n",
      "Validation: loss 5.64467696640782, covariance difference 8.632150286657325, sinkhorn epsilon 0.0\n",
      "Iteration  876\n",
      "Training: loss 4.604943752288818, covariance difference 1.015934705734253\n",
      "Validation: loss 5.663608640899073, covariance difference 8.561975832443501, sinkhorn epsilon 0.0\n",
      "Iteration  877\n",
      "Training: loss 4.623884201049805, covariance difference 1.0168681144714355\n",
      "Validation: loss 5.700678398092375, covariance difference 8.8358164505381, sinkhorn epsilon 9.095427946975869e-14\n",
      "Iteration  878\n",
      "Training: loss 4.660986423492432, covariance difference 1.0237046480178833\n",
      "Validation: loss 5.65639363965884, covariance difference 8.49175199375382, sinkhorn epsilon 3.77599831093218e-14\n",
      "Iteration  879\n",
      "Training: loss 4.616692066192627, covariance difference 1.0151184797286987\n",
      "Validation: loss 5.623157236922567, covariance difference 8.529622845583555, sinkhorn epsilon 0.0\n",
      "Iteration  880\n",
      "Training: loss 4.583426475524902, covariance difference 1.0090835094451904\n",
      "Validation: loss 5.66311773846309, covariance difference 8.713144918831917, sinkhorn epsilon 0.0\n",
      "Iteration  881\n",
      "Training: loss 4.623391151428223, covariance difference 1.016762375831604\n",
      "Validation: loss 5.626159658359736, covariance difference 8.500213807016939, sinkhorn epsilon 1.6650324074685474e-14\n",
      "Iteration  882\n",
      "Training: loss 4.58646821975708, covariance difference 1.0069307088851929\n",
      "Validation: loss 5.721857600070627, covariance difference 8.777373380193596, sinkhorn epsilon 0.0\n",
      "Iteration  883\n",
      "Training: loss 4.682125091552734, covariance difference 1.0279359817504883\n",
      "Validation: loss 5.64709917839757, covariance difference 8.705968904596995, sinkhorn epsilon 0.0\n",
      "Iteration  884\n",
      "Training: loss 4.6073737144470215, covariance difference 1.0141676664352417\n",
      "Validation: loss 5.689105920493178, covariance difference 8.727966593411612, sinkhorn epsilon 0.0\n",
      "Iteration  885\n",
      "Training: loss 4.64937686920166, covariance difference 1.0206867456436157\n",
      "Validation: loss 5.613700335895766, covariance difference 8.533706218484635, sinkhorn epsilon 3.1605097943684826e-14\n",
      "Iteration  886\n",
      "Training: loss 4.573971748352051, covariance difference 1.0079975128173828\n",
      "Validation: loss 5.677745963657374, covariance difference 8.599777736231944, sinkhorn epsilon 0.0\n",
      "Iteration  887\n",
      "Training: loss 4.63801383972168, covariance difference 1.020011067390442\n",
      "Validation: loss 5.726164706303491, covariance difference 8.50209211896725, sinkhorn epsilon 4.402319081801497e-14\n",
      "Iteration  888\n",
      "Training: loss 4.686454772949219, covariance difference 1.0267810821533203\n",
      "Validation: loss 5.650491818590668, covariance difference 8.690883799413099, sinkhorn epsilon 0.0\n",
      "Iteration  889\n",
      "Training: loss 4.61076545715332, covariance difference 1.0139755010604858\n",
      "Validation: loss 5.64789707724506, covariance difference 8.484528105729698, sinkhorn epsilon 0.0\n",
      "Iteration  890\n",
      "Training: loss 4.608166694641113, covariance difference 1.0130817890167236\n",
      "Validation: loss 5.6507468983510645, covariance difference 8.617262231244343, sinkhorn epsilon 8.111618862385252e-15\n",
      "Iteration  891\n",
      "Training: loss 4.61102294921875, covariance difference 1.01399827003479\n",
      "Validation: loss 5.589458068557385, covariance difference 8.653277538204115, sinkhorn epsilon 0.0\n",
      "Iteration  892\n",
      "Training: loss 4.549727439880371, covariance difference 1.0031319856643677\n",
      "Validation: loss 5.6618627947301645, covariance difference 8.812641489211655, sinkhorn epsilon 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  893\n",
      "Training: loss 4.622145652770996, covariance difference 1.0165680646896362\n",
      "Validation: loss 5.705790089303063, covariance difference 8.748813336926345, sinkhorn epsilon 2.2814500189555958e-14\n",
      "Iteration  894\n",
      "Training: loss 4.666060447692871, covariance difference 1.0235645771026611\n",
      "Validation: loss 5.662135629587406, covariance difference 8.7827383177305, sinkhorn epsilon 0.0\n",
      "Iteration  895\n",
      "Training: loss 4.622405052185059, covariance difference 1.0166373252868652\n",
      "Validation: loss 5.730009144237516, covariance difference 8.67756779694609, sinkhorn epsilon 0.0\n",
      "Iteration  896\n",
      "Training: loss 4.690277099609375, covariance difference 1.0281686782836914\n",
      "Validation: loss 5.671115240901193, covariance difference 8.859500023230126, sinkhorn epsilon 0.0\n",
      "Iteration  897\n",
      "Training: loss 4.631386756896973, covariance difference 1.01646888256073\n",
      "Validation: loss 5.648204024855258, covariance difference 8.317287849408553, sinkhorn epsilon 0.0\n",
      "Iteration  898\n",
      "Training: loss 4.608475208282471, covariance difference 1.0119155645370483\n",
      "Validation: loss 5.563135793805571, covariance difference 8.352779832588494, sinkhorn epsilon 1.9797327193435323e-14\n",
      "Iteration  899\n",
      "Training: loss 4.523410320281982, covariance difference 0.999136745929718\n",
      "Validation: loss 5.652025439776358, covariance difference 8.676650406860087, sinkhorn epsilon 0.0\n",
      "Iteration  900\n",
      "Training: loss 4.61229944229126, covariance difference 1.013980507850647\n",
      "Validation: loss 5.689048177950121, covariance difference 8.55050685571664, sinkhorn epsilon 0.0\n",
      "Iteration  901\n",
      "Training: loss 4.649326324462891, covariance difference 1.0197244882583618\n",
      "Validation: loss 5.681925028020748, covariance difference 8.655004217749815, sinkhorn epsilon 0.0\n",
      "Iteration  902\n",
      "Training: loss 4.642196178436279, covariance difference 1.019815444946289\n",
      "Validation: loss 5.623649178956821, covariance difference 8.398441849491403, sinkhorn epsilon 0.0\n",
      "Iteration  903\n",
      "Training: loss 4.583932399749756, covariance difference 1.0107163190841675\n",
      "Validation: loss 5.5509859933341055, covariance difference 8.477066085802505, sinkhorn epsilon 3.2786795863733765e-14\n",
      "Iteration  904\n",
      "Training: loss 4.511268138885498, covariance difference 0.9976094365119934\n",
      "Validation: loss 5.645846466808543, covariance difference 8.534584833844955, sinkhorn epsilon 0.0\n",
      "Iteration  905\n",
      "Training: loss 4.60612154006958, covariance difference 1.013476848602295\n",
      "Validation: loss 5.688587549956486, covariance difference 8.582359067975624, sinkhorn epsilon 2.6532002581930078e-14\n",
      "Iteration  906\n",
      "Training: loss 4.648861885070801, covariance difference 1.0212262868881226\n",
      "Validation: loss 5.683158745253981, covariance difference 8.761226828093998, sinkhorn epsilon 0.0\n",
      "Iteration  907\n",
      "Training: loss 4.643427848815918, covariance difference 1.0182373523712158\n",
      "Validation: loss 5.641229524387314, covariance difference 8.699769246328655, sinkhorn epsilon 0.0\n",
      "Iteration  908\n",
      "Training: loss 4.601502418518066, covariance difference 1.0106898546218872\n",
      "Validation: loss 5.604147063766667, covariance difference 8.397548073475663, sinkhorn epsilon 0.0\n",
      "Iteration  909\n",
      "Training: loss 4.564414978027344, covariance difference 1.0038121938705444\n",
      "Validation: loss 5.631058568561977, covariance difference 8.76609194318379, sinkhorn epsilon 0.0\n",
      "Iteration  910\n",
      "Training: loss 4.59133243560791, covariance difference 1.0098602771759033\n",
      "Validation: loss 5.587233554401587, covariance difference 8.408961448669187, sinkhorn epsilon 1.67700062008743e-14\n",
      "Iteration  911\n",
      "Training: loss 4.547508239746094, covariance difference 1.0029418468475342\n",
      "Validation: loss 5.703187732107994, covariance difference 8.750141585091267, sinkhorn epsilon 3.409997594300758e-14\n",
      "Iteration  912\n",
      "Training: loss 4.663455963134766, covariance difference 1.022438645362854\n",
      "Validation: loss 5.614369446787249, covariance difference 8.619211517847877, sinkhorn epsilon 0.0\n",
      "Iteration  913\n",
      "Training: loss 4.574638366699219, covariance difference 1.0075972080230713\n",
      "Validation: loss 5.63768765652482, covariance difference 8.410067692864144, sinkhorn epsilon 0.0\n",
      "Iteration  914\n",
      "Training: loss 4.5979695320129395, covariance difference 1.0082863569259644\n",
      "Validation: loss 5.6280238840575505, covariance difference 8.728715668430569, sinkhorn epsilon 0.0\n",
      "Iteration  915\n",
      "Training: loss 4.588298797607422, covariance difference 1.0084688663482666\n",
      "Validation: loss 5.753498975270228, covariance difference 8.857671110681549, sinkhorn epsilon 0.0\n",
      "Iteration  916\n",
      "Training: loss 4.713768005371094, covariance difference 1.0319682359695435\n",
      "Validation: loss 5.6050369690392, covariance difference 8.581648559455267, sinkhorn epsilon 1.6907613007481867e-14\n",
      "Iteration  917\n",
      "Training: loss 4.565308570861816, covariance difference 1.0034615993499756\n",
      "Validation: loss 5.666576973379007, covariance difference 8.416251194944183, sinkhorn epsilon 0.0\n",
      "Iteration  918\n",
      "Training: loss 4.6268463134765625, covariance difference 1.017393946647644\n",
      "Validation: loss 5.672664480402835, covariance difference 8.596767849484175, sinkhorn epsilon 0.0\n",
      "Iteration  919\n",
      "Training: loss 4.632937908172607, covariance difference 1.0181713104248047\n",
      "Validation: loss 5.565038166053946, covariance difference 8.522264760721676, sinkhorn epsilon 0.0\n",
      "Iteration  920\n",
      "Training: loss 4.525329113006592, covariance difference 0.9990242123603821\n",
      "Validation: loss 5.756382531570211, covariance difference 8.578921723924992, sinkhorn epsilon 0.0\n",
      "Iteration  921\n",
      "Training: loss 4.716658115386963, covariance difference 1.0343801975250244\n",
      "Validation: loss 5.620092290833081, covariance difference 8.639184468261176, sinkhorn epsilon 0.0\n",
      "Iteration  922\n",
      "Training: loss 4.580361366271973, covariance difference 1.0081456899642944\n",
      "Validation: loss 5.684389496480805, covariance difference 8.6466097372262, sinkhorn epsilon 3.1388677028615826e-14\n",
      "Iteration  923\n",
      "Training: loss 4.644660949707031, covariance difference 1.019676685333252\n",
      "Validation: loss 5.639954723974757, covariance difference 8.512761951215523, sinkhorn epsilon 0.0\n",
      "Iteration  924\n",
      "Training: loss 4.600233554840088, covariance difference 1.0120352506637573\n",
      "Validation: loss 5.6311926000487045, covariance difference 8.450452788336266, sinkhorn epsilon 0.0\n",
      "Iteration  925\n",
      "Training: loss 4.591464996337891, covariance difference 1.010453224182129\n",
      "Validation: loss 5.656165656323919, covariance difference 8.699151210832298, sinkhorn epsilon 2.3427467776064492e-14\n",
      "Iteration  926\n",
      "Training: loss 4.6164398193359375, covariance difference 1.0149767398834229\n",
      "Validation: loss 5.569439623423934, covariance difference 8.428183080799759, sinkhorn epsilon 0.0\n",
      "Iteration  927\n",
      "Training: loss 4.52971076965332, covariance difference 0.998018741607666\n",
      "Validation: loss 5.695207368381741, covariance difference 8.75852459891835, sinkhorn epsilon 3.776993482857462e-14\n",
      "Iteration  928\n",
      "Training: loss 4.655490875244141, covariance difference 1.0211595296859741\n",
      "Validation: loss 5.67161444076899, covariance difference 8.804596374981246, sinkhorn epsilon 0.0\n",
      "Iteration  929\n",
      "Training: loss 4.631892681121826, covariance difference 1.0182558298110962\n",
      "Validation: loss 5.691481873272307, covariance difference 8.757560917039957, sinkhorn epsilon 0.0\n",
      "Iteration  930\n",
      "Training: loss 4.651763916015625, covariance difference 1.0218628644943237\n",
      "Validation: loss 5.672321094114349, covariance difference 8.422280662431142, sinkhorn epsilon 0.0\n",
      "Iteration  931\n",
      "Training: loss 4.6325907707214355, covariance difference 1.018775463104248\n",
      "Validation: loss 5.704243907253606, covariance difference 8.423761377839941, sinkhorn epsilon 2.321160717990165e-14\n",
      "Iteration  932\n",
      "Training: loss 4.664514064788818, covariance difference 1.023946762084961\n",
      "Validation: loss 5.701235720086212, covariance difference 8.848492558247758, sinkhorn epsilon 0.0\n",
      "Iteration  933\n",
      "Training: loss 4.6615071296691895, covariance difference 1.0223174095153809\n",
      "Validation: loss 5.696661889688638, covariance difference 8.508899558115582, sinkhorn epsilon 0.0\n",
      "Iteration  934\n",
      "Training: loss 4.656939506530762, covariance difference 1.0208241939544678\n",
      "Validation: loss 5.719633466962066, covariance difference 8.631255559169663, sinkhorn epsilon 0.0\n",
      "Iteration  935\n",
      "Training: loss 4.679903507232666, covariance difference 1.0256567001342773\n",
      "Validation: loss 5.59135940642781, covariance difference 8.73662454875959, sinkhorn epsilon 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  936\n",
      "Training: loss 4.5516510009765625, covariance difference 1.0045084953308105\n",
      "Validation: loss 5.7029256391449525, covariance difference 8.900027854786192, sinkhorn epsilon 0.0\n",
      "Iteration  937\n",
      "Training: loss 4.6631975173950195, covariance difference 1.0254300832748413\n",
      "Validation: loss 5.658807935049827, covariance difference 8.600156315936976, sinkhorn epsilon 0.0\n",
      "Iteration  938\n",
      "Training: loss 4.619077682495117, covariance difference 1.0165013074874878\n",
      "Validation: loss 5.639578987280611, covariance difference 8.511683644462916, sinkhorn epsilon 0.0\n",
      "Iteration  939\n",
      "Training: loss 4.599847793579102, covariance difference 1.011644959449768\n",
      "Validation: loss 5.65482185856853, covariance difference 8.667030506397992, sinkhorn epsilon 0.0\n",
      "Iteration  940\n",
      "Training: loss 4.61510705947876, covariance difference 1.0149191617965698\n",
      "Validation: loss 5.6668040485672195, covariance difference 8.76300692931336, sinkhorn epsilon 4.847062132791625e-14\n",
      "Iteration  941\n",
      "Training: loss 4.627071857452393, covariance difference 1.0169504880905151\n",
      "Validation: loss 5.719043789566444, covariance difference 8.868562804453804, sinkhorn epsilon 0.0\n",
      "Iteration  942\n",
      "Training: loss 4.679316520690918, covariance difference 1.0280765295028687\n",
      "Validation: loss 5.690488104529995, covariance difference 8.80967818673058, sinkhorn epsilon 0.0\n",
      "Iteration  943\n",
      "Training: loss 4.650761604309082, covariance difference 1.0210402011871338\n",
      "Validation: loss 5.688408777118074, covariance difference 8.614509203059074, sinkhorn epsilon 0.0\n",
      "Iteration  944\n",
      "Training: loss 4.648682594299316, covariance difference 1.0198613405227661\n",
      "Validation: loss 5.624645356491492, covariance difference 8.651266215278081, sinkhorn epsilon 0.0\n",
      "Iteration  945\n",
      "Training: loss 4.584916591644287, covariance difference 1.0093674659729004\n",
      "Validation: loss 5.64435584519129, covariance difference 8.67780753391011, sinkhorn epsilon 0.0\n",
      "Iteration  946\n",
      "Training: loss 4.6046271324157715, covariance difference 1.0118041038513184\n",
      "Validation: loss 5.622288749748836, covariance difference 8.493661945443613, sinkhorn epsilon 0.0\n",
      "Iteration  947\n",
      "Training: loss 4.582592010498047, covariance difference 1.0100643634796143\n",
      "Validation: loss 5.648631246804555, covariance difference 8.623281430127566, sinkhorn epsilon 0.0\n",
      "Iteration  948\n",
      "Training: loss 4.6088995933532715, covariance difference 1.0138187408447266\n",
      "Validation: loss 5.689245761414073, covariance difference 8.725530416739854, sinkhorn epsilon 0.0\n",
      "Iteration  949\n",
      "Training: loss 4.649524688720703, covariance difference 1.0214027166366577\n",
      "Validation: loss 5.577724541593894, covariance difference 8.484913293230653, sinkhorn epsilon 0.0\n",
      "Iteration  950\n",
      "Training: loss 4.537994384765625, covariance difference 1.001692771911621\n",
      "Validation: loss 5.657054947622184, covariance difference 8.557791729524837, sinkhorn epsilon 0.0\n",
      "Iteration  951\n",
      "Training: loss 4.617339134216309, covariance difference 1.016201376914978\n",
      "Validation: loss 5.670281960292803, covariance difference 8.407763811497261, sinkhorn epsilon 0.0\n",
      "Iteration  952\n",
      "Training: loss 4.63055419921875, covariance difference 1.0158032178878784\n",
      "Validation: loss 5.6559226979713735, covariance difference 8.648560037471574, sinkhorn epsilon 2.9826841999281485e-14\n",
      "Iteration  953\n",
      "Training: loss 4.616193771362305, covariance difference 1.0144867897033691\n",
      "Validation: loss 5.687162825294502, covariance difference 9.005198505513288, sinkhorn epsilon 0.0\n",
      "Iteration  954\n",
      "Training: loss 4.647436141967773, covariance difference 1.0216957330703735\n",
      "Validation: loss 5.6209632187101315, covariance difference 8.529492566809955, sinkhorn epsilon 0.0\n",
      "Iteration  955\n",
      "Training: loss 4.581230640411377, covariance difference 1.008680820465088\n",
      "Validation: loss 5.638261057393164, covariance difference 8.619230813616774, sinkhorn epsilon 5.601868342700451e-15\n",
      "Iteration  956\n",
      "Training: loss 4.598579406738281, covariance difference 1.0114973783493042\n",
      "Validation: loss 5.6839170634032925, covariance difference 8.761668944232078, sinkhorn epsilon 0.0\n",
      "Iteration  957\n",
      "Training: loss 4.644190788269043, covariance difference 1.0181952714920044\n",
      "Validation: loss 5.562612116579558, covariance difference 8.522229500982222, sinkhorn epsilon 0.0\n",
      "Iteration  958\n",
      "Training: loss 4.522883415222168, covariance difference 0.9983121752738953\n",
      "Validation: loss 5.688259456962996, covariance difference 8.639347451492831, sinkhorn epsilon 0.0\n",
      "Iteration  959\n",
      "Training: loss 4.648530006408691, covariance difference 1.0214992761611938\n",
      "Validation: loss 5.62846708414453, covariance difference 8.621519583480849, sinkhorn epsilon 0.0\n",
      "Iteration  960\n",
      "Training: loss 4.588755130767822, covariance difference 1.0085082054138184\n",
      "Validation: loss 5.592229090590446, covariance difference 8.560389204331138, sinkhorn epsilon 0.0\n",
      "Iteration  961\n",
      "Training: loss 4.552502155303955, covariance difference 1.0032906532287598\n",
      "Validation: loss 5.63546858874623, covariance difference 8.363832982739986, sinkhorn epsilon 0.0\n",
      "Iteration  962\n",
      "Training: loss 4.59574031829834, covariance difference 1.0118041038513184\n",
      "Validation: loss 5.666477604921411, covariance difference 8.67454792650748, sinkhorn epsilon 0.0\n",
      "Iteration  963\n",
      "Training: loss 4.626750946044922, covariance difference 1.016335129737854\n",
      "Validation: loss 5.722104083005624, covariance difference 8.846211292314386, sinkhorn epsilon 2.2997894510095227e-14\n",
      "Iteration  964\n",
      "Training: loss 4.682377815246582, covariance difference 1.0279340744018555\n",
      "Validation: loss 5.649897467351223, covariance difference 8.697676330232717, sinkhorn epsilon 0.0\n",
      "Iteration  965\n",
      "Training: loss 4.610194206237793, covariance difference 1.014408826828003\n",
      "Validation: loss 5.710394799086567, covariance difference 8.756571027538527, sinkhorn epsilon 0.0\n",
      "Iteration  966\n",
      "Training: loss 4.67066764831543, covariance difference 1.0236611366271973\n",
      "Validation: loss 5.674675851817652, covariance difference 8.802820036503702, sinkhorn epsilon 0.0\n",
      "Iteration  967\n",
      "Training: loss 4.634944915771484, covariance difference 1.0181949138641357\n",
      "Validation: loss 5.632334452390894, covariance difference 8.46387104106972, sinkhorn epsilon 6.226236171208145e-14\n",
      "Iteration  968\n",
      "Training: loss 4.5926079750061035, covariance difference 1.010627269744873\n",
      "Validation: loss 5.633292149846135, covariance difference 8.476541828820984, sinkhorn epsilon 0.0\n",
      "Iteration  969\n",
      "Training: loss 4.593562126159668, covariance difference 1.010280966758728\n",
      "Validation: loss 5.646491150598663, covariance difference 8.57916219455771, sinkhorn epsilon 0.0\n",
      "Iteration  970\n",
      "Training: loss 4.6067633628845215, covariance difference 1.0138797760009766\n",
      "Validation: loss 5.715873587331902, covariance difference 8.691611759621408, sinkhorn epsilon 0.0\n",
      "Iteration  971\n",
      "Training: loss 4.6761603355407715, covariance difference 1.0250431299209595\n",
      "Validation: loss 5.692315277620524, covariance difference 8.438135455990265, sinkhorn epsilon 0.0\n",
      "Iteration  972\n",
      "Training: loss 4.652585029602051, covariance difference 1.020930528640747\n",
      "Validation: loss 5.651311955931677, covariance difference 8.494094089272116, sinkhorn epsilon 0.0\n",
      "Iteration  973\n",
      "Training: loss 4.611578941345215, covariance difference 1.0136997699737549\n",
      "Validation: loss 5.673827165375835, covariance difference 8.721863187716094, sinkhorn epsilon 0.0\n",
      "Iteration  974\n",
      "Training: loss 4.634105682373047, covariance difference 1.0195187330245972\n",
      "Validation: loss 5.667277895559945, covariance difference 8.685839850578056, sinkhorn epsilon 0.0\n",
      "Iteration  975\n",
      "Training: loss 4.6275506019592285, covariance difference 1.018211007118225\n",
      "Validation: loss 5.619830527297965, covariance difference 8.642100234795757, sinkhorn epsilon 0.0\n",
      "Iteration  976\n",
      "Training: loss 4.580099105834961, covariance difference 1.0087605714797974\n",
      "Validation: loss 5.6107607476737495, covariance difference 8.355778730797237, sinkhorn epsilon 0.0\n",
      "Iteration  977\n",
      "Training: loss 4.57103157043457, covariance difference 1.005363941192627\n",
      "Validation: loss 5.703397557315323, covariance difference 8.779366768672896, sinkhorn epsilon 0.0\n",
      "Iteration  978\n",
      "Training: loss 4.663673400878906, covariance difference 1.0211645364761353\n",
      "Validation: loss 5.611370420780882, covariance difference 8.310166800764751, sinkhorn epsilon 0.0\n",
      "Iteration  979\n",
      "Training: loss 4.571643829345703, covariance difference 1.0065973997116089\n",
      "Validation: loss 5.617918768729645, covariance difference 8.361633882190018, sinkhorn epsilon 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  980\n",
      "Training: loss 4.578217029571533, covariance difference 1.0084819793701172\n",
      "Validation: loss 5.5400989050203595, covariance difference 8.222862533261877, sinkhorn epsilon 0.0\n",
      "Iteration  981\n",
      "Training: loss 4.500354290008545, covariance difference 0.9928858280181885\n",
      "Validation: loss 5.692817496878149, covariance difference 8.708092123081945, sinkhorn epsilon 0.0\n",
      "Iteration  982\n",
      "Training: loss 4.6530842781066895, covariance difference 1.0210998058319092\n",
      "Validation: loss 5.604693090980367, covariance difference 8.384117940462884, sinkhorn epsilon 0.0\n",
      "Iteration  983\n",
      "Training: loss 4.564962863922119, covariance difference 1.005588173866272\n",
      "Validation: loss 5.696536259170599, covariance difference 8.855763826225946, sinkhorn epsilon 0.0\n",
      "Iteration  984\n",
      "Training: loss 4.656809329986572, covariance difference 1.0222846269607544\n",
      "Validation: loss 5.677610215696717, covariance difference 8.564993569250673, sinkhorn epsilon 0.0\n",
      "Iteration  985\n",
      "Training: loss 4.6378960609436035, covariance difference 1.0171895027160645\n",
      "Validation: loss 5.661031490974815, covariance difference 8.670793661239605, sinkhorn epsilon 0.0\n",
      "Iteration  986\n",
      "Training: loss 4.621306419372559, covariance difference 1.0152732133865356\n",
      "Validation: loss 5.676375685248816, covariance difference 8.795602539783106, sinkhorn epsilon 0.0\n",
      "Iteration  987\n",
      "Training: loss 4.636645317077637, covariance difference 1.0202667713165283\n",
      "Validation: loss 5.58515221253731, covariance difference 8.453028408599708, sinkhorn epsilon 0.0\n",
      "Iteration  988\n",
      "Training: loss 4.545422554016113, covariance difference 1.0023045539855957\n",
      "Validation: loss 5.7230490577099635, covariance difference 8.785603146328313, sinkhorn epsilon 0.0\n",
      "Iteration  989\n",
      "Training: loss 4.683324813842773, covariance difference 1.027063012123108\n",
      "Validation: loss 5.5876714207203015, covariance difference 8.4250943487437, sinkhorn epsilon 4.2395721865617874e-14\n",
      "Iteration  990\n",
      "Training: loss 4.547940254211426, covariance difference 1.0015324354171753\n",
      "Validation: loss 5.614990035198819, covariance difference 8.827961246768295, sinkhorn epsilon 0.0\n",
      "Iteration  991\n",
      "Training: loss 4.575263023376465, covariance difference 1.0064541101455688\n",
      "Validation: loss 5.675961742417337, covariance difference 8.545297619984035, sinkhorn epsilon 0.0\n",
      "Iteration  992\n",
      "Training: loss 4.636231422424316, covariance difference 1.0185412168502808\n",
      "Validation: loss 5.694664219357301, covariance difference 8.66802550692462, sinkhorn epsilon 0.0\n",
      "Iteration  993\n",
      "Training: loss 4.6549530029296875, covariance difference 1.0233418941497803\n",
      "Validation: loss 5.624799645214805, covariance difference 8.680478993881511, sinkhorn epsilon 0.0\n",
      "Iteration  994\n",
      "Training: loss 4.58505392074585, covariance difference 1.0089629888534546\n",
      "Validation: loss 5.568997174021463, covariance difference 8.373286279463226, sinkhorn epsilon 0.0\n",
      "Iteration  995\n",
      "Training: loss 4.529262542724609, covariance difference 1.0004546642303467\n",
      "Validation: loss 5.669475357724022, covariance difference 8.70415438447298, sinkhorn epsilon 0.0\n",
      "Iteration  996\n",
      "Training: loss 4.629744052886963, covariance difference 1.0163871049880981\n",
      "Validation: loss 5.733394508429933, covariance difference 8.764003308358488, sinkhorn epsilon 0.0\n",
      "Iteration  997\n",
      "Training: loss 4.693666458129883, covariance difference 1.0273066759109497\n",
      "Validation: loss 5.640159674139952, covariance difference 8.62517125962527, sinkhorn epsilon 0.0\n",
      "Iteration  998\n",
      "Training: loss 4.600428581237793, covariance difference 1.0116654634475708\n",
      "Validation: loss 5.65025859426588, covariance difference 8.535609875883738, sinkhorn epsilon 2.859573374944065e-14\n",
      "Iteration  999\n",
      "Training: loss 4.610530376434326, covariance difference 1.0139650106430054\n",
      "Validation: loss 5.620148603319987, covariance difference 8.381565020825036, sinkhorn epsilon 0.0\n",
      "Iteration  1000\n",
      "Training: loss 4.580417156219482, covariance difference 1.0079541206359863\n",
      "Validation: loss 5.6504278142736695, covariance difference 8.698848653456437, sinkhorn epsilon 0.0\n",
      "Iteration  1001\n",
      "Training: loss 4.610695838928223, covariance difference 1.0131968259811401\n",
      "Validation: loss 5.699379773418942, covariance difference 8.814839418808965, sinkhorn epsilon 3.3757301787220484e-14\n",
      "Iteration  1002\n",
      "Training: loss 4.659651279449463, covariance difference 1.0222982168197632\n",
      "Validation: loss 5.687826365088063, covariance difference 8.754817134700092, sinkhorn epsilon 8.034858445353018e-14\n",
      "Iteration  1003\n",
      "Training: loss 4.648094654083252, covariance difference 1.0193274021148682\n",
      "Validation: loss 5.692069070795974, covariance difference 8.781353386540994, sinkhorn epsilon 4.191166353332746e-14\n",
      "Iteration  1004\n",
      "Training: loss 4.652338981628418, covariance difference 1.022239089012146\n",
      "Validation: loss 5.7031585462132774, covariance difference 8.783300383107882, sinkhorn epsilon 0.0\n",
      "Iteration  1005\n",
      "Training: loss 4.663426399230957, covariance difference 1.0213322639465332\n",
      "Validation: loss 5.712542974593538, covariance difference 8.757132334351772, sinkhorn epsilon 0.0\n",
      "Iteration  1006\n",
      "Training: loss 4.6728129386901855, covariance difference 1.0249152183532715\n",
      "Validation: loss 5.693403976294498, covariance difference 8.673990597498578, sinkhorn epsilon 0.0\n",
      "Iteration  1007\n",
      "Training: loss 4.6536760330200195, covariance difference 1.022702693939209\n",
      "Validation: loss 5.6492185203885885, covariance difference 8.452169968129017, sinkhorn epsilon 0.0\n",
      "Iteration  1008\n",
      "Training: loss 4.609488487243652, covariance difference 1.0114730596542358\n",
      "Validation: loss 5.68502891800851, covariance difference 8.710891014211363, sinkhorn epsilon 0.0\n",
      "Iteration  1009\n",
      "Training: loss 4.645301818847656, covariance difference 1.0202367305755615\n",
      "Validation: loss 5.679533095784597, covariance difference 8.713776573623305, sinkhorn epsilon 0.0\n",
      "Iteration  1010\n",
      "Training: loss 4.639802932739258, covariance difference 1.01907479763031\n",
      "Validation: loss 5.648967405761626, covariance difference 8.75552444734002, sinkhorn epsilon 0.0\n",
      "Iteration  1011\n",
      "Training: loss 4.609238624572754, covariance difference 1.0135536193847656\n",
      "Validation: loss 5.6533890495923655, covariance difference 8.51923127005987, sinkhorn epsilon 3.2595929180384894e-14\n",
      "Iteration  1012\n",
      "Training: loss 4.6136579513549805, covariance difference 1.0154496431350708\n",
      "Validation: loss 5.5794068420696386, covariance difference 8.410264454124112, sinkhorn epsilon 0.0\n",
      "Iteration  1013\n",
      "Training: loss 4.539677143096924, covariance difference 0.9991831183433533\n",
      "Validation: loss 5.697181061214402, covariance difference 8.72434184091842, sinkhorn epsilon 0.0\n",
      "Iteration  1014\n",
      "Training: loss 4.657449245452881, covariance difference 1.020500898361206\n",
      "Validation: loss 5.66743006494284, covariance difference 8.797775134552055, sinkhorn epsilon 0.0\n",
      "Iteration  1015\n",
      "Training: loss 4.6277008056640625, covariance difference 1.016101598739624\n",
      "Validation: loss 5.544751774143767, covariance difference 8.386896902191967, sinkhorn epsilon 0.0\n",
      "Iteration  1016\n",
      "Training: loss 4.505032539367676, covariance difference 0.9939243197441101\n",
      "Validation: loss 5.646391004839421, covariance difference 8.807121388830204, sinkhorn epsilon 5.1250758788815446e-14\n",
      "Iteration  1017\n",
      "Training: loss 4.606660842895508, covariance difference 1.0121676921844482\n",
      "Validation: loss 5.583562668278626, covariance difference 8.431660375675019, sinkhorn epsilon 0.0\n",
      "Iteration  1018\n",
      "Training: loss 4.543828010559082, covariance difference 1.001721739768982\n",
      "Validation: loss 5.657162017811408, covariance difference 8.724478295465131, sinkhorn epsilon 0.0\n",
      "Iteration  1019\n",
      "Training: loss 4.617443084716797, covariance difference 1.0130550861358643\n",
      "Validation: loss 5.644254328945095, covariance difference 8.415694743209, sinkhorn epsilon 0.0\n",
      "Iteration  1020\n",
      "Training: loss 4.604523181915283, covariance difference 1.0136719942092896\n",
      "Validation: loss 5.606678879734204, covariance difference 8.664072858464754, sinkhorn epsilon 0.0\n",
      "Iteration  1021\n",
      "Training: loss 4.566956043243408, covariance difference 1.0046353340148926\n",
      "Validation: loss 5.614547281674078, covariance difference 8.602475225633262, sinkhorn epsilon 0.0\n",
      "Iteration  1022\n",
      "Training: loss 4.574819564819336, covariance difference 1.0077848434448242\n",
      "Validation: loss 5.676313668814203, covariance difference 8.484761655852576, sinkhorn epsilon 1.0067150198803984e-13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  1023\n",
      "Training: loss 4.636580944061279, covariance difference 1.019531011581421\n",
      "Validation: loss 5.601540508376425, covariance difference 8.774568438443074, sinkhorn epsilon 0.0\n",
      "Iteration  1024\n",
      "Training: loss 4.56181001663208, covariance difference 1.006799340248108\n",
      "Validation: loss 5.699966008622253, covariance difference 8.670658495159044, sinkhorn epsilon 0.0\n",
      "Iteration  1025\n",
      "Training: loss 4.66023588180542, covariance difference 1.0224114656448364\n",
      "Validation: loss 5.577486693665994, covariance difference 8.503767484561449, sinkhorn epsilon 0.0\n",
      "Iteration  1026\n",
      "Training: loss 4.537755489349365, covariance difference 1.0012966394424438\n",
      "Validation: loss 5.621157956614452, covariance difference 8.48003541314291, sinkhorn epsilon 5.898662910140472e-14\n",
      "Iteration  1027\n",
      "Training: loss 4.581439018249512, covariance difference 1.0076892375946045\n",
      "Validation: loss 5.622528522316425, covariance difference 8.572985038364596, sinkhorn epsilon 0.0\n",
      "Iteration  1028\n",
      "Training: loss 4.582797050476074, covariance difference 1.009648084640503\n",
      "Validation: loss 5.679960551406652, covariance difference 8.591354978308065, sinkhorn epsilon 0.0\n",
      "Iteration  1029\n",
      "Training: loss 4.640228748321533, covariance difference 1.0201778411865234\n",
      "Validation: loss 5.645297740302376, covariance difference 8.421363977129902, sinkhorn epsilon 4.277913351533907e-14\n",
      "Iteration  1030\n",
      "Training: loss 4.605569839477539, covariance difference 1.0122992992401123\n",
      "Validation: loss 5.678011264949152, covariance difference 8.542235871260196, sinkhorn epsilon 1.7682125893181808e-14\n",
      "Iteration  1031\n",
      "Training: loss 4.638316631317139, covariance difference 1.0181742906570435\n",
      "Validation: loss 5.6585494757848025, covariance difference 8.574537080442758, sinkhorn epsilon 0.0\n",
      "Iteration  1032\n",
      "Training: loss 4.618821620941162, covariance difference 1.0161917209625244\n",
      "Validation: loss 5.5949205730623515, covariance difference 8.469566953171165, sinkhorn epsilon 0.0\n",
      "Iteration  1033\n",
      "Training: loss 4.555188179016113, covariance difference 1.0019199848175049\n",
      "Validation: loss 5.636406603019467, covariance difference 8.5164197556972, sinkhorn epsilon 0.0\n",
      "Iteration  1034\n",
      "Training: loss 4.596676826477051, covariance difference 1.0107386112213135\n",
      "Validation: loss 5.664446538146268, covariance difference 8.511385887591926, sinkhorn epsilon 0.0\n",
      "Iteration  1035\n",
      "Training: loss 4.62472677230835, covariance difference 1.0147043466567993\n",
      "Validation: loss 5.657963936291641, covariance difference 8.459397608763224, sinkhorn epsilon 0.0\n",
      "Iteration  1036\n",
      "Training: loss 4.618234634399414, covariance difference 1.0144816637039185\n",
      "Validation: loss 5.711058164027401, covariance difference 8.681672140589923, sinkhorn epsilon 4.302366944701807e-14\n",
      "Iteration  1037\n",
      "Training: loss 4.671327590942383, covariance difference 1.0261057615280151\n",
      "Validation: loss 5.66955444009421, covariance difference 8.955026549831175, sinkhorn epsilon 8.853036192329772e-14\n",
      "Iteration  1038\n",
      "Training: loss 4.629825115203857, covariance difference 1.0173345804214478\n",
      "Validation: loss 5.6443472746504995, covariance difference 8.509427727758627, sinkhorn epsilon 0.0\n",
      "Iteration  1039\n",
      "Training: loss 4.604615211486816, covariance difference 1.0126667022705078\n",
      "Validation: loss 5.654937614964165, covariance difference 8.486792144212233, sinkhorn epsilon 3.584768834671039e-14\n",
      "Iteration  1040\n",
      "Training: loss 4.615206718444824, covariance difference 1.0147440433502197\n",
      "Validation: loss 5.632605785861295, covariance difference 8.71699244185793, sinkhorn epsilon 0.0\n",
      "Iteration  1041\n",
      "Training: loss 4.592883586883545, covariance difference 1.0111674070358276\n",
      "Validation: loss 5.6014960811267995, covariance difference 8.321020218814697, sinkhorn epsilon 0.0\n",
      "Iteration  1042\n",
      "Training: loss 4.561767101287842, covariance difference 1.0061473846435547\n",
      "Validation: loss 5.653858017150413, covariance difference 8.521193918002547, sinkhorn epsilon 0.0\n",
      "Iteration  1043\n",
      "Training: loss 4.614128112792969, covariance difference 1.0153051614761353\n",
      "Validation: loss 5.7024320596402145, covariance difference 8.681849466721397, sinkhorn epsilon 0.0\n",
      "Iteration  1044\n",
      "Training: loss 4.662701606750488, covariance difference 1.0220363140106201\n",
      "Validation: loss 5.585140478413669, covariance difference 8.845319921610095, sinkhorn epsilon 7.755617458674604e-14\n",
      "Iteration  1045\n",
      "Training: loss 4.54541540145874, covariance difference 1.0017832517623901\n",
      "Validation: loss 5.634655589968905, covariance difference 8.47935846152355, sinkhorn epsilon 5.6029436302586965e-14\n",
      "Iteration  1046\n",
      "Training: loss 4.5949296951293945, covariance difference 1.0107358694076538\n",
      "Validation: loss 5.672675234274203, covariance difference 8.707421398650498, sinkhorn epsilon 0.0\n",
      "Iteration  1047\n",
      "Training: loss 4.6329450607299805, covariance difference 1.0171184539794922\n",
      "Validation: loss 5.6343993614020125, covariance difference 8.620917175294057, sinkhorn epsilon 0.0\n",
      "Iteration  1048\n",
      "Training: loss 4.594664096832275, covariance difference 1.009692907333374\n",
      "Validation: loss 5.656363181327826, covariance difference 8.650994582315489, sinkhorn epsilon 0.0\n",
      "Iteration  1049\n",
      "Training: loss 4.616640567779541, covariance difference 1.0162779092788696\n",
      "Validation: loss 5.651548101779798, covariance difference 8.561202955565566, sinkhorn epsilon 0.0\n",
      "Iteration  1050\n",
      "Training: loss 4.611812114715576, covariance difference 1.013016700744629\n",
      "Validation: loss 5.62683784130518, covariance difference 8.4456534499048, sinkhorn epsilon 0.0\n",
      "Iteration  1051\n",
      "Training: loss 4.587105751037598, covariance difference 1.0082141160964966\n",
      "Validation: loss 5.679143787962916, covariance difference 8.662803614998834, sinkhorn epsilon 0.0\n",
      "Iteration  1052\n",
      "Training: loss 4.63941764831543, covariance difference 1.017529845237732\n",
      "Validation: loss 5.670558691142395, covariance difference 8.613852146325481, sinkhorn epsilon 1.8301176562462512e-14\n",
      "Iteration  1053\n",
      "Training: loss 4.630840301513672, covariance difference 1.0164631605148315\n",
      "Validation: loss 5.675004583559394, covariance difference 8.761985113017259, sinkhorn epsilon 3.7907548321724354e-14\n",
      "Iteration  1054\n",
      "Training: loss 4.635284900665283, covariance difference 1.0177675485610962\n",
      "Validation: loss 5.653597631157108, covariance difference 8.589776301172007, sinkhorn epsilon 0.0\n",
      "Iteration  1055\n",
      "Training: loss 4.6138715744018555, covariance difference 1.0167315006256104\n",
      "Validation: loss 5.742346066620675, covariance difference 8.554420686674531, sinkhorn epsilon 0.0\n",
      "Iteration  1056\n",
      "Training: loss 4.7026166915893555, covariance difference 1.0303277969360352\n",
      "Validation: loss 5.6949468947890844, covariance difference 8.718760104777065, sinkhorn epsilon 0.0\n",
      "Iteration  1057\n",
      "Training: loss 4.655217170715332, covariance difference 1.0225892066955566\n",
      "Validation: loss 5.63687661091733, covariance difference 8.646530934485678, sinkhorn epsilon 0.0\n",
      "Iteration  1058\n",
      "Training: loss 4.597140789031982, covariance difference 1.0122902393341064\n",
      "Validation: loss 5.669010510117235, covariance difference 8.554655965318787, sinkhorn epsilon 0.0\n",
      "Iteration  1059\n",
      "Training: loss 4.629281520843506, covariance difference 1.0179322957992554\n",
      "Validation: loss 5.659989210489984, covariance difference 8.67526305199455, sinkhorn epsilon 0.0\n",
      "Iteration  1060\n",
      "Training: loss 4.620258331298828, covariance difference 1.0162720680236816\n",
      "Validation: loss 5.640652140873673, covariance difference 8.617985508656854, sinkhorn epsilon 0.0\n",
      "Iteration  1061\n",
      "Training: loss 4.60092830657959, covariance difference 1.0150527954101562\n",
      "Validation: loss 5.691258952703416, covariance difference 8.853394274835834, sinkhorn epsilon 7.90049263692154e-14\n",
      "Iteration  1062\n",
      "Training: loss 4.651529788970947, covariance difference 1.0206457376480103\n",
      "Validation: loss 5.646215868659635, covariance difference 8.650444503714743, sinkhorn epsilon 0.0\n",
      "Iteration  1063\n",
      "Training: loss 4.606483459472656, covariance difference 1.0140650272369385\n",
      "Validation: loss 5.640695243676812, covariance difference 8.596250693147148, sinkhorn epsilon 0.0\n",
      "Iteration  1064\n",
      "Training: loss 4.600964546203613, covariance difference 1.0126895904541016\n",
      "Validation: loss 5.608797269254232, covariance difference 8.72937788354401, sinkhorn epsilon 0.0\n",
      "Iteration  1065\n",
      "Training: loss 4.569070339202881, covariance difference 1.00644850730896\n",
      "Validation: loss 5.663822600746092, covariance difference 8.582408082197205, sinkhorn epsilon 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  1066\n",
      "Training: loss 4.624094486236572, covariance difference 1.0163718461990356\n",
      "Validation: loss 5.70084101123124, covariance difference 8.845200174103859, sinkhorn epsilon 0.0\n",
      "Iteration  1067\n",
      "Training: loss 4.6611223220825195, covariance difference 1.024141788482666\n",
      "Validation: loss 5.633729576484183, covariance difference 8.457465121455481, sinkhorn epsilon 0.0\n",
      "Iteration  1068\n",
      "Training: loss 4.594005107879639, covariance difference 1.0101025104522705\n",
      "Validation: loss 5.595378693960927, covariance difference 8.641425210666416, sinkhorn epsilon 0.0\n",
      "Iteration  1069\n",
      "Training: loss 4.555655479431152, covariance difference 1.0040931701660156\n",
      "Validation: loss 5.643443042345563, covariance difference 8.651667247117388, sinkhorn epsilon 0.0\n",
      "Iteration  1070\n",
      "Training: loss 4.603716850280762, covariance difference 1.0124560594558716\n",
      "Validation: loss 5.665334459051882, covariance difference 8.635645789925398, sinkhorn epsilon 0.0\n",
      "Iteration  1071\n",
      "Training: loss 4.625603199005127, covariance difference 1.0162514448165894\n",
      "Validation: loss 5.612615585932864, covariance difference 8.681114233247637, sinkhorn epsilon 0.0\n",
      "Iteration  1072\n",
      "Training: loss 4.572887420654297, covariance difference 1.0048376321792603\n",
      "Validation: loss 5.651829871927051, covariance difference 8.6200674000339, sinkhorn epsilon 0.0\n",
      "Iteration  1073\n",
      "Training: loss 4.612098693847656, covariance difference 1.0123264789581299\n",
      "Validation: loss 5.742041888322104, covariance difference 8.801711542432535, sinkhorn epsilon 0.0\n",
      "Iteration  1074\n",
      "Training: loss 4.702310562133789, covariance difference 1.0305637121200562\n",
      "Validation: loss 5.648680909156555, covariance difference 8.605156538891105, sinkhorn epsilon 7.011768225398341e-14\n",
      "Iteration  1075\n",
      "Training: loss 4.608954429626465, covariance difference 1.013712763786316\n",
      "Validation: loss 5.669871345028725, covariance difference 8.752627234723969, sinkhorn epsilon 0.0\n",
      "Iteration  1076\n",
      "Training: loss 4.630146026611328, covariance difference 1.0168185234069824\n",
      "Validation: loss 5.647406902692953, covariance difference 8.488748133863425, sinkhorn epsilon 0.0\n",
      "Iteration  1077\n",
      "Training: loss 4.607678413391113, covariance difference 1.010414719581604\n",
      "Validation: loss 5.743797216361868, covariance difference 8.80765725545154, sinkhorn epsilon 0.0\n",
      "Iteration  1078\n",
      "Training: loss 4.7040696144104, covariance difference 1.0307620763778687\n",
      "Validation: loss 5.595615275695298, covariance difference 8.644777564458272, sinkhorn epsilon 0.0\n",
      "Iteration  1079\n",
      "Training: loss 4.5559282302856445, covariance difference 1.005110740661621\n",
      "Validation: loss 5.6367173278519385, covariance difference 8.688076334107146, sinkhorn epsilon 0.0\n",
      "Iteration  1080\n",
      "Training: loss 4.596994400024414, covariance difference 1.010108232498169\n",
      "Validation: loss 5.6697977689037, covariance difference 8.710077221768751, sinkhorn epsilon 0.0\n",
      "Iteration  1081\n",
      "Training: loss 4.630069255828857, covariance difference 1.0187019109725952\n",
      "Validation: loss 5.632330053232757, covariance difference 8.685067658069064, sinkhorn epsilon 0.0\n",
      "Iteration  1082\n",
      "Training: loss 4.592598915100098, covariance difference 1.012542486190796\n",
      "Validation: loss 5.681172076382653, covariance difference 8.48088693995066, sinkhorn epsilon 0.0\n",
      "Iteration  1083\n",
      "Training: loss 4.641495227813721, covariance difference 1.0187984704971313\n",
      "Validation: loss 5.603757317919467, covariance difference 8.600418771642135, sinkhorn epsilon 0.0\n",
      "Iteration  1084\n",
      "Training: loss 4.564028739929199, covariance difference 1.0050653219223022\n",
      "Validation: loss 5.662569392828437, covariance difference 8.73618641011741, sinkhorn epsilon 0.0\n",
      "Iteration  1085\n",
      "Training: loss 4.6228413581848145, covariance difference 1.016414761543274\n",
      "Validation: loss 5.613537587184363, covariance difference 8.536523156589954, sinkhorn epsilon 1.247563313539871e-14\n",
      "Iteration  1086\n",
      "Training: loss 4.57381534576416, covariance difference 1.0074808597564697\n",
      "Validation: loss 5.706556416908651, covariance difference 8.546705118961576, sinkhorn epsilon 0.0\n",
      "Iteration  1087\n",
      "Training: loss 4.6668267250061035, covariance difference 1.0219649076461792\n",
      "Validation: loss 5.660034426873589, covariance difference 8.657395356128259, sinkhorn epsilon 0.0\n",
      "Iteration  1088\n",
      "Training: loss 4.620303153991699, covariance difference 1.0161973237991333\n",
      "Validation: loss 5.6881634414923505, covariance difference 8.560331587862677, sinkhorn epsilon 0.0\n",
      "Iteration  1089\n",
      "Training: loss 4.648433685302734, covariance difference 1.0203039646148682\n",
      "Validation: loss 5.598361862900529, covariance difference 8.608227167199948, sinkhorn epsilon 0.0\n",
      "Iteration  1090\n",
      "Training: loss 4.55863094329834, covariance difference 1.005189299583435\n",
      "Validation: loss 5.589969955259987, covariance difference 8.48365700734916, sinkhorn epsilon 0.0\n",
      "Iteration  1091\n",
      "Training: loss 4.5502400398254395, covariance difference 1.0013906955718994\n",
      "Validation: loss 5.737521412450924, covariance difference 8.463204129903074, sinkhorn epsilon 0.0\n",
      "Iteration  1092\n",
      "Training: loss 4.697789669036865, covariance difference 1.0315338373184204\n",
      "Validation: loss 5.669168960021154, covariance difference 8.661115439304165, sinkhorn epsilon 0.0\n",
      "Iteration  1093\n",
      "Training: loss 4.6294450759887695, covariance difference 1.0174078941345215\n",
      "Validation: loss 5.701604117117032, covariance difference 8.761177343892664, sinkhorn epsilon 0.0\n",
      "Iteration  1094\n",
      "Training: loss 4.661874771118164, covariance difference 1.0231324434280396\n",
      "Validation: loss 5.6724006078410945, covariance difference 8.75485431072329, sinkhorn epsilon 6.981984976071874e-14\n",
      "Iteration  1095\n",
      "Training: loss 4.632668495178223, covariance difference 1.0187410116195679\n",
      "Validation: loss 5.566075142916489, covariance difference 8.35779959587466, sinkhorn epsilon 0.0\n",
      "Iteration  1096\n",
      "Training: loss 4.526341438293457, covariance difference 0.9997397661209106\n",
      "Validation: loss 5.663426381037901, covariance difference 8.81433777395921, sinkhorn epsilon 0.0\n",
      "Iteration  1097\n",
      "Training: loss 4.6236958503723145, covariance difference 1.0180848836898804\n",
      "Validation: loss 5.598044582291924, covariance difference 8.593486736296864, sinkhorn epsilon 0.0\n",
      "Iteration  1098\n",
      "Training: loss 4.558314323425293, covariance difference 1.0051482915878296\n",
      "Validation: loss 5.667482178267742, covariance difference 8.548516671961266, sinkhorn epsilon 0.0\n",
      "Iteration  1099\n",
      "Training: loss 4.627758026123047, covariance difference 1.0175999402999878\n",
      "Validation: loss 5.659773323779539, covariance difference 8.662076550911431, sinkhorn epsilon 0.0\n",
      "Iteration  1100\n",
      "Training: loss 4.620043754577637, covariance difference 1.0162333250045776\n",
      "Validation: loss 5.60890537956371, covariance difference 8.619948207993799, sinkhorn epsilon 0.0\n",
      "Iteration  1101\n",
      "Training: loss 4.569173812866211, covariance difference 1.0076489448547363\n",
      "Validation: loss 5.579383806783159, covariance difference 8.527160624169834, sinkhorn epsilon 0.0\n",
      "Iteration  1102\n",
      "Training: loss 4.539652347564697, covariance difference 1.0020246505737305\n",
      "Validation: loss 5.680893121990613, covariance difference 8.66615228641127, sinkhorn epsilon 0.0\n",
      "Iteration  1103\n",
      "Training: loss 4.6411638259887695, covariance difference 1.0197607278823853\n",
      "Validation: loss 5.711001048667595, covariance difference 8.75138487402044, sinkhorn epsilon 0.0\n",
      "Iteration  1104\n",
      "Training: loss 4.671271324157715, covariance difference 1.026100754737854\n",
      "Validation: loss 5.6446958939342675, covariance difference 8.598989388021016, sinkhorn epsilon 0.0\n",
      "Iteration  1105\n",
      "Training: loss 4.6049652099609375, covariance difference 1.011235237121582\n",
      "Validation: loss 5.581352357235199, covariance difference 8.397800956710777, sinkhorn epsilon 0.0\n",
      "Iteration  1106\n",
      "Training: loss 4.541622161865234, covariance difference 1.0023140907287598\n",
      "Validation: loss 5.697036423951648, covariance difference 8.920656685233652, sinkhorn epsilon 0.0\n",
      "Iteration  1107\n",
      "Training: loss 4.657303810119629, covariance difference 1.0210931301116943\n",
      "Validation: loss 5.732379448088533, covariance difference 8.776291809080742, sinkhorn epsilon 0.0\n",
      "Iteration  1108\n",
      "Training: loss 4.692652702331543, covariance difference 1.0283942222595215\n",
      "Validation: loss 5.673018671327561, covariance difference 8.599997768139216, sinkhorn epsilon 0.0\n",
      "Iteration  1109\n",
      "Training: loss 4.633286476135254, covariance difference 1.0185879468917847\n",
      "Validation: loss 5.644124533155131, covariance difference 8.747326640463612, sinkhorn epsilon 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  1110\n",
      "Training: loss 4.604394912719727, covariance difference 1.012613296508789\n",
      "Validation: loss 5.686685676389507, covariance difference 8.577983990659597, sinkhorn epsilon 0.0\n",
      "Iteration  1111\n",
      "Training: loss 4.646954536437988, covariance difference 1.0215296745300293\n",
      "Validation: loss 5.6188506761534, covariance difference 8.576957396613532, sinkhorn epsilon 0.0\n",
      "Iteration  1112\n",
      "Training: loss 4.579127788543701, covariance difference 1.008419156074524\n",
      "Validation: loss 5.66100841070106, covariance difference 8.668377095340999, sinkhorn epsilon 0.0\n",
      "Iteration  1113\n",
      "Training: loss 4.621282577514648, covariance difference 1.0159430503845215\n",
      "Validation: loss 5.672412199186362, covariance difference 8.592215499544036, sinkhorn epsilon 6.286383977041911e-14\n",
      "Iteration  1114\n",
      "Training: loss 4.632684230804443, covariance difference 1.0173498392105103\n",
      "Validation: loss 5.616968810576147, covariance difference 8.394047957208754, sinkhorn epsilon 0.0\n",
      "Iteration  1115\n",
      "Training: loss 4.577238082885742, covariance difference 1.0077929496765137\n",
      "Validation: loss 5.712884560367158, covariance difference 8.882139306537017, sinkhorn epsilon 4.100464740544828e-14\n",
      "Iteration  1116\n",
      "Training: loss 4.673152923583984, covariance difference 1.0235539674758911\n",
      "Validation: loss 5.733137332873941, covariance difference 8.823176020802832, sinkhorn epsilon 0.0\n",
      "Iteration  1117\n",
      "Training: loss 4.693406105041504, covariance difference 1.0299044847488403\n",
      "Validation: loss 5.6159612012062015, covariance difference 8.71564576288113, sinkhorn epsilon 0.0\n",
      "Iteration  1118\n",
      "Training: loss 4.576227188110352, covariance difference 1.007307529449463\n",
      "Validation: loss 5.662345552177683, covariance difference 8.518042600081628, sinkhorn epsilon 0.0\n",
      "Iteration  1119\n",
      "Training: loss 4.622615337371826, covariance difference 1.015600323677063\n",
      "Validation: loss 5.6823969667611225, covariance difference 8.34689612292215, sinkhorn epsilon 0.0\n",
      "Iteration  1120\n",
      "Training: loss 4.642679691314697, covariance difference 1.018121600151062\n",
      "Validation: loss 5.625950058538459, covariance difference 8.626682429734121, sinkhorn epsilon 0.0\n",
      "Iteration  1121\n",
      "Training: loss 4.586236953735352, covariance difference 1.0101288557052612\n",
      "Validation: loss 5.608183709395296, covariance difference 8.384324218981154, sinkhorn epsilon 0.0\n",
      "Iteration  1122\n",
      "Training: loss 4.568451404571533, covariance difference 1.0051703453063965\n",
      "Validation: loss 5.686806776178491, covariance difference 8.895978543205482, sinkhorn epsilon 0.0\n",
      "Iteration  1123\n",
      "Training: loss 4.647073745727539, covariance difference 1.01953125\n",
      "Validation: loss 5.676802556018291, covariance difference 8.689534479584333, sinkhorn epsilon 0.0\n",
      "Iteration  1124\n",
      "Training: loss 4.637070655822754, covariance difference 1.0189710855484009\n",
      "Validation: loss 5.571796221323559, covariance difference 8.45694658948112, sinkhorn epsilon 0.0\n",
      "Iteration  1125\n",
      "Training: loss 4.532066345214844, covariance difference 0.9998627305030823\n",
      "Validation: loss 5.674238246681192, covariance difference 8.625180306487092, sinkhorn epsilon 0.0\n",
      "Iteration  1126\n",
      "Training: loss 4.6345109939575195, covariance difference 1.018548607826233\n",
      "Validation: loss 5.644342704360808, covariance difference 8.638840371382653, sinkhorn epsilon 0.0\n",
      "Iteration  1127\n",
      "Training: loss 4.604612350463867, covariance difference 1.0124921798706055\n",
      "Validation: loss 5.652430948428188, covariance difference 8.465788402520117, sinkhorn epsilon 0.0\n",
      "Iteration  1128\n",
      "Training: loss 4.612700939178467, covariance difference 1.0133737325668335\n",
      "Validation: loss 5.657610193272347, covariance difference 8.863741115736802, sinkhorn epsilon 0.0\n",
      "Iteration  1129\n",
      "Training: loss 4.617885589599609, covariance difference 1.0136675834655762\n",
      "Validation: loss 5.690431103053394, covariance difference 8.702516740712495, sinkhorn epsilon 8.888656162255018e-14\n",
      "Iteration  1130\n",
      "Training: loss 4.65070915222168, covariance difference 1.0223438739776611\n",
      "Validation: loss 5.7161790910038555, covariance difference 8.79097195185351, sinkhorn epsilon 0.0\n",
      "Iteration  1131\n",
      "Training: loss 4.676448822021484, covariance difference 1.0247310400009155\n",
      "Validation: loss 5.699220440523495, covariance difference 8.767762068050144, sinkhorn epsilon 0.0\n",
      "Iteration  1132\n",
      "Training: loss 4.659493446350098, covariance difference 1.0219190120697021\n",
      "Validation: loss 5.635171651660381, covariance difference 8.532797439375521, sinkhorn epsilon 0.0\n",
      "Iteration  1133\n",
      "Training: loss 4.595444679260254, covariance difference 1.0106029510498047\n",
      "Validation: loss 5.692972184450621, covariance difference 8.59145258037895, sinkhorn epsilon 0.0\n",
      "Iteration  1134\n",
      "Training: loss 4.653256416320801, covariance difference 1.0204963684082031\n",
      "Validation: loss 5.66423846631484, covariance difference 8.488043500379872, sinkhorn epsilon 0.0\n",
      "Iteration  1135\n",
      "Training: loss 4.624509334564209, covariance difference 1.0189661979675293\n",
      "Validation: loss 5.6636045648617435, covariance difference 8.691904489193137, sinkhorn epsilon 0.0\n",
      "Iteration  1136\n",
      "Training: loss 4.623873710632324, covariance difference 1.0186653137207031\n",
      "Validation: loss 5.69168836967032, covariance difference 8.658082434341319, sinkhorn epsilon 0.0\n",
      "Iteration  1137\n",
      "Training: loss 4.651954650878906, covariance difference 1.0221679210662842\n",
      "Validation: loss 5.690453298378757, covariance difference 8.548566740636423, sinkhorn epsilon 0.0\n",
      "Iteration  1138\n",
      "Training: loss 4.6507368087768555, covariance difference 1.0200564861297607\n",
      "Validation: loss 5.742129268054432, covariance difference 8.836565173005853, sinkhorn epsilon 0.0\n",
      "Iteration  1139\n",
      "Training: loss 4.702398777008057, covariance difference 1.0279645919799805\n",
      "Validation: loss 5.666926672930167, covariance difference 8.652421596745071, sinkhorn epsilon 0.0\n",
      "Iteration  1140\n",
      "Training: loss 4.627194404602051, covariance difference 1.016263484954834\n",
      "Validation: loss 5.614241337468445, covariance difference 8.364413634272823, sinkhorn epsilon 0.0\n",
      "Iteration  1141\n",
      "Training: loss 4.574505805969238, covariance difference 1.0078927278518677\n",
      "Validation: loss 5.647790582118457, covariance difference 8.720470143309491, sinkhorn epsilon 0.0\n",
      "Iteration  1142\n",
      "Training: loss 4.608058452606201, covariance difference 1.0139888525009155\n",
      "Validation: loss 5.6929585793249915, covariance difference 8.923399358029993, sinkhorn epsilon 0.0\n",
      "Iteration  1143\n",
      "Training: loss 4.653222560882568, covariance difference 1.0216151475906372\n",
      "Validation: loss 5.728303726416784, covariance difference 8.57659732212032, sinkhorn epsilon 4.3828878673838846e-14\n",
      "Iteration  1144\n",
      "Training: loss 4.688573360443115, covariance difference 1.0269235372543335\n",
      "Validation: loss 5.7037711177456085, covariance difference 8.840327987703597, sinkhorn epsilon 0.0\n",
      "Iteration  1145\n",
      "Training: loss 4.664034843444824, covariance difference 1.0236622095108032\n",
      "Validation: loss 5.647841316582204, covariance difference 8.458191139695462, sinkhorn epsilon 5.859667973701055e-14\n",
      "Iteration  1146\n",
      "Training: loss 4.608109951019287, covariance difference 1.0124330520629883\n",
      "Validation: loss 5.683587337473497, covariance difference 8.751228044441707, sinkhorn epsilon 0.0\n",
      "Iteration  1147\n",
      "Training: loss 4.643855571746826, covariance difference 1.020078420639038\n",
      "Validation: loss 5.6760169830719525, covariance difference 8.816735916673585, sinkhorn epsilon 0.0\n",
      "Iteration  1148\n",
      "Training: loss 4.636284828186035, covariance difference 1.0179251432418823\n",
      "Validation: loss 5.622397772198696, covariance difference 8.690314512999327, sinkhorn epsilon 0.0\n",
      "Iteration  1149\n",
      "Training: loss 4.582668781280518, covariance difference 1.0087260007858276\n",
      "Validation: loss 5.698953109703534, covariance difference 8.638438414220493, sinkhorn epsilon 2.1862157548475554e-14\n",
      "Iteration  1150\n",
      "Training: loss 4.65922737121582, covariance difference 1.023013710975647\n",
      "Validation: loss 5.697925139348863, covariance difference 8.890005110120844, sinkhorn epsilon 0.0\n",
      "Iteration  1151\n",
      "Training: loss 4.658197402954102, covariance difference 1.022007942199707\n",
      "Validation: loss 5.609851192509107, covariance difference 8.548365653923275, sinkhorn epsilon 0.0\n",
      "Iteration  1152\n",
      "Training: loss 4.570122241973877, covariance difference 1.0071980953216553\n",
      "Validation: loss 5.701215311733872, covariance difference 8.700815846490777, sinkhorn epsilon 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  1153\n",
      "Training: loss 4.6614885330200195, covariance difference 1.0225567817687988\n",
      "Validation: loss 5.728278812146346, covariance difference 8.856427340845944, sinkhorn epsilon 0.0\n",
      "Iteration  1154\n",
      "Training: loss 4.688549995422363, covariance difference 1.0274441242218018\n",
      "Validation: loss 5.633172130762212, covariance difference 8.580349877034667, sinkhorn epsilon 0.0\n",
      "Iteration  1155\n",
      "Training: loss 4.593445301055908, covariance difference 1.01112699508667\n",
      "Validation: loss 5.677700062548228, covariance difference 8.592948121773476, sinkhorn epsilon 0.0\n",
      "Iteration  1156\n",
      "Training: loss 4.637969493865967, covariance difference 1.0187788009643555\n",
      "Validation: loss 5.743401034919797, covariance difference 8.8364278796227, sinkhorn epsilon 1.5277724705362747e-14\n",
      "Iteration  1157\n",
      "Training: loss 4.703670501708984, covariance difference 1.0306365489959717\n",
      "Validation: loss 5.659024686077693, covariance difference 8.579837076409884, sinkhorn epsilon 0.0\n",
      "Iteration  1158\n",
      "Training: loss 4.619292736053467, covariance difference 1.0160765647888184\n",
      "Validation: loss 5.665945164461025, covariance difference 8.563929792257438, sinkhorn epsilon 0.0\n",
      "Iteration  1159\n",
      "Training: loss 4.626213073730469, covariance difference 1.0159112215042114\n",
      "Validation: loss 5.600604403009562, covariance difference 8.5500347187488, sinkhorn epsilon 0.0\n",
      "Iteration  1160\n",
      "Training: loss 4.560873031616211, covariance difference 1.0046523809432983\n",
      "Validation: loss 5.568235380919829, covariance difference 8.50165116498341, sinkhorn epsilon 0.0\n",
      "Iteration  1161\n",
      "Training: loss 4.528504848480225, covariance difference 0.9994378089904785\n",
      "Validation: loss 5.634833332417234, covariance difference 8.61638390489348, sinkhorn epsilon 0.0\n",
      "Iteration  1162\n",
      "Training: loss 4.595100402832031, covariance difference 1.0110762119293213\n",
      "Validation: loss 5.636991121068837, covariance difference 8.62047341961426, sinkhorn epsilon 0.0\n",
      "Iteration  1163\n",
      "Training: loss 4.597261428833008, covariance difference 1.009925365447998\n",
      "Validation: loss 5.65690227074986, covariance difference 8.712652566958534, sinkhorn epsilon 0.0\n",
      "Iteration  1164\n",
      "Training: loss 4.617171287536621, covariance difference 1.0156633853912354\n",
      "Validation: loss 5.662829095763082, covariance difference 8.62138830800545, sinkhorn epsilon 2.99746910555543e-14\n",
      "Iteration  1165\n",
      "Training: loss 4.623098373413086, covariance difference 1.0154176950454712\n",
      "Validation: loss 5.639576031270428, covariance difference 8.539951910273892, sinkhorn epsilon 0.0\n",
      "Iteration  1166\n",
      "Training: loss 4.599844455718994, covariance difference 1.0113357305526733\n",
      "Validation: loss 5.613677408076571, covariance difference 8.456021144305081, sinkhorn epsilon 0.0\n",
      "Iteration  1167\n",
      "Training: loss 4.573945999145508, covariance difference 1.006008267402649\n",
      "Validation: loss 5.643561732293042, covariance difference 8.495034297612193, sinkhorn epsilon 0.0\n",
      "Iteration  1168\n",
      "Training: loss 4.603837966918945, covariance difference 1.0118495225906372\n",
      "Validation: loss 5.635606063012908, covariance difference 8.3700664174476, sinkhorn epsilon 0.0\n",
      "Iteration  1169\n",
      "Training: loss 4.595877170562744, covariance difference 1.010061502456665\n",
      "Validation: loss 5.683967769635018, covariance difference 8.565080539571492, sinkhorn epsilon 0.0\n",
      "Iteration  1170\n",
      "Training: loss 4.644235610961914, covariance difference 1.019979476928711\n",
      "Validation: loss 5.682841968132095, covariance difference 8.583768387934056, sinkhorn epsilon 0.0\n",
      "Iteration  1171\n",
      "Training: loss 4.643113613128662, covariance difference 1.0190125703811646\n",
      "Validation: loss 5.629928616583061, covariance difference 8.709729594033178, sinkhorn epsilon 0.0\n",
      "Iteration  1172\n",
      "Training: loss 4.590198993682861, covariance difference 1.0121909379959106\n",
      "Validation: loss 5.6770512526356995, covariance difference 8.580832187020555, sinkhorn epsilon 0.0\n",
      "Iteration  1173\n",
      "Training: loss 4.6373186111450195, covariance difference 1.0185514688491821\n",
      "Validation: loss 5.690350965750268, covariance difference 8.715332325327102, sinkhorn epsilon 0.0\n",
      "Iteration  1174\n",
      "Training: loss 4.650618553161621, covariance difference 1.0210983753204346\n",
      "Validation: loss 5.505605739295547, covariance difference 8.409824252965109, sinkhorn epsilon 5.696829867370728e-14\n",
      "Iteration  1175\n",
      "Training: loss 4.465879440307617, covariance difference 0.9879667162895203\n",
      "Validation: loss 5.789339695206573, covariance difference 8.909573864247003, sinkhorn epsilon 0.0\n",
      "Iteration  1176\n",
      "Training: loss 4.749608993530273, covariance difference 1.0393197536468506\n",
      "Validation: loss 5.597361988289786, covariance difference 8.66694590767387, sinkhorn epsilon 0.0\n",
      "Iteration  1177\n",
      "Training: loss 4.557631492614746, covariance difference 1.0028655529022217\n",
      "Validation: loss 5.657669740593977, covariance difference 8.556823101070469, sinkhorn epsilon 0.0\n",
      "Iteration  1178\n",
      "Training: loss 4.617938995361328, covariance difference 1.014096736907959\n",
      "Validation: loss 5.743790098920842, covariance difference 8.660722251059276, sinkhorn epsilon 0.0\n",
      "Iteration  1179\n",
      "Training: loss 4.7040605545043945, covariance difference 1.029578447341919\n",
      "Validation: loss 5.7093852404224235, covariance difference 8.775342266641779, sinkhorn epsilon 0.0\n",
      "Iteration  1180\n",
      "Training: loss 4.669652938842773, covariance difference 1.0219937562942505\n",
      "Validation: loss 5.592575008119357, covariance difference 8.54516639864611, sinkhorn epsilon 0.0\n",
      "Iteration  1181\n",
      "Training: loss 4.552845001220703, covariance difference 1.0053296089172363\n",
      "Validation: loss 5.666950022224979, covariance difference 8.632006466340671, sinkhorn epsilon 0.0\n",
      "Iteration  1182\n",
      "Training: loss 4.627222061157227, covariance difference 1.0164799690246582\n",
      "Validation: loss 5.586771930285759, covariance difference 8.49297569970689, sinkhorn epsilon 0.0\n",
      "Iteration  1183\n",
      "Training: loss 4.547040939331055, covariance difference 1.0022000074386597\n",
      "Validation: loss 5.695509330467912, covariance difference 8.745397742881275, sinkhorn epsilon 0.0\n",
      "Iteration  1184\n",
      "Training: loss 4.6557817459106445, covariance difference 1.0224428176879883\n",
      "Validation: loss 5.673527503274375, covariance difference 8.613589287215541, sinkhorn epsilon 3.954813806186144e-14\n",
      "Iteration  1185\n",
      "Training: loss 4.633803844451904, covariance difference 1.0167908668518066\n",
      "Validation: loss 5.765373625179692, covariance difference 8.56687857088947, sinkhorn epsilon 0.0\n",
      "Iteration  1186\n",
      "Training: loss 4.725646018981934, covariance difference 1.0332801342010498\n",
      "Validation: loss 5.695748178582347, covariance difference 8.605021645894103, sinkhorn epsilon 0.0\n",
      "Iteration  1187\n",
      "Training: loss 4.656017303466797, covariance difference 1.0221526622772217\n",
      "Validation: loss 5.68371211973219, covariance difference 8.65717397341544, sinkhorn epsilon 4.4071125244268256e-14\n",
      "Iteration  1188\n",
      "Training: loss 4.643989562988281, covariance difference 1.0209050178527832\n",
      "Validation: loss 5.60202657208732, covariance difference 8.440887728322464, sinkhorn epsilon 0.0\n",
      "Iteration  1189\n",
      "Training: loss 4.5623016357421875, covariance difference 1.0050793886184692\n",
      "Validation: loss 5.635851240509285, covariance difference 8.58917276744428, sinkhorn epsilon 0.0\n",
      "Iteration  1190\n",
      "Training: loss 4.596125602722168, covariance difference 1.009804606437683\n",
      "Validation: loss 5.654274050862318, covariance difference 8.56182538341579, sinkhorn epsilon 0.0\n",
      "Iteration  1191\n",
      "Training: loss 4.61453914642334, covariance difference 1.01349675655365\n",
      "Validation: loss 5.629628702485299, covariance difference 8.536224221333084, sinkhorn epsilon 0.0\n",
      "Iteration  1192\n",
      "Training: loss 4.589901924133301, covariance difference 1.0106563568115234\n",
      "Validation: loss 5.645366854478699, covariance difference 8.767217177292629, sinkhorn epsilon 0.0\n",
      "Iteration  1193\n",
      "Training: loss 4.605635643005371, covariance difference 1.0123958587646484\n",
      "Validation: loss 5.692619440511715, covariance difference 8.523061752779931, sinkhorn epsilon 0.0\n",
      "Iteration  1194\n",
      "Training: loss 4.652896404266357, covariance difference 1.0211906433105469\n",
      "Validation: loss 5.560107688775476, covariance difference 8.321745349077874, sinkhorn epsilon 3.585439801227077e-14\n",
      "Iteration  1195\n",
      "Training: loss 4.520381450653076, covariance difference 0.9983471632003784\n",
      "Validation: loss 5.573249273093228, covariance difference 8.398057245202782, sinkhorn epsilon 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  1196\n",
      "Training: loss 4.533526420593262, covariance difference 1.0002994537353516\n",
      "Validation: loss 5.718500282746829, covariance difference 8.833450283855043, sinkhorn epsilon 0.0\n",
      "Iteration  1197\n",
      "Training: loss 4.678768157958984, covariance difference 1.0257781744003296\n",
      "Validation: loss 5.681251382685727, covariance difference 8.802909648004977, sinkhorn epsilon 0.0\n",
      "Iteration  1198\n",
      "Training: loss 4.641514778137207, covariance difference 1.0193532705307007\n",
      "Validation: loss 5.6730154113155855, covariance difference 8.597692796878285, sinkhorn epsilon 0.0\n",
      "Iteration  1199\n",
      "Training: loss 4.633269309997559, covariance difference 1.0176273584365845\n",
      "Validation: loss 5.585898425729566, covariance difference 8.664925956976617, sinkhorn epsilon 0.0\n",
      "Iteration  1200\n",
      "Training: loss 4.546170234680176, covariance difference 1.0027780532836914\n",
      "Validation: loss 5.5742196485671345, covariance difference 8.528289345679843, sinkhorn epsilon 0.0\n",
      "Iteration  1201\n",
      "Training: loss 4.534493923187256, covariance difference 1.0000249147415161\n",
      "Validation: loss 5.674362685724753, covariance difference 8.735342501030827, sinkhorn epsilon 0.0\n",
      "Iteration  1202\n",
      "Training: loss 4.634632587432861, covariance difference 1.0181680917739868\n",
      "Validation: loss 5.628708860223236, covariance difference 8.63612447687083, sinkhorn epsilon 0.0\n",
      "Iteration  1203\n",
      "Training: loss 4.588982582092285, covariance difference 1.0102190971374512\n",
      "Validation: loss 5.648390641305284, covariance difference 8.681129695589211, sinkhorn epsilon 0.0\n",
      "Iteration  1204\n",
      "Training: loss 4.608659744262695, covariance difference 1.0138134956359863\n",
      "Validation: loss 5.657399752336796, covariance difference 8.482611779406843, sinkhorn epsilon 0.0\n",
      "Iteration  1205\n",
      "Training: loss 4.617668628692627, covariance difference 1.0152952671051025\n",
      "Validation: loss 5.669939929775811, covariance difference 8.505537394930899, sinkhorn epsilon 0.0\n",
      "Iteration  1206\n",
      "Training: loss 4.6302289962768555, covariance difference 1.0180805921554565\n",
      "Validation: loss 5.5896938677907615, covariance difference 8.798031834019008, sinkhorn epsilon 0.0\n",
      "Iteration  1207\n",
      "Training: loss 4.549962043762207, covariance difference 1.0029350519180298\n",
      "Validation: loss 5.6241233963969535, covariance difference 8.543686425423568, sinkhorn epsilon 0.0\n",
      "Iteration  1208\n",
      "Training: loss 4.5843915939331055, covariance difference 1.0097005367279053\n",
      "Validation: loss 5.614049486005076, covariance difference 8.498801987568177, sinkhorn epsilon 0.0\n",
      "Iteration  1209\n",
      "Training: loss 4.5743303298950195, covariance difference 1.0072065591812134\n",
      "Validation: loss 5.56908476033518, covariance difference 8.41438486207824, sinkhorn epsilon 4.3938383571790695e-14\n",
      "Iteration  1210\n",
      "Training: loss 4.529353141784668, covariance difference 0.998294472694397\n",
      "Validation: loss 5.65339856212462, covariance difference 8.567463353377551, sinkhorn epsilon 4.759557007501003e-14\n",
      "Iteration  1211\n",
      "Training: loss 4.613680839538574, covariance difference 1.0141183137893677\n",
      "Validation: loss 5.614142172954348, covariance difference 8.627562913586322, sinkhorn epsilon 0.0\n",
      "Iteration  1212\n",
      "Training: loss 4.574409484863281, covariance difference 1.0065569877624512\n",
      "Validation: loss 5.692596009882148, covariance difference 8.67381742827945, sinkhorn epsilon 0.0\n",
      "Iteration  1213\n",
      "Training: loss 4.65286922454834, covariance difference 1.0207068920135498\n",
      "Validation: loss 5.582250916739399, covariance difference 8.409766113334822, sinkhorn epsilon 0.0\n",
      "Iteration  1214\n",
      "Training: loss 4.542522430419922, covariance difference 1.002665400505066\n",
      "Validation: loss 5.682111240820949, covariance difference 8.67851795360024, sinkhorn epsilon 0.0\n",
      "Iteration  1215\n",
      "Training: loss 4.642381191253662, covariance difference 1.019544005393982\n",
      "Validation: loss 5.5937005823352175, covariance difference 8.397041732842725, sinkhorn epsilon 0.0\n",
      "Iteration  1216\n",
      "Training: loss 4.553971290588379, covariance difference 1.0031698942184448\n",
      "Validation: loss 5.593919259513396, covariance difference 8.470429324707435, sinkhorn epsilon 1.8124693034680033e-14\n",
      "Iteration  1217\n",
      "Training: loss 4.554187774658203, covariance difference 1.0043342113494873\n",
      "Validation: loss 5.592622980909786, covariance difference 8.499248534898234, sinkhorn epsilon 0.0\n",
      "Iteration  1218\n",
      "Training: loss 4.552891254425049, covariance difference 1.0030523538589478\n",
      "Validation: loss 5.587273336386556, covariance difference 8.541622710594716, sinkhorn epsilon 0.0\n",
      "Iteration  1219\n",
      "Training: loss 4.547540664672852, covariance difference 1.002577543258667\n",
      "Validation: loss 5.71528817321377, covariance difference 8.835260936995962, sinkhorn epsilon 0.0\n",
      "Iteration  1220\n",
      "Training: loss 4.675556182861328, covariance difference 1.025838851928711\n",
      "Validation: loss 5.685101159703116, covariance difference 8.707010656255566, sinkhorn epsilon 0.0\n",
      "Iteration  1221\n",
      "Training: loss 4.645366191864014, covariance difference 1.020452618598938\n",
      "Validation: loss 5.5703509604808294, covariance difference 8.715185674662706, sinkhorn epsilon 0.0\n",
      "Iteration  1222\n",
      "Training: loss 4.530623435974121, covariance difference 1.00078284740448\n",
      "Validation: loss 5.674862818053376, covariance difference 8.77647913990174, sinkhorn epsilon 0.0\n",
      "Iteration  1223\n",
      "Training: loss 4.635132312774658, covariance difference 1.0182347297668457\n",
      "Validation: loss 5.720357030068423, covariance difference 8.631930790105683, sinkhorn epsilon 0.0\n",
      "Iteration  1224\n",
      "Training: loss 4.680624485015869, covariance difference 1.0258325338363647\n",
      "Validation: loss 5.666694782501978, covariance difference 8.910653021625047, sinkhorn epsilon 0.0\n",
      "Iteration  1225\n",
      "Training: loss 4.62696647644043, covariance difference 1.0167062282562256\n",
      "Validation: loss 5.650348552656007, covariance difference 8.702758752922778, sinkhorn epsilon 0.0\n",
      "Iteration  1226\n",
      "Training: loss 4.6106157302856445, covariance difference 1.0149519443511963\n",
      "Validation: loss 5.575544771239226, covariance difference 8.693040264559926, sinkhorn epsilon 0.0\n",
      "Iteration  1227\n",
      "Training: loss 4.535820960998535, covariance difference 0.9999409914016724\n",
      "Validation: loss 5.5970064864098745, covariance difference 8.650020800506134, sinkhorn epsilon 0.0\n",
      "Iteration  1228\n",
      "Training: loss 4.5572710037231445, covariance difference 1.0045537948608398\n",
      "Validation: loss 5.677650692491203, covariance difference 8.57524583394693, sinkhorn epsilon 0.0\n",
      "Iteration  1229\n",
      "Training: loss 4.637918472290039, covariance difference 1.0201321840286255\n",
      "Validation: loss 5.709852406673253, covariance difference 8.828971468250034, sinkhorn epsilon 0.0\n",
      "Iteration  1230\n",
      "Training: loss 4.670122146606445, covariance difference 1.024896264076233\n",
      "Validation: loss 5.700814989492019, covariance difference 8.647742996685375, sinkhorn epsilon 1.76959351692546e-14\n",
      "Iteration  1231\n",
      "Training: loss 4.66108512878418, covariance difference 1.0223143100738525\n",
      "Validation: loss 5.7153038190557615, covariance difference 8.449350288390216, sinkhorn epsilon 0.0\n",
      "Iteration  1232\n",
      "Training: loss 4.675571441650391, covariance difference 1.0245041847229004\n",
      "Validation: loss 5.6490394465741325, covariance difference 8.508701245739461, sinkhorn epsilon 0.0\n",
      "Iteration  1233\n",
      "Training: loss 4.609311103820801, covariance difference 1.0137954950332642\n",
      "Validation: loss 5.582548690223989, covariance difference 8.529211235807582, sinkhorn epsilon 0.0\n",
      "Iteration  1234\n",
      "Training: loss 4.54281759262085, covariance difference 1.0007838010787964\n",
      "Validation: loss 5.599054139912426, covariance difference 8.692095368502917, sinkhorn epsilon 0.0\n",
      "Iteration  1235\n",
      "Training: loss 4.559322357177734, covariance difference 1.0026434659957886\n",
      "Validation: loss 5.603582142303292, covariance difference 8.378847365592325, sinkhorn epsilon 0.0\n",
      "Iteration  1236\n",
      "Training: loss 4.563859939575195, covariance difference 1.0052400827407837\n",
      "Validation: loss 5.7048910584165435, covariance difference 8.601079035812866, sinkhorn epsilon 0.0\n",
      "Iteration  1237\n",
      "Training: loss 4.6651611328125, covariance difference 1.021417260169983\n",
      "Validation: loss 5.666110778904572, covariance difference 8.738384226436088, sinkhorn epsilon 0.0\n",
      "Iteration  1238\n",
      "Training: loss 4.626379489898682, covariance difference 1.0189310312271118\n",
      "Validation: loss 5.741562327687266, covariance difference 8.63335906470939, sinkhorn epsilon 0.0\n",
      "Iteration  1239\n",
      "Training: loss 4.701836585998535, covariance difference 1.0297529697418213\n",
      "Validation: loss 5.759364766928228, covariance difference 8.93226520457732, sinkhorn epsilon 5.900823518210073e-14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  1240\n",
      "Training: loss 4.719635963439941, covariance difference 1.032249927520752\n",
      "Validation: loss 5.7026895476476875, covariance difference 8.65081739168725, sinkhorn epsilon 0.0\n",
      "Iteration  1241\n",
      "Training: loss 4.66295862197876, covariance difference 1.0237220525741577\n",
      "Validation: loss 5.722107089185521, covariance difference 8.841368504672234, sinkhorn epsilon 0.0\n",
      "Iteration  1242\n",
      "Training: loss 4.682374954223633, covariance difference 1.027064561843872\n",
      "Validation: loss 5.696233058529697, covariance difference 8.719805068921582, sinkhorn epsilon 0.0\n",
      "Iteration  1243\n",
      "Training: loss 4.656500816345215, covariance difference 1.021913766860962\n",
      "Validation: loss 5.612383144372556, covariance difference 8.724016743066274, sinkhorn epsilon 0.0\n",
      "Iteration  1244\n",
      "Training: loss 4.572652816772461, covariance difference 1.0078604221343994\n",
      "Validation: loss 5.670637978243449, covariance difference 8.524755529120151, sinkhorn epsilon 0.0\n",
      "Iteration  1245\n",
      "Training: loss 4.6309099197387695, covariance difference 1.018455147743225\n",
      "Validation: loss 5.5657914719626485, covariance difference 8.638674876481018, sinkhorn epsilon 0.0\n",
      "Iteration  1246\n",
      "Training: loss 4.526059150695801, covariance difference 0.9985319972038269\n",
      "Validation: loss 5.65526215227561, covariance difference 8.748943279270032, sinkhorn epsilon 0.0\n",
      "Iteration  1247\n",
      "Training: loss 4.615530490875244, covariance difference 1.0158791542053223\n",
      "Validation: loss 5.684251402003641, covariance difference 8.614337232812565, sinkhorn epsilon 0.0\n",
      "Iteration  1248\n",
      "Training: loss 4.644519805908203, covariance difference 1.0207916498184204\n",
      "Validation: loss 5.618891120210965, covariance difference 8.51272267111008, sinkhorn epsilon 0.0\n",
      "Iteration  1249\n",
      "Training: loss 4.579156398773193, covariance difference 1.0089154243469238\n",
      "Validation: loss 5.658936431589162, covariance difference 8.637263746218343, sinkhorn epsilon 0.0\n",
      "Iteration  1250\n",
      "Training: loss 4.619208335876465, covariance difference 1.0161114931106567\n",
      "Validation: loss 5.601613551912575, covariance difference 8.466015532188676, sinkhorn epsilon 0.0\n",
      "Iteration  1251\n",
      "Training: loss 4.561882495880127, covariance difference 1.0045585632324219\n",
      "Validation: loss 5.657738036939711, covariance difference 8.738668121790408, sinkhorn epsilon 0.0\n",
      "Iteration  1252\n",
      "Training: loss 4.618006706237793, covariance difference 1.014237403869629\n",
      "Validation: loss 5.601800787546498, covariance difference 8.503493517653277, sinkhorn epsilon 0.0\n",
      "Iteration  1253\n",
      "Training: loss 4.562068462371826, covariance difference 1.005264401435852\n",
      "Validation: loss 5.694293060334884, covariance difference 8.711044198131045, sinkhorn epsilon 0.0\n",
      "Iteration  1254\n",
      "Training: loss 4.654565334320068, covariance difference 1.022007942199707\n",
      "Validation: loss 5.663000587878136, covariance difference 8.747727679633673, sinkhorn epsilon 0.0\n",
      "Iteration  1255\n",
      "Training: loss 4.623272895812988, covariance difference 1.016709566116333\n",
      "Validation: loss 5.656006755999217, covariance difference 8.666226604115923, sinkhorn epsilon 0.0\n",
      "Iteration  1256\n",
      "Training: loss 4.616271018981934, covariance difference 1.0150470733642578\n",
      "Validation: loss 5.619999707088759, covariance difference 8.75258887716045, sinkhorn epsilon 0.0\n",
      "Iteration  1257\n",
      "Training: loss 4.580268859863281, covariance difference 1.0072624683380127\n",
      "Validation: loss 5.707063376654377, covariance difference 8.76897850378658, sinkhorn epsilon 6.297994790572438e-14\n",
      "Iteration  1258\n",
      "Training: loss 4.667331695556641, covariance difference 1.0247749090194702\n",
      "Validation: loss 5.663613422890689, covariance difference 8.777270223961075, sinkhorn epsilon 0.0\n",
      "Iteration  1259\n",
      "Training: loss 4.623883247375488, covariance difference 1.016232967376709\n",
      "Validation: loss 5.687483712726442, covariance difference 8.653230922431337, sinkhorn epsilon 0.0\n",
      "Iteration  1260\n",
      "Training: loss 4.647752285003662, covariance difference 1.020777702331543\n",
      "Validation: loss 5.702823894957086, covariance difference 8.945123740856971, sinkhorn epsilon 0.0\n",
      "Iteration  1261\n",
      "Training: loss 4.663093566894531, covariance difference 1.0235249996185303\n",
      "Validation: loss 5.598170226138563, covariance difference 8.375322563601383, sinkhorn epsilon 4.963793584585456e-14\n",
      "Iteration  1262\n",
      "Training: loss 4.55842399597168, covariance difference 1.0031520128250122\n",
      "Validation: loss 5.654511086217429, covariance difference 8.532922900523078, sinkhorn epsilon 0.0\n",
      "Iteration  1263\n",
      "Training: loss 4.614778518676758, covariance difference 1.014116644859314\n",
      "Validation: loss 5.654065009582765, covariance difference 8.805226310647074, sinkhorn epsilon 0.0\n",
      "Iteration  1264\n",
      "Training: loss 4.614334583282471, covariance difference 1.013692021369934\n",
      "Validation: loss 5.687451906329377, covariance difference 8.606857646598362, sinkhorn epsilon 0.0\n",
      "Iteration  1265\n",
      "Training: loss 4.6477203369140625, covariance difference 1.0197513103485107\n",
      "Validation: loss 5.624834022961442, covariance difference 8.495396992222979, sinkhorn epsilon 0.0\n",
      "Iteration  1266\n",
      "Training: loss 4.5851030349731445, covariance difference 1.0080902576446533\n",
      "Validation: loss 5.672371042456175, covariance difference 8.75026876531659, sinkhorn epsilon 0.0\n",
      "Iteration  1267\n",
      "Training: loss 4.63264274597168, covariance difference 1.0192745923995972\n",
      "Validation: loss 5.74026474339642, covariance difference 8.72157731000566, sinkhorn epsilon 0.0\n",
      "Iteration  1268\n",
      "Training: loss 4.700533390045166, covariance difference 1.0307512283325195\n",
      "Validation: loss 5.604080452499345, covariance difference 8.584900352264704, sinkhorn epsilon 0.0\n",
      "Iteration  1269\n",
      "Training: loss 4.564350128173828, covariance difference 1.0059007406234741\n",
      "Validation: loss 5.682550312467959, covariance difference 8.780068039275173, sinkhorn epsilon 6.077168904476863e-14\n",
      "Iteration  1270\n",
      "Training: loss 4.642828941345215, covariance difference 1.0201659202575684\n",
      "Validation: loss 5.63834178394017, covariance difference 8.477478642944355, sinkhorn epsilon 0.0\n",
      "Iteration  1271\n",
      "Training: loss 4.598610877990723, covariance difference 1.0107152462005615\n",
      "Validation: loss 5.675852939132561, covariance difference 8.606068599478633, sinkhorn epsilon 5.015218543813706e-14\n",
      "Iteration  1272\n",
      "Training: loss 4.636139392852783, covariance difference 1.0184381008148193\n",
      "Validation: loss 5.53018697234336, covariance difference 8.397686541098276, sinkhorn epsilon 0.0\n",
      "Iteration  1273\n",
      "Training: loss 4.490455627441406, covariance difference 0.9933202862739563\n",
      "Validation: loss 5.630313231322523, covariance difference 8.489567858742477, sinkhorn epsilon 0.0\n",
      "Iteration  1274\n",
      "Training: loss 4.590585708618164, covariance difference 1.0089901685714722\n",
      "Validation: loss 5.63161953391576, covariance difference 8.533002396142596, sinkhorn epsilon 0.0\n",
      "Iteration  1275\n",
      "Training: loss 4.591889381408691, covariance difference 1.0107821226119995\n",
      "Validation: loss 5.664470106565833, covariance difference 8.83483674287712, sinkhorn epsilon 0.0\n",
      "Iteration  1276\n",
      "Training: loss 4.624746799468994, covariance difference 1.01949942111969\n",
      "Validation: loss 5.6379264289181235, covariance difference 8.429094133042131, sinkhorn epsilon 0.0\n",
      "Iteration  1277\n",
      "Training: loss 4.5981950759887695, covariance difference 1.010339617729187\n",
      "Validation: loss 5.628885764481415, covariance difference 8.526112742727783, sinkhorn epsilon 0.0\n",
      "Iteration  1278\n",
      "Training: loss 4.589162349700928, covariance difference 1.0106792449951172\n",
      "Validation: loss 5.6636764348439375, covariance difference 8.690546491389421, sinkhorn epsilon 0.0\n",
      "Iteration  1279\n",
      "Training: loss 4.623958587646484, covariance difference 1.0146877765655518\n",
      "Validation: loss 5.585047092040198, covariance difference 8.378620098769748, sinkhorn epsilon 0.0\n",
      "Iteration  1280\n",
      "Training: loss 4.545314311981201, covariance difference 1.0007914304733276\n",
      "Validation: loss 5.672029561627851, covariance difference 8.689251707347465, sinkhorn epsilon 0.0\n",
      "Iteration  1281\n",
      "Training: loss 4.632297992706299, covariance difference 1.0171396732330322\n",
      "Validation: loss 5.70458109290592, covariance difference 8.758533792320316, sinkhorn epsilon 0.0\n",
      "Iteration  1282\n",
      "Training: loss 4.664855003356934, covariance difference 1.0231877565383911\n",
      "Validation: loss 5.593726161615865, covariance difference 8.589998781794046, sinkhorn epsilon 0.0\n",
      "Iteration  1283\n",
      "Training: loss 4.553994178771973, covariance difference 1.003702163696289\n",
      "Validation: loss 5.714396362990959, covariance difference 8.74763059043481, sinkhorn epsilon 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  1284\n",
      "Training: loss 4.674665451049805, covariance difference 1.0250548124313354\n",
      "Validation: loss 5.691184023975983, covariance difference 8.530213656108462, sinkhorn epsilon 0.0\n",
      "Iteration  1285\n",
      "Training: loss 4.651453018188477, covariance difference 1.0206142663955688\n",
      "Validation: loss 5.707798038420781, covariance difference 8.636442667399969, sinkhorn epsilon 0.0\n",
      "Iteration  1286\n",
      "Training: loss 4.6680588722229, covariance difference 1.024991512298584\n",
      "Validation: loss 5.6391399856375966, covariance difference 8.582133289044359, sinkhorn epsilon 0.0\n",
      "Iteration  1287\n",
      "Training: loss 4.599412441253662, covariance difference 1.0122942924499512\n",
      "Validation: loss 5.6495941618310415, covariance difference 8.773504949286808, sinkhorn epsilon 0.0\n",
      "Iteration  1288\n",
      "Training: loss 4.60986328125, covariance difference 1.0127339363098145\n",
      "Validation: loss 5.668287743948622, covariance difference 8.750490986849401, sinkhorn epsilon 0.0\n",
      "Iteration  1289\n",
      "Training: loss 4.628558158874512, covariance difference 1.017920732498169\n",
      "Validation: loss 5.672545493958976, covariance difference 8.836395347896845, sinkhorn epsilon 0.0\n",
      "Iteration  1290\n",
      "Training: loss 4.632818222045898, covariance difference 1.018776535987854\n",
      "Validation: loss 5.617715418609057, covariance difference 8.557953238844828, sinkhorn epsilon 0.0\n",
      "Iteration  1291\n",
      "Training: loss 4.5779924392700195, covariance difference 1.0078811645507812\n",
      "Validation: loss 5.652534373414808, covariance difference 8.656048614532422, sinkhorn epsilon 0.0\n",
      "Iteration  1292\n",
      "Training: loss 4.612802505493164, covariance difference 1.0149421691894531\n",
      "Validation: loss 5.548706935078533, covariance difference 8.729783714991031, sinkhorn epsilon 0.0\n",
      "Iteration  1293\n",
      "Training: loss 4.508971214294434, covariance difference 0.9948688745498657\n",
      "Validation: loss 5.644749849897399, covariance difference 8.621587972012234, sinkhorn epsilon 0.0\n",
      "Iteration  1294\n",
      "Training: loss 4.605027198791504, covariance difference 1.0117429494857788\n",
      "Validation: loss 5.691167466305313, covariance difference 8.526625837596908, sinkhorn epsilon 0.0\n",
      "Iteration  1295\n",
      "Training: loss 4.651435852050781, covariance difference 1.0215556621551514\n",
      "Validation: loss 5.684018340923973, covariance difference 8.697764779471429, sinkhorn epsilon 0.0\n",
      "Iteration  1296\n",
      "Training: loss 4.644283294677734, covariance difference 1.01972496509552\n",
      "Validation: loss 5.60203847736163, covariance difference 8.588857873900405, sinkhorn epsilon 0.0\n",
      "Iteration  1297\n",
      "Training: loss 4.5623087882995605, covariance difference 1.0048880577087402\n",
      "Validation: loss 5.6787342050622005, covariance difference 8.627389959848678, sinkhorn epsilon 0.0\n",
      "Iteration  1298\n",
      "Training: loss 4.639001846313477, covariance difference 1.01868736743927\n",
      "Validation: loss 5.733214016395263, covariance difference 8.761938262971904, sinkhorn epsilon 0.0\n",
      "Iteration  1299\n",
      "Training: loss 4.693483352661133, covariance difference 1.0280122756958008\n",
      "Validation: loss 5.601967082058549, covariance difference 8.546528860795645, sinkhorn epsilon 0.0\n",
      "Iteration  1300\n",
      "Training: loss 4.562235355377197, covariance difference 1.006776213645935\n",
      "Validation: loss 5.633409533039487, covariance difference 8.510901930541403, sinkhorn epsilon 0.0\n",
      "Iteration  1301\n",
      "Training: loss 4.593678951263428, covariance difference 1.0093779563903809\n",
      "Validation: loss 5.697375602824227, covariance difference 8.675789530156534, sinkhorn epsilon 0.0\n",
      "Iteration  1302\n",
      "Training: loss 4.657644271850586, covariance difference 1.0215716361999512\n",
      "Validation: loss 5.674731386443188, covariance difference 8.886105942803267, sinkhorn epsilon 5.709336743635669e-14\n",
      "Iteration  1303\n",
      "Training: loss 4.6349992752075195, covariance difference 1.0196022987365723\n",
      "Validation: loss 5.691560201954771, covariance difference 8.596352267666004, sinkhorn epsilon 0.0\n",
      "Iteration  1304\n",
      "Training: loss 4.651828765869141, covariance difference 1.0223712921142578\n",
      "Validation: loss 5.672622817625038, covariance difference 8.37068259330254, sinkhorn epsilon 0.0\n",
      "Iteration  1305\n",
      "Training: loss 4.632890701293945, covariance difference 1.0178148746490479\n",
      "Validation: loss 5.60674338157202, covariance difference 8.341220117372604, sinkhorn epsilon 0.0\n",
      "Iteration  1306\n",
      "Training: loss 4.567013740539551, covariance difference 1.0055081844329834\n",
      "Validation: loss 5.597899273163879, covariance difference 8.509140554509475, sinkhorn epsilon 0.0\n",
      "Iteration  1307\n",
      "Training: loss 4.558168888092041, covariance difference 1.0054073333740234\n",
      "Validation: loss 5.670691001666867, covariance difference 8.769769488718955, sinkhorn epsilon 0.0\n",
      "Iteration  1308\n",
      "Training: loss 4.6309614181518555, covariance difference 1.0172075033187866\n",
      "Validation: loss 5.678798273530997, covariance difference 8.712283042876805, sinkhorn epsilon 6.647873976270237e-14\n",
      "Iteration  1309\n",
      "Training: loss 4.639067649841309, covariance difference 1.0191571712493896\n",
      "Validation: loss 5.629161603039554, covariance difference 8.482630535240133, sinkhorn epsilon 0.0\n",
      "Iteration  1310\n",
      "Training: loss 4.589426040649414, covariance difference 1.0103265047073364\n",
      "Validation: loss 5.647828662089188, covariance difference 8.773088004043668, sinkhorn epsilon 0.0\n",
      "Iteration  1311\n",
      "Training: loss 4.608096122741699, covariance difference 1.014952540397644\n",
      "Validation: loss 5.716482370792406, covariance difference 8.734967175220845, sinkhorn epsilon 0.0\n",
      "Iteration  1312\n",
      "Training: loss 4.676750183105469, covariance difference 1.026233196258545\n",
      "Validation: loss 5.632190488669241, covariance difference 8.704100306809572, sinkhorn epsilon 6.433999478506389e-14\n",
      "Iteration  1313\n",
      "Training: loss 4.592463493347168, covariance difference 1.0102614164352417\n",
      "Validation: loss 5.6608306744745835, covariance difference 8.56214948073458, sinkhorn epsilon 0.0\n",
      "Iteration  1314\n",
      "Training: loss 4.621099472045898, covariance difference 1.013727068901062\n",
      "Validation: loss 5.7441396804203535, covariance difference 8.849016765352628, sinkhorn epsilon 0.0\n",
      "Iteration  1315\n",
      "Training: loss 4.704392433166504, covariance difference 1.0297520160675049\n",
      "Validation: loss 5.681143025694073, covariance difference 8.810280194520715, sinkhorn epsilon 0.0\n",
      "Iteration  1316\n",
      "Training: loss 4.641410827636719, covariance difference 1.0208905935287476\n",
      "Validation: loss 5.559340081733313, covariance difference 8.636501466431847, sinkhorn epsilon 0.0\n",
      "Iteration  1317\n",
      "Training: loss 4.519604206085205, covariance difference 0.9961561560630798\n",
      "Validation: loss 5.574663140209485, covariance difference 8.709659899694975, sinkhorn epsilon 0.0\n",
      "Iteration  1318\n",
      "Training: loss 4.534932613372803, covariance difference 1.002320647239685\n",
      "Validation: loss 5.6331160161567375, covariance difference 8.621243856082165, sinkhorn epsilon 0.0\n",
      "Iteration  1319\n",
      "Training: loss 4.593386173248291, covariance difference 1.0129830837249756\n",
      "Validation: loss 5.600097531586339, covariance difference 8.440483960740615, sinkhorn epsilon 0.0\n",
      "Iteration  1320\n",
      "Training: loss 4.560365676879883, covariance difference 1.005104660987854\n",
      "Validation: loss 5.683802425556947, covariance difference 8.520815142481176, sinkhorn epsilon 0.0\n",
      "Iteration  1321\n",
      "Training: loss 4.644071102142334, covariance difference 1.0192350149154663\n",
      "Validation: loss 5.761630675150085, covariance difference 9.007210005173546, sinkhorn epsilon 0.0\n",
      "Iteration  1322\n",
      "Training: loss 4.721901893615723, covariance difference 1.0334326028823853\n",
      "Validation: loss 5.62055150879927, covariance difference 8.682121215741118, sinkhorn epsilon 0.0\n",
      "Iteration  1323\n",
      "Training: loss 4.580820083618164, covariance difference 1.0077744722366333\n",
      "Validation: loss 5.595924084422155, covariance difference 8.479824399503249, sinkhorn epsilon 0.0\n",
      "Iteration  1324\n",
      "Training: loss 4.556192398071289, covariance difference 1.0038093328475952\n",
      "Validation: loss 5.580246246297144, covariance difference 8.524035694478071, sinkhorn epsilon 0.0\n",
      "Iteration  1325\n",
      "Training: loss 4.5405144691467285, covariance difference 1.0026882886886597\n",
      "Validation: loss 5.706298903322815, covariance difference 8.58108204213707, sinkhorn epsilon 1.6438053507882832e-14\n",
      "Iteration  1326\n",
      "Training: loss 4.666567802429199, covariance difference 1.0236613750457764\n",
      "Validation: loss 5.611794740483508, covariance difference 8.50219508172709, sinkhorn epsilon 0.0\n",
      "Iteration  1327\n",
      "Training: loss 4.5720672607421875, covariance difference 1.004878044128418\n",
      "Validation: loss 5.69547688285137, covariance difference 8.569147255974672, sinkhorn epsilon 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  1328\n",
      "Training: loss 4.655744552612305, covariance difference 1.0223195552825928\n",
      "Validation: loss 5.680485923960903, covariance difference 8.688009860046146, sinkhorn epsilon 0.0\n",
      "Iteration  1329\n",
      "Training: loss 4.6407551765441895, covariance difference 1.0179040431976318\n",
      "Validation: loss 5.710331864877638, covariance difference 8.661615963747714, sinkhorn epsilon 0.0\n",
      "Iteration  1330\n",
      "Training: loss 4.670601844787598, covariance difference 1.0234870910644531\n",
      "Validation: loss 5.692428904273669, covariance difference 8.569126237246303, sinkhorn epsilon 0.0\n",
      "Iteration  1331\n",
      "Training: loss 4.652683258056641, covariance difference 1.0225465297698975\n",
      "Validation: loss 5.612845578129038, covariance difference 8.725792045905804, sinkhorn epsilon 0.0\n",
      "Iteration  1332\n",
      "Training: loss 4.5731611251831055, covariance difference 1.0068295001983643\n",
      "Validation: loss 5.579456108643734, covariance difference 8.369681685899122, sinkhorn epsilon 2.222568850219952e-14\n",
      "Iteration  1333\n",
      "Training: loss 4.539726257324219, covariance difference 1.0006057024002075\n",
      "Validation: loss 5.650460909695816, covariance difference 8.484143631896583, sinkhorn epsilon 0.0\n",
      "Iteration  1334\n",
      "Training: loss 4.610729217529297, covariance difference 1.0128461122512817\n",
      "Validation: loss 5.720572758958871, covariance difference 8.949993470945264, sinkhorn epsilon 0.0\n",
      "Iteration  1335\n",
      "Training: loss 4.680840969085693, covariance difference 1.0268052816390991\n",
      "Validation: loss 5.649823706261568, covariance difference 8.390843251221707, sinkhorn epsilon 0.0\n",
      "Iteration  1336\n",
      "Training: loss 4.610095024108887, covariance difference 1.0140202045440674\n",
      "Validation: loss 5.634998217680995, covariance difference 8.455114161896985, sinkhorn epsilon 0.0\n",
      "Iteration  1337\n",
      "Training: loss 4.595263481140137, covariance difference 1.0089144706726074\n",
      "Validation: loss 5.676892463594883, covariance difference 8.656603551845707, sinkhorn epsilon 0.0\n",
      "Iteration  1338\n",
      "Training: loss 4.6371612548828125, covariance difference 1.0182299613952637\n",
      "Validation: loss 5.583855760753125, covariance difference 8.440122345924069, sinkhorn epsilon 0.0\n",
      "Iteration  1339\n",
      "Training: loss 4.544125556945801, covariance difference 1.0010732412338257\n",
      "Validation: loss 5.62024420408831, covariance difference 8.822709488556978, sinkhorn epsilon 0.0\n",
      "Iteration  1340\n",
      "Training: loss 4.580513000488281, covariance difference 1.0073022842407227\n",
      "Validation: loss 5.6427024824592245, covariance difference 8.570018841405695, sinkhorn epsilon 0.0\n",
      "Iteration  1341\n",
      "Training: loss 4.602972507476807, covariance difference 1.0130892992019653\n",
      "Validation: loss 5.684862574922059, covariance difference 8.43363175710915, sinkhorn epsilon 4.8096201324616705e-14\n",
      "Iteration  1342\n",
      "Training: loss 4.645133018493652, covariance difference 1.0202440023422241\n",
      "Validation: loss 5.656345894262547, covariance difference 8.512441798006025, sinkhorn epsilon 0.0\n",
      "Iteration  1343\n",
      "Training: loss 4.616621971130371, covariance difference 1.0132100582122803\n",
      "Validation: loss 5.572895288037748, covariance difference 8.50040420508634, sinkhorn epsilon 0.0\n",
      "Iteration  1344\n",
      "Training: loss 4.533173084259033, covariance difference 1.0014663934707642\n",
      "Validation: loss 5.70819472814831, covariance difference 8.768292844517452, sinkhorn epsilon 0.0\n",
      "Iteration  1345\n",
      "Training: loss 4.668468952178955, covariance difference 1.024665117263794\n",
      "Validation: loss 5.633320023016075, covariance difference 8.616395080862777, sinkhorn epsilon 0.0\n",
      "Iteration  1346\n",
      "Training: loss 4.593591213226318, covariance difference 1.010724663734436\n",
      "Validation: loss 5.608256379705175, covariance difference 8.742953666779057, sinkhorn epsilon 0.0\n",
      "Iteration  1347\n",
      "Training: loss 4.568528175354004, covariance difference 1.0085232257843018\n",
      "Validation: loss 5.646966019913239, covariance difference 8.714575680110693, sinkhorn epsilon 0.0\n",
      "Iteration  1348\n",
      "Training: loss 4.607235431671143, covariance difference 1.0131949186325073\n",
      "Validation: loss 5.640457223221207, covariance difference 8.490566164759882, sinkhorn epsilon 0.0\n",
      "Iteration  1349\n",
      "Training: loss 4.6007256507873535, covariance difference 1.012848138809204\n",
      "Validation: loss 5.660952655696995, covariance difference 8.68899580390434, sinkhorn epsilon 0.0\n",
      "Iteration  1350\n",
      "Training: loss 4.621219635009766, covariance difference 1.0170872211456299\n",
      "Validation: loss 5.661203669179219, covariance difference 8.90959566340686, sinkhorn epsilon 0.0\n",
      "Iteration  1351\n",
      "Training: loss 4.621467113494873, covariance difference 1.0151957273483276\n",
      "Validation: loss 5.587084308484674, covariance difference 8.61951785721278, sinkhorn epsilon 3.276090315271027e-14\n",
      "Iteration  1352\n",
      "Training: loss 4.5473527908325195, covariance difference 1.0044188499450684\n",
      "Validation: loss 5.651054783731381, covariance difference 8.571062884479263, sinkhorn epsilon 0.0\n",
      "Iteration  1353\n",
      "Training: loss 4.611324787139893, covariance difference 1.0135308504104614\n",
      "Validation: loss 5.718714953818251, covariance difference 8.647931608248054, sinkhorn epsilon 0.0\n",
      "Iteration  1354\n",
      "Training: loss 4.678985595703125, covariance difference 1.027951717376709\n",
      "Validation: loss 5.682072283700697, covariance difference 8.747029145549504, sinkhorn epsilon 0.0\n",
      "Iteration  1355\n",
      "Training: loss 4.642339706420898, covariance difference 1.0198159217834473\n",
      "Validation: loss 5.713295940246539, covariance difference 8.649981285489536, sinkhorn epsilon 2.4855655712395205e-14\n",
      "Iteration  1356\n",
      "Training: loss 4.6735639572143555, covariance difference 1.0228188037872314\n",
      "Validation: loss 5.653257141624642, covariance difference 8.711686776805395, sinkhorn epsilon 0.0\n",
      "Iteration  1357\n",
      "Training: loss 4.613526344299316, covariance difference 1.0144654512405396\n",
      "Validation: loss 5.638674629207201, covariance difference 8.505996257691404, sinkhorn epsilon 0.0\n",
      "Iteration  1358\n",
      "Training: loss 4.598944664001465, covariance difference 1.0127397775650024\n",
      "Validation: loss 5.635379904175277, covariance difference 8.602009345980491, sinkhorn epsilon 0.0\n",
      "Iteration  1359\n",
      "Training: loss 4.595647811889648, covariance difference 1.0097311735153198\n",
      "Validation: loss 5.629728759062104, covariance difference 8.458918730624765, sinkhorn epsilon 0.0\n",
      "Iteration  1360\n",
      "Training: loss 4.590001106262207, covariance difference 1.0097825527191162\n",
      "Validation: loss 5.592815787016526, covariance difference 8.526539768776583, sinkhorn epsilon 0.0\n",
      "Iteration  1361\n",
      "Training: loss 4.5530853271484375, covariance difference 1.0054306983947754\n",
      "Validation: loss 5.673298175104407, covariance difference 8.649705417492259, sinkhorn epsilon 0.0\n",
      "Iteration  1362\n",
      "Training: loss 4.633552551269531, covariance difference 1.0191165208816528\n",
      "Validation: loss 5.564543117675495, covariance difference 8.486309869363126, sinkhorn epsilon 0.0\n",
      "Iteration  1363\n",
      "Training: loss 4.524812698364258, covariance difference 1.000013828277588\n",
      "Validation: loss 5.645128496129044, covariance difference 8.723649587775586, sinkhorn epsilon 0.0\n",
      "Iteration  1364\n",
      "Training: loss 4.6053924560546875, covariance difference 1.0120195150375366\n",
      "Validation: loss 5.718855196150799, covariance difference 8.52338647455866, sinkhorn epsilon 3.3293971520303277e-14\n",
      "Iteration  1365\n",
      "Training: loss 4.679126262664795, covariance difference 1.0256322622299194\n",
      "Validation: loss 5.648332244372396, covariance difference 8.742868422634936, sinkhorn epsilon 0.0\n",
      "Iteration  1366\n",
      "Training: loss 4.6085991859436035, covariance difference 1.0140235424041748\n",
      "Validation: loss 5.69124798443676, covariance difference 8.620742710124013, sinkhorn epsilon 0.0\n",
      "Iteration  1367\n",
      "Training: loss 4.651500701904297, covariance difference 1.0216033458709717\n",
      "Validation: loss 5.675157750263162, covariance difference 8.492959968273668, sinkhorn epsilon 0.0\n",
      "Iteration  1368\n",
      "Training: loss 4.635426998138428, covariance difference 1.0193805694580078\n",
      "Validation: loss 5.661583936621597, covariance difference 8.526077594698217, sinkhorn epsilon 0.0\n",
      "Iteration  1369\n",
      "Training: loss 4.621852874755859, covariance difference 1.0138217210769653\n",
      "Validation: loss 5.563452896773681, covariance difference 8.57054064454881, sinkhorn epsilon 0.0\n",
      "Iteration  1370\n",
      "Training: loss 4.523725509643555, covariance difference 0.998875081539154\n",
      "Validation: loss 5.548254181299216, covariance difference 8.598759772746591, sinkhorn epsilon 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  1371\n",
      "Training: loss 4.508522987365723, covariance difference 0.9964213371276855\n",
      "Validation: loss 5.609913782345211, covariance difference 8.56969477975499, sinkhorn epsilon 0.0\n",
      "Iteration  1372\n",
      "Training: loss 4.570181846618652, covariance difference 1.0063717365264893\n",
      "Validation: loss 5.681676314850429, covariance difference 8.85160564478641, sinkhorn epsilon 0.0\n",
      "Iteration  1373\n",
      "Training: loss 4.641946315765381, covariance difference 1.0182560682296753\n",
      "Validation: loss 5.673004390420015, covariance difference 8.776597039723363, sinkhorn epsilon 0.0\n",
      "Iteration  1374\n",
      "Training: loss 4.633272171020508, covariance difference 1.016733169555664\n",
      "Validation: loss 5.732431859091318, covariance difference 8.858499905126596, sinkhorn epsilon 3.838880173028942e-14\n",
      "Iteration  1375\n",
      "Training: loss 4.692708492279053, covariance difference 1.0306190252304077\n",
      "Validation: loss 5.618670756673192, covariance difference 8.585186860233486, sinkhorn epsilon 0.0\n",
      "Iteration  1376\n",
      "Training: loss 4.578940391540527, covariance difference 1.0061182975769043\n",
      "Validation: loss 5.623920629732459, covariance difference 8.367097280981215, sinkhorn epsilon 0.0\n",
      "Iteration  1377\n",
      "Training: loss 4.584189414978027, covariance difference 1.0081355571746826\n",
      "Validation: loss 5.667031125565452, covariance difference 8.537832994171302, sinkhorn epsilon 0.0\n",
      "Iteration  1378\n",
      "Training: loss 4.627300262451172, covariance difference 1.0181804895401\n",
      "Validation: loss 5.695330617490345, covariance difference 8.743830439333962, sinkhorn epsilon 0.0\n",
      "Iteration  1379\n",
      "Training: loss 4.655600547790527, covariance difference 1.0217183828353882\n",
      "Validation: loss 5.65866991322554, covariance difference 8.470223961482414, sinkhorn epsilon 0.0\n",
      "Iteration  1380\n",
      "Training: loss 4.6189398765563965, covariance difference 1.0158394575119019\n",
      "Validation: loss 5.726139699048768, covariance difference 8.928145459345297, sinkhorn epsilon 2.8060701683873278e-14\n",
      "Iteration  1381\n",
      "Training: loss 4.686408042907715, covariance difference 1.028804063796997\n",
      "Validation: loss 5.676415094552188, covariance difference 8.486947168662791, sinkhorn epsilon 7.41368725539532e-14\n",
      "Iteration  1382\n",
      "Training: loss 4.636683464050293, covariance difference 1.0166676044464111\n",
      "Validation: loss 5.647803022529686, covariance difference 8.531108665600414, sinkhorn epsilon 0.0\n",
      "Iteration  1383\n",
      "Training: loss 4.608067989349365, covariance difference 1.012608528137207\n",
      "Validation: loss 5.6825566374173455, covariance difference 8.441940434469954, sinkhorn epsilon 0.0\n",
      "Iteration  1384\n",
      "Training: loss 4.6428303718566895, covariance difference 1.0186903476715088\n",
      "Validation: loss 5.692127612100692, covariance difference 8.74788069506368, sinkhorn epsilon 0.0\n",
      "Iteration  1385\n",
      "Training: loss 4.652396202087402, covariance difference 1.0226647853851318\n",
      "Validation: loss 5.736166071627972, covariance difference 8.499140198322634, sinkhorn epsilon 0.0\n",
      "Iteration  1386\n",
      "Training: loss 4.696436405181885, covariance difference 1.0276154279708862\n",
      "Validation: loss 5.571870367087473, covariance difference 8.78528087000403, sinkhorn epsilon 0.0\n",
      "Iteration  1387\n",
      "Training: loss 4.532147407531738, covariance difference 0.9980599284172058\n",
      "Validation: loss 5.697925423639326, covariance difference 8.735868730377927, sinkhorn epsilon 0.0\n",
      "Iteration  1388\n",
      "Training: loss 4.6581950187683105, covariance difference 1.0216045379638672\n",
      "Validation: loss 5.675411202645555, covariance difference 8.868688438036315, sinkhorn epsilon 0.0\n",
      "Iteration  1389\n",
      "Training: loss 4.6356706619262695, covariance difference 1.0183045864105225\n",
      "Validation: loss 5.7041969931794405, covariance difference 8.665539301598999, sinkhorn epsilon 0.0\n",
      "Iteration  1390\n",
      "Training: loss 4.66446590423584, covariance difference 1.0234909057617188\n",
      "Validation: loss 5.684422000542705, covariance difference 8.695602037205285, sinkhorn epsilon 0.0\n",
      "Iteration  1391\n",
      "Training: loss 4.644689559936523, covariance difference 1.0197142362594604\n",
      "Validation: loss 5.620689140816268, covariance difference 8.320020249692806, sinkhorn epsilon 0.0\n",
      "Iteration  1392\n",
      "Training: loss 4.580959796905518, covariance difference 1.007936954498291\n",
      "Validation: loss 5.662775325641631, covariance difference 8.683979249629965, sinkhorn epsilon 0.0\n",
      "Iteration  1393\n",
      "Training: loss 4.6230316162109375, covariance difference 1.0174585580825806\n",
      "Validation: loss 5.595688056615778, covariance difference 8.617521989977648, sinkhorn epsilon 0.0\n",
      "Iteration  1394\n",
      "Training: loss 4.5559563636779785, covariance difference 1.0025814771652222\n",
      "Validation: loss 5.653370826245494, covariance difference 8.49061050809708, sinkhorn epsilon 0.0\n",
      "Iteration  1395\n",
      "Training: loss 4.613646984100342, covariance difference 1.0152113437652588\n",
      "Validation: loss 5.661121283930036, covariance difference 8.460062834617345, sinkhorn epsilon 0.0\n",
      "Iteration  1396\n",
      "Training: loss 4.621383190155029, covariance difference 1.0150656700134277\n",
      "Validation: loss 5.5876231193498755, covariance difference 8.436680004074544, sinkhorn epsilon 7.440708129197298e-14\n",
      "Iteration  1397\n",
      "Training: loss 4.547890663146973, covariance difference 1.002483606338501\n",
      "Validation: loss 5.674562449875539, covariance difference 8.766134718797495, sinkhorn epsilon 0.0\n",
      "Iteration  1398\n",
      "Training: loss 4.634832382202148, covariance difference 1.0170308351516724\n",
      "Validation: loss 5.642751954699498, covariance difference 8.470453582261309, sinkhorn epsilon 0.0\n",
      "Iteration  1399\n",
      "Training: loss 4.603019714355469, covariance difference 1.0134984254837036\n",
      "Validation: loss 5.6557383265918535, covariance difference 8.83834126797175, sinkhorn epsilon 0.0\n",
      "Iteration  1400\n",
      "Training: loss 4.616008281707764, covariance difference 1.0153343677520752\n",
      "Validation: loss 5.612166876093825, covariance difference 8.55192642274677, sinkhorn epsilon 0.0\n",
      "Iteration  1401\n",
      "Training: loss 4.572434425354004, covariance difference 1.0088855028152466\n",
      "Validation: loss 5.655106057986848, covariance difference 8.725084814533682, sinkhorn epsilon 9.720310843102572e-14\n",
      "Iteration  1402\n",
      "Training: loss 4.6153764724731445, covariance difference 1.0136613845825195\n",
      "Validation: loss 5.6760052875377305, covariance difference 8.668539805648038, sinkhorn epsilon 0.0\n",
      "Iteration  1403\n",
      "Training: loss 4.636279106140137, covariance difference 1.0188384056091309\n",
      "Validation: loss 5.621069278902102, covariance difference 8.809230067188379, sinkhorn epsilon 0.0\n",
      "Iteration  1404\n",
      "Training: loss 4.581337928771973, covariance difference 1.0089627504348755\n",
      "Validation: loss 5.630001282740429, covariance difference 8.723784069801496, sinkhorn epsilon 0.0\n",
      "Iteration  1405\n",
      "Training: loss 4.590269565582275, covariance difference 1.0095902681350708\n",
      "Validation: loss 5.712867675184265, covariance difference 8.754745464954068, sinkhorn epsilon 0.0\n",
      "Iteration  1406\n",
      "Training: loss 4.673124313354492, covariance difference 1.0265891551971436\n",
      "Validation: loss 5.615610187155167, covariance difference 8.509553994907357, sinkhorn epsilon 0.0\n",
      "Iteration  1407\n",
      "Training: loss 4.575880527496338, covariance difference 1.0077937841415405\n",
      "Validation: loss 5.654673631219953, covariance difference 8.461982808800645, sinkhorn epsilon 0.0\n",
      "Iteration  1408\n",
      "Training: loss 4.614937782287598, covariance difference 1.0149657726287842\n",
      "Validation: loss 5.650187407529234, covariance difference 8.782283457466432, sinkhorn epsilon 0.0\n",
      "Iteration  1409\n",
      "Training: loss 4.61045503616333, covariance difference 1.0141494274139404\n",
      "Validation: loss 5.635763519232611, covariance difference 8.57891116316561, sinkhorn epsilon 0.0\n",
      "Iteration  1410\n",
      "Training: loss 4.59603214263916, covariance difference 1.0120105743408203\n",
      "Validation: loss 5.645469435507096, covariance difference 8.493008126406657, sinkhorn epsilon 0.0\n",
      "Iteration  1411\n",
      "Training: loss 4.60573673248291, covariance difference 1.0142871141433716\n",
      "Validation: loss 5.611109679921595, covariance difference 8.42466277547415, sinkhorn epsilon 0.0\n",
      "Iteration  1412\n",
      "Training: loss 4.571377277374268, covariance difference 1.0064599514007568\n",
      "Validation: loss 5.637698932385936, covariance difference 8.545552366574615, sinkhorn epsilon 0.0\n",
      "Iteration  1413\n",
      "Training: loss 4.597968578338623, covariance difference 1.0108834505081177\n",
      "Validation: loss 5.755089935063011, covariance difference 8.652158834142062, sinkhorn epsilon 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  1414\n",
      "Training: loss 4.715359210968018, covariance difference 1.032982587814331\n",
      "Validation: loss 5.659215230736738, covariance difference 8.596741953117526, sinkhorn epsilon 4.179087702495526e-14\n",
      "Iteration  1415\n",
      "Training: loss 4.619483470916748, covariance difference 1.0147199630737305\n",
      "Validation: loss 5.688613410000378, covariance difference 8.726855876097563, sinkhorn epsilon 0.0\n",
      "Iteration  1416\n",
      "Training: loss 4.648879528045654, covariance difference 1.0195742845535278\n",
      "Validation: loss 5.747129024525366, covariance difference 8.750822891716915, sinkhorn epsilon 0.0\n",
      "Iteration  1417\n",
      "Training: loss 4.707401275634766, covariance difference 1.0315800905227661\n",
      "Validation: loss 5.650600373689193, covariance difference 8.6857678456415, sinkhorn epsilon 0.0\n",
      "Iteration  1418\n",
      "Training: loss 4.610876560211182, covariance difference 1.0126385688781738\n",
      "Validation: loss 5.630240304639792, covariance difference 8.533821357251632, sinkhorn epsilon 0.0\n",
      "Iteration  1419\n",
      "Training: loss 4.590509414672852, covariance difference 1.0093374252319336\n",
      "Validation: loss 5.64791179079598, covariance difference 8.744226988738866, sinkhorn epsilon 0.0\n",
      "Iteration  1420\n",
      "Training: loss 4.608180999755859, covariance difference 1.011860728263855\n",
      "Validation: loss 5.679046594672969, covariance difference 8.61656389136839, sinkhorn epsilon 0.0\n",
      "Iteration  1421\n",
      "Training: loss 4.639316558837891, covariance difference 1.019087791442871\n",
      "Validation: loss 5.638574257164125, covariance difference 8.606545401640755, sinkhorn epsilon 0.0\n",
      "Iteration  1422\n",
      "Training: loss 4.598840713500977, covariance difference 1.0110630989074707\n",
      "Validation: loss 5.69352680901745, covariance difference 8.751423927178845, sinkhorn epsilon 0.0\n",
      "Iteration  1423\n",
      "Training: loss 4.653797149658203, covariance difference 1.0213401317596436\n",
      "Validation: loss 5.642904835684929, covariance difference 8.763928857045617, sinkhorn epsilon 0.0\n",
      "Iteration  1424\n",
      "Training: loss 4.60317325592041, covariance difference 1.01291024684906\n",
      "Validation: loss 5.621236301807009, covariance difference 8.48622849003878, sinkhorn epsilon 0.0\n",
      "Iteration  1425\n",
      "Training: loss 4.581509113311768, covariance difference 1.0086283683776855\n",
      "Validation: loss 5.618686070945463, covariance difference 8.55708785665346, sinkhorn epsilon 0.0\n",
      "Iteration  1426\n",
      "Training: loss 4.57895565032959, covariance difference 1.0077152252197266\n",
      "Validation: loss 5.606309374702666, covariance difference 8.508372602074878, sinkhorn epsilon 0.0\n",
      "Iteration  1427\n",
      "Training: loss 4.566577434539795, covariance difference 1.0064592361450195\n",
      "Validation: loss 5.5954048307167845, covariance difference 8.511627063257281, sinkhorn epsilon 0.0\n",
      "Iteration  1428\n",
      "Training: loss 4.555676460266113, covariance difference 1.0046348571777344\n",
      "Validation: loss 5.645138291151042, covariance difference 8.610255383449164, sinkhorn epsilon 0.0\n",
      "Iteration  1429\n",
      "Training: loss 4.605405330657959, covariance difference 1.0113708972930908\n",
      "Validation: loss 5.734937588823115, covariance difference 8.895138004848047, sinkhorn epsilon 0.0\n",
      "Iteration  1430\n",
      "Training: loss 4.695209503173828, covariance difference 1.0280935764312744\n",
      "Validation: loss 5.579841909389587, covariance difference 8.5448586644788, sinkhorn epsilon 0.0\n",
      "Iteration  1431\n",
      "Training: loss 4.540111541748047, covariance difference 1.0015348196029663\n",
      "Validation: loss 5.592509940538151, covariance difference 8.480087717965551, sinkhorn epsilon 0.0\n",
      "Iteration  1432\n",
      "Training: loss 4.552779197692871, covariance difference 1.0034513473510742\n",
      "Validation: loss 5.687005243363348, covariance difference 8.517253205147803, sinkhorn epsilon 0.0\n",
      "Iteration  1433\n",
      "Training: loss 4.647270679473877, covariance difference 1.0202847719192505\n",
      "Validation: loss 5.684230085154965, covariance difference 8.739288757083429, sinkhorn epsilon 0.0\n",
      "Iteration  1434\n",
      "Training: loss 4.64450740814209, covariance difference 1.0194668769836426\n",
      "Validation: loss 5.675909026107089, covariance difference 8.635921726077068, sinkhorn epsilon 0.0\n",
      "Iteration  1435\n",
      "Training: loss 4.636178016662598, covariance difference 1.0178794860839844\n",
      "Validation: loss 5.728936631687624, covariance difference 8.63110890569782, sinkhorn epsilon 0.0\n",
      "Iteration  1436\n",
      "Training: loss 4.689205169677734, covariance difference 1.0264836549758911\n",
      "Validation: loss 5.596280466968526, covariance difference 8.72511796514998, sinkhorn epsilon 0.0\n",
      "Iteration  1437\n",
      "Training: loss 4.556551933288574, covariance difference 1.0041439533233643\n",
      "Validation: loss 5.655399452700044, covariance difference 8.650552107388744, sinkhorn epsilon 0.0\n",
      "Iteration  1438\n",
      "Training: loss 4.615668296813965, covariance difference 1.015773057937622\n",
      "Validation: loss 5.675587841792091, covariance difference 8.642825879185404, sinkhorn epsilon 0.0\n",
      "Iteration  1439\n",
      "Training: loss 4.635858535766602, covariance difference 1.0175071954727173\n",
      "Validation: loss 5.656910391147628, covariance difference 8.700515620933906, sinkhorn epsilon 0.0\n",
      "Iteration  1440\n",
      "Training: loss 4.617177963256836, covariance difference 1.0134977102279663\n",
      "Validation: loss 5.700702064895077, covariance difference 8.615959216272644, sinkhorn epsilon 4.7657275971551355e-15\n",
      "Iteration  1441\n",
      "Training: loss 4.660971641540527, covariance difference 1.0234116315841675\n",
      "Validation: loss 5.752908990565799, covariance difference 8.897720274654716, sinkhorn epsilon 0.0\n",
      "Iteration  1442\n",
      "Training: loss 4.7131781578063965, covariance difference 1.031795620918274\n",
      "Validation: loss 5.604488226826606, covariance difference 8.487766400230349, sinkhorn epsilon 0.0\n",
      "Iteration  1443\n",
      "Training: loss 4.564756393432617, covariance difference 1.0051780939102173\n",
      "Validation: loss 5.705183150863078, covariance difference 8.602189306980941, sinkhorn epsilon 0.0\n",
      "Iteration  1444\n",
      "Training: loss 4.6654510498046875, covariance difference 1.02305269241333\n",
      "Validation: loss 5.652047657541408, covariance difference 8.584019095629964, sinkhorn epsilon 0.0\n",
      "Iteration  1445\n",
      "Training: loss 4.612315654754639, covariance difference 1.0145273208618164\n",
      "Validation: loss 5.696806145731899, covariance difference 8.671321737946755, sinkhorn epsilon 0.0\n",
      "Iteration  1446\n",
      "Training: loss 4.657073974609375, covariance difference 1.0213110446929932\n",
      "Validation: loss 5.663897302694911, covariance difference 8.6001126805929, sinkhorn epsilon 0.0\n",
      "Iteration  1447\n",
      "Training: loss 4.6241607666015625, covariance difference 1.0170501470565796\n",
      "Validation: loss 5.686491841937937, covariance difference 8.618333236824677, sinkhorn epsilon 0.0\n",
      "Iteration  1448\n",
      "Training: loss 4.646761894226074, covariance difference 1.0213812589645386\n",
      "Validation: loss 5.746816454745772, covariance difference 8.973508252907576, sinkhorn epsilon 0.0\n",
      "Iteration  1449\n",
      "Training: loss 4.707084655761719, covariance difference 1.0309969186782837\n",
      "Validation: loss 5.655589069984543, covariance difference 8.669075448922749, sinkhorn epsilon 0.0\n",
      "Iteration  1450\n",
      "Training: loss 4.615857124328613, covariance difference 1.0131206512451172\n",
      "Validation: loss 5.737318154544677, covariance difference 8.571361958056665, sinkhorn epsilon 0.0\n",
      "Iteration  1451\n",
      "Training: loss 4.697587013244629, covariance difference 1.0274780988693237\n",
      "Validation: loss 5.613385929670172, covariance difference 8.581927224517027, sinkhorn epsilon 0.0\n",
      "Iteration  1452\n",
      "Training: loss 4.5736565589904785, covariance difference 1.007258415222168\n",
      "Validation: loss 5.626353759920233, covariance difference 8.683848799876909, sinkhorn epsilon 0.0\n",
      "Iteration  1453\n",
      "Training: loss 4.586655139923096, covariance difference 1.0089683532714844\n",
      "Validation: loss 5.642922167020387, covariance difference 8.696072009481991, sinkhorn epsilon 0.0\n",
      "Iteration  1454\n",
      "Training: loss 4.603192329406738, covariance difference 1.0148556232452393\n",
      "Validation: loss 5.749020565214104, covariance difference 8.949755220097522, sinkhorn epsilon 0.0\n",
      "Iteration  1455\n",
      "Training: loss 4.70928955078125, covariance difference 1.031718134880066\n",
      "Validation: loss 5.755200752715121, covariance difference 8.801845404601469, sinkhorn epsilon 0.0\n",
      "Iteration  1456\n",
      "Training: loss 4.7154693603515625, covariance difference 1.0321698188781738\n",
      "Validation: loss 5.594199172172328, covariance difference 8.649227681657639, sinkhorn epsilon 0.0\n",
      "Iteration  1457\n",
      "Training: loss 4.554471015930176, covariance difference 1.0031712055206299\n",
      "Validation: loss 5.698900118183615, covariance difference 8.58146920977708, sinkhorn epsilon 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  1458\n",
      "Training: loss 4.659172534942627, covariance difference 1.0225647687911987\n",
      "Validation: loss 5.673727863340577, covariance difference 8.620984046848186, sinkhorn epsilon 0.0\n",
      "Iteration  1459\n",
      "Training: loss 4.633997440338135, covariance difference 1.017382264137268\n",
      "Validation: loss 5.666202890608216, covariance difference 8.75091314287816, sinkhorn epsilon 0.0\n",
      "Iteration  1460\n",
      "Training: loss 4.62647008895874, covariance difference 1.0166202783584595\n",
      "Validation: loss 5.692488875138394, covariance difference 8.599001889994073, sinkhorn epsilon 0.0\n",
      "Iteration  1461\n",
      "Training: loss 4.652757167816162, covariance difference 1.0210832357406616\n",
      "Validation: loss 5.663890872020822, covariance difference 8.518720834333518, sinkhorn epsilon 0.0\n",
      "Iteration  1462\n",
      "Training: loss 4.6241607666015625, covariance difference 1.0153357982635498\n",
      "Validation: loss 5.627904394590752, covariance difference 8.697474785538393, sinkhorn epsilon 0.0\n",
      "Iteration  1463\n",
      "Training: loss 4.5881853103637695, covariance difference 1.0094523429870605\n",
      "Validation: loss 5.654389578381961, covariance difference 8.452851052574118, sinkhorn epsilon 4.345762313786098e-14\n",
      "Iteration  1464\n",
      "Training: loss 4.614660263061523, covariance difference 1.0144280195236206\n",
      "Validation: loss 5.701659991721687, covariance difference 8.68090606690288, sinkhorn epsilon 0.0\n",
      "Iteration  1465\n",
      "Training: loss 4.661924362182617, covariance difference 1.0230220556259155\n",
      "Validation: loss 5.722507085029109, covariance difference 8.487713275526371, sinkhorn epsilon 0.0\n",
      "Iteration  1466\n",
      "Training: loss 4.682776927947998, covariance difference 1.025494933128357\n",
      "Validation: loss 5.660447050960867, covariance difference 8.558700611046307, sinkhorn epsilon 0.0\n",
      "Iteration  1467\n",
      "Training: loss 4.620715618133545, covariance difference 1.0135188102722168\n",
      "Validation: loss 5.660284815596237, covariance difference 8.565658341143, sinkhorn epsilon 0.0\n",
      "Iteration  1468\n",
      "Training: loss 4.620543003082275, covariance difference 1.0165084600448608\n",
      "Validation: loss 5.606807590650355, covariance difference 8.565568726390019, sinkhorn epsilon 0.0\n",
      "Iteration  1469\n",
      "Training: loss 4.567075729370117, covariance difference 1.005742073059082\n",
      "Validation: loss 5.61704301280888, covariance difference 8.45400594859398, sinkhorn epsilon 0.0\n",
      "Iteration  1470\n",
      "Training: loss 4.57731294631958, covariance difference 1.0071971416473389\n",
      "Validation: loss 5.620136761273772, covariance difference 8.701783830887399, sinkhorn epsilon 0.0\n",
      "Iteration  1471\n",
      "Training: loss 4.580404758453369, covariance difference 1.0096211433410645\n",
      "Validation: loss 5.624168622506178, covariance difference 8.557441557741567, sinkhorn epsilon 0.0\n",
      "Iteration  1472\n",
      "Training: loss 4.584437370300293, covariance difference 1.0105175971984863\n",
      "Validation: loss 5.664049296886962, covariance difference 8.511955707947951, sinkhorn epsilon 0.0\n",
      "Iteration  1473\n",
      "Training: loss 4.624321937561035, covariance difference 1.0173240900039673\n",
      "Validation: loss 5.685355788323027, covariance difference 8.754011393980866, sinkhorn epsilon 0.0\n",
      "Iteration  1474\n",
      "Training: loss 4.645627498626709, covariance difference 1.0196162462234497\n",
      "Validation: loss 5.636981756110838, covariance difference 8.78644406344541, sinkhorn epsilon 0.0\n",
      "Iteration  1475\n",
      "Training: loss 4.59725284576416, covariance difference 1.0100842714309692\n",
      "Validation: loss 5.6669638219425105, covariance difference 8.419753764289133, sinkhorn epsilon 0.0\n",
      "Iteration  1476\n",
      "Training: loss 4.627232551574707, covariance difference 1.015075445175171\n",
      "Validation: loss 5.632319611425813, covariance difference 8.909683635161919, sinkhorn epsilon 0.0\n",
      "Iteration  1477\n",
      "Training: loss 4.592591285705566, covariance difference 1.0112719535827637\n",
      "Validation: loss 5.693930693169508, covariance difference 8.68802733590409, sinkhorn epsilon 0.0\n",
      "Iteration  1478\n",
      "Training: loss 4.654201030731201, covariance difference 1.022658348083496\n",
      "Validation: loss 5.61283074378286, covariance difference 8.47794016037017, sinkhorn epsilon 0.0\n",
      "Iteration  1479\n",
      "Training: loss 4.573100566864014, covariance difference 1.0072689056396484\n",
      "Validation: loss 5.610115247371384, covariance difference 8.543573392327742, sinkhorn epsilon 0.0\n",
      "Iteration  1480\n",
      "Training: loss 4.570379734039307, covariance difference 1.0063550472259521\n",
      "Validation: loss 5.655796864915134, covariance difference 8.498710282835392, sinkhorn epsilon 0.0\n",
      "Iteration  1481\n",
      "Training: loss 4.616067409515381, covariance difference 1.0171304941177368\n",
      "Validation: loss 5.66201656141243, covariance difference 8.522489229120897, sinkhorn epsilon 0.0\n",
      "Iteration  1482\n",
      "Training: loss 4.62228536605835, covariance difference 1.0144908428192139\n",
      "Validation: loss 5.650323219341783, covariance difference 8.792315352474473, sinkhorn epsilon 0.0\n",
      "Iteration  1483\n",
      "Training: loss 4.610592842102051, covariance difference 1.011543869972229\n",
      "Validation: loss 5.617637449757518, covariance difference 8.712052138590899, sinkhorn epsilon 5.618993780639924e-14\n",
      "Iteration  1484\n",
      "Training: loss 4.577907085418701, covariance difference 1.0084686279296875\n",
      "Validation: loss 5.679103767628179, covariance difference 8.592698860265404, sinkhorn epsilon 0.0\n",
      "Iteration  1485\n",
      "Training: loss 4.639371871948242, covariance difference 1.0171072483062744\n",
      "Validation: loss 5.548659795401889, covariance difference 8.567614914808432, sinkhorn epsilon 0.0\n",
      "Iteration  1486\n",
      "Training: loss 4.508927822113037, covariance difference 0.995280385017395\n",
      "Validation: loss 5.6760510675279265, covariance difference 8.78591778043135, sinkhorn epsilon 5.1281828327565917e-14\n",
      "Iteration  1487\n",
      "Training: loss 4.6363205909729, covariance difference 1.0186243057250977\n",
      "Validation: loss 5.60547720039513, covariance difference 8.618738959418636, sinkhorn epsilon 5.932938000556664e-14\n",
      "Iteration  1488\n",
      "Training: loss 4.5657453536987305, covariance difference 1.0051873922348022\n",
      "Validation: loss 5.675066924819188, covariance difference 8.659682897510114, sinkhorn epsilon 0.0\n",
      "Iteration  1489\n",
      "Training: loss 4.635335922241211, covariance difference 1.0181280374526978\n",
      "Validation: loss 5.684248774138286, covariance difference 8.740852564001376, sinkhorn epsilon 0.0\n",
      "Iteration  1490\n",
      "Training: loss 4.644517421722412, covariance difference 1.0206108093261719\n",
      "Validation: loss 5.634690625508706, covariance difference 8.561251993823605, sinkhorn epsilon 6.864637315262483e-14\n",
      "Iteration  1491\n",
      "Training: loss 4.594961166381836, covariance difference 1.0119911432266235\n",
      "Validation: loss 5.6722351911810875, covariance difference 8.750286546989217, sinkhorn epsilon 0.0\n",
      "Iteration  1492\n",
      "Training: loss 4.632502555847168, covariance difference 1.019117832183838\n",
      "Validation: loss 5.745470198218029, covariance difference 8.846329986934393, sinkhorn epsilon 0.0\n",
      "Iteration  1493\n",
      "Training: loss 4.705742359161377, covariance difference 1.0314995050430298\n",
      "Validation: loss 5.6792761331409825, covariance difference 8.42444479005064, sinkhorn epsilon 0.0\n",
      "Iteration  1494\n",
      "Training: loss 4.639544486999512, covariance difference 1.0211312770843506\n",
      "Validation: loss 5.662055931164582, covariance difference 8.502382893473394, sinkhorn epsilon 0.0\n",
      "Iteration  1495\n",
      "Training: loss 4.622324466705322, covariance difference 1.0146191120147705\n",
      "Validation: loss 5.640487834595952, covariance difference 8.697214153461333, sinkhorn epsilon 0.0\n",
      "Iteration  1496\n",
      "Training: loss 4.60075569152832, covariance difference 1.0140647888183594\n",
      "Validation: loss 5.540444067522202, covariance difference 8.597176395678432, sinkhorn epsilon 0.0\n",
      "Iteration  1497\n",
      "Training: loss 4.5007123947143555, covariance difference 0.9950670599937439\n",
      "Validation: loss 5.710246096189455, covariance difference 8.831718398923734, sinkhorn epsilon 0.0\n",
      "Iteration  1498\n",
      "Training: loss 4.670499801635742, covariance difference 1.0236377716064453\n",
      "Validation: loss 5.681432691650386, covariance difference 8.451944247198211, sinkhorn epsilon 0.0\n",
      "Iteration  1499\n",
      "Training: loss 4.641704082489014, covariance difference 1.0196895599365234\n",
      "Validation: loss 5.67636920414425, covariance difference 8.674730129739519, sinkhorn epsilon 3.6883086158374993e-14\n",
      "Iteration  1500\n",
      "Training: loss 4.636638164520264, covariance difference 1.0188102722167969\n",
      "Validation: loss 5.643405052582885, covariance difference 8.704011195652061, sinkhorn epsilon 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  1501\n",
      "Training: loss 4.603675842285156, covariance difference 1.0116043090820312\n",
      "Validation: loss 5.613567114935724, covariance difference 8.545890659168247, sinkhorn epsilon 0.0\n",
      "Iteration  1502\n",
      "Training: loss 4.5738348960876465, covariance difference 1.0077539682388306\n",
      "Validation: loss 5.694269015158964, covariance difference 8.539612581963299, sinkhorn epsilon 0.0\n",
      "Iteration  1503\n",
      "Training: loss 4.654540061950684, covariance difference 1.0197736024856567\n",
      "Validation: loss 5.6295393774195785, covariance difference 8.511302237584788, sinkhorn epsilon 0.0\n",
      "Iteration  1504\n",
      "Training: loss 4.589807510375977, covariance difference 1.006723165512085\n",
      "Validation: loss 5.632959445905325, covariance difference 8.618491917597993, sinkhorn epsilon 0.0\n",
      "Iteration  1505\n",
      "Training: loss 4.593227386474609, covariance difference 1.010103464126587\n",
      "Validation: loss 5.602809111560768, covariance difference 8.620256819414848, sinkhorn epsilon 0.0\n",
      "Iteration  1506\n",
      "Training: loss 4.563076972961426, covariance difference 1.0066814422607422\n",
      "Validation: loss 5.608286183184835, covariance difference 8.583849109093794, sinkhorn epsilon 0.0\n",
      "Iteration  1507\n",
      "Training: loss 4.568550109863281, covariance difference 1.0044862031936646\n",
      "Validation: loss 5.611219213742998, covariance difference 8.496108162475778, sinkhorn epsilon 0.0\n",
      "Iteration  1508\n",
      "Training: loss 4.571486949920654, covariance difference 1.0062839984893799\n",
      "Validation: loss 5.592755765984543, covariance difference 8.605395615980928, sinkhorn epsilon 0.0\n",
      "Iteration  1509\n",
      "Training: loss 4.553024768829346, covariance difference 1.0047049522399902\n",
      "Validation: loss 5.600089504932022, covariance difference 8.4424773127529, sinkhorn epsilon 0.0\n",
      "Iteration  1510\n",
      "Training: loss 4.560357093811035, covariance difference 1.0045411586761475\n",
      "Validation: loss 5.5976676965684256, covariance difference 8.482345226879156, sinkhorn epsilon 2.3148841626597498e-14\n",
      "Iteration  1511\n",
      "Training: loss 4.557941913604736, covariance difference 1.004404902458191\n",
      "Validation: loss 5.666380165236612, covariance difference 8.486654240445242, sinkhorn epsilon 0.0\n",
      "Iteration  1512\n",
      "Training: loss 4.626648426055908, covariance difference 1.0165355205535889\n",
      "Validation: loss 5.700603351897147, covariance difference 8.676957969899641, sinkhorn epsilon 0.0\n",
      "Iteration  1513\n",
      "Training: loss 4.66086483001709, covariance difference 1.0230164527893066\n",
      "Validation: loss 5.701577513784649, covariance difference 8.435032736929852, sinkhorn epsilon 0.0\n",
      "Iteration  1514\n",
      "Training: loss 4.661845684051514, covariance difference 1.0232102870941162\n",
      "Validation: loss 5.566099379977884, covariance difference 8.675821776136537, sinkhorn epsilon 0.0\n",
      "Iteration  1515\n",
      "Training: loss 4.526368141174316, covariance difference 1.0000314712524414\n",
      "Validation: loss 5.630115018226634, covariance difference 8.514951423976097, sinkhorn epsilon 2.4467604348648084e-14\n",
      "Iteration  1516\n",
      "Training: loss 4.590390205383301, covariance difference 1.009742021560669\n",
      "Validation: loss 5.643209401748855, covariance difference 8.717378955516939, sinkhorn epsilon 0.0\n",
      "Iteration  1517\n",
      "Training: loss 4.603480339050293, covariance difference 1.012328028678894\n",
      "Validation: loss 5.695827786776267, covariance difference 8.65453043477818, sinkhorn epsilon 0.0\n",
      "Iteration  1518\n",
      "Training: loss 4.656096458435059, covariance difference 1.0220060348510742\n",
      "Validation: loss 5.616943449013958, covariance difference 8.631582009818619, sinkhorn epsilon 0.0\n",
      "Iteration  1519\n",
      "Training: loss 4.577206134796143, covariance difference 1.0076572895050049\n",
      "Validation: loss 5.6728597909323355, covariance difference 8.696745583786504, sinkhorn epsilon 0.0\n",
      "Iteration  1520\n",
      "Training: loss 4.6331353187561035, covariance difference 1.0157822370529175\n",
      "Validation: loss 5.708329903499552, covariance difference 8.783380960737436, sinkhorn epsilon 0.0\n",
      "Iteration  1521\n",
      "Training: loss 4.668598175048828, covariance difference 1.0250362157821655\n",
      "Validation: loss 5.596934270833383, covariance difference 8.50959510517325, sinkhorn epsilon 0.0\n",
      "Iteration  1522\n",
      "Training: loss 4.55720329284668, covariance difference 1.004983901977539\n",
      "Validation: loss 5.6053717573952815, covariance difference 8.348185603580577, sinkhorn epsilon 0.0\n",
      "Iteration  1523\n",
      "Training: loss 4.565639972686768, covariance difference 1.0058082342147827\n",
      "Validation: loss 5.715060291578766, covariance difference 8.557559095959357, sinkhorn epsilon 0.0\n",
      "Iteration  1524\n",
      "Training: loss 4.675328254699707, covariance difference 1.0221973657608032\n",
      "Validation: loss 5.589311975083884, covariance difference 8.468956178367494, sinkhorn epsilon 0.0\n",
      "Iteration  1525\n",
      "Training: loss 4.549580097198486, covariance difference 1.0030452013015747\n",
      "Validation: loss 5.693894151494859, covariance difference 8.67255323152216, sinkhorn epsilon 0.0\n",
      "Iteration  1526\n",
      "Training: loss 4.654162406921387, covariance difference 1.0216130018234253\n",
      "Validation: loss 5.578123013126987, covariance difference 8.531061352738558, sinkhorn epsilon 5.621190447091073e-14\n",
      "Iteration  1527\n",
      "Training: loss 4.53839111328125, covariance difference 1.0003145933151245\n",
      "Validation: loss 5.6560598670708995, covariance difference 8.70924340820955, sinkhorn epsilon 0.0\n",
      "Iteration  1528\n",
      "Training: loss 4.616328239440918, covariance difference 1.0128188133239746\n",
      "Validation: loss 5.626312219101923, covariance difference 8.499134466695926, sinkhorn epsilon 0.0\n",
      "Iteration  1529\n",
      "Training: loss 4.586579322814941, covariance difference 1.0089131593704224\n",
      "Validation: loss 5.640375374771085, covariance difference 8.632212019237492, sinkhorn epsilon 0.0\n",
      "Iteration  1530\n",
      "Training: loss 4.600647926330566, covariance difference 1.012435793876648\n",
      "Validation: loss 5.62934749676041, covariance difference 8.61493174048685, sinkhorn epsilon 0.0\n",
      "Iteration  1531\n",
      "Training: loss 4.589616298675537, covariance difference 1.0112448930740356\n",
      "Validation: loss 5.644480143944271, covariance difference 8.595612287193516, sinkhorn epsilon 0.0\n",
      "Iteration  1532\n",
      "Training: loss 4.604747772216797, covariance difference 1.0132386684417725\n",
      "Validation: loss 5.669035440030754, covariance difference 8.84115563147976, sinkhorn epsilon 0.0\n",
      "Iteration  1533\n",
      "Training: loss 4.629306316375732, covariance difference 1.0172889232635498\n",
      "Validation: loss 5.6090803259355795, covariance difference 8.512267700206577, sinkhorn epsilon 0.0\n",
      "Iteration  1534\n",
      "Training: loss 4.5693488121032715, covariance difference 1.0074059963226318\n",
      "Validation: loss 5.63672861958614, covariance difference 8.575876392939712, sinkhorn epsilon 0.0\n",
      "Iteration  1535\n",
      "Training: loss 4.5969977378845215, covariance difference 1.009909749031067\n",
      "Validation: loss 5.729720880628885, covariance difference 8.728752549221285, sinkhorn epsilon 0.0\n",
      "Iteration  1536\n",
      "Training: loss 4.6899847984313965, covariance difference 1.0286335945129395\n",
      "Validation: loss 5.654550662218455, covariance difference 8.538287382542265, sinkhorn epsilon 0.0\n",
      "Iteration  1537\n",
      "Training: loss 4.6148223876953125, covariance difference 1.0146050453186035\n",
      "Validation: loss 5.68241132804498, covariance difference 8.588439286279781, sinkhorn epsilon 0.0\n",
      "Iteration  1538\n",
      "Training: loss 4.642679214477539, covariance difference 1.0205100774765015\n",
      "Validation: loss 5.644211605661369, covariance difference 8.4455126678329, sinkhorn epsilon 0.0\n",
      "Iteration  1539\n",
      "Training: loss 4.604482650756836, covariance difference 1.0129965543746948\n",
      "Validation: loss 5.647903338675327, covariance difference 8.827498509715447, sinkhorn epsilon 0.0\n",
      "Iteration  1540\n",
      "Training: loss 4.608168601989746, covariance difference 1.0145726203918457\n",
      "Validation: loss 5.720425907194419, covariance difference 8.51543249573563, sinkhorn epsilon 0.0\n",
      "Iteration  1541\n",
      "Training: loss 4.680680751800537, covariance difference 1.0277137756347656\n",
      "Validation: loss 5.648206883487406, covariance difference 8.591743810402528, sinkhorn epsilon 0.0\n",
      "Iteration  1542\n",
      "Training: loss 4.60847282409668, covariance difference 1.0124971866607666\n",
      "Validation: loss 5.600581950097544, covariance difference 8.485238616364326, sinkhorn epsilon 0.0\n",
      "Iteration  1543\n",
      "Training: loss 4.560851097106934, covariance difference 1.0044039487838745\n",
      "Validation: loss 5.651594863711509, covariance difference 8.573372563961566, sinkhorn epsilon 0.0\n",
      "Iteration  1544\n",
      "Training: loss 4.6118597984313965, covariance difference 1.0124233961105347\n",
      "Validation: loss 5.682029898471971, covariance difference 8.480287723216101, sinkhorn epsilon 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  1545\n",
      "Training: loss 4.642299175262451, covariance difference 1.0196179151535034\n",
      "Validation: loss 5.6755768578351535, covariance difference 8.571214664506256, sinkhorn epsilon 0.0\n",
      "Iteration  1546\n",
      "Training: loss 4.635846138000488, covariance difference 1.0190683603286743\n",
      "Validation: loss 5.7313190897659565, covariance difference 8.969478415895932, sinkhorn epsilon 0.0\n",
      "Iteration  1547\n",
      "Training: loss 4.691588878631592, covariance difference 1.0297069549560547\n",
      "Validation: loss 5.723103725605788, covariance difference 8.52457239355053, sinkhorn epsilon 0.0\n",
      "Iteration  1548\n",
      "Training: loss 4.683371543884277, covariance difference 1.0278209447860718\n",
      "Validation: loss 5.596434792879722, covariance difference 8.296061427644059, sinkhorn epsilon 0.0\n",
      "Iteration  1549\n",
      "Training: loss 4.556704521179199, covariance difference 1.0038094520568848\n",
      "Validation: loss 5.607151220968188, covariance difference 8.571613993843801, sinkhorn epsilon 0.0\n",
      "Iteration  1550\n",
      "Training: loss 4.567420482635498, covariance difference 1.0061370134353638\n",
      "Validation: loss 5.670125219788556, covariance difference 8.70503426699131, sinkhorn epsilon 0.0\n",
      "Iteration  1551\n",
      "Training: loss 4.630393028259277, covariance difference 1.0175817012786865\n",
      "Validation: loss 5.634717693414473, covariance difference 8.489604272233418, sinkhorn epsilon 0.0\n",
      "Iteration  1552\n",
      "Training: loss 4.594985008239746, covariance difference 1.0108616352081299\n",
      "Validation: loss 5.614978986120278, covariance difference 8.270773146226722, sinkhorn epsilon 0.0\n",
      "Iteration  1553\n",
      "Training: loss 4.575253009796143, covariance difference 1.0078024864196777\n",
      "Validation: loss 5.729180916651925, covariance difference 8.876812985699647, sinkhorn epsilon 7.485123076262921e-14\n",
      "Iteration  1554\n",
      "Training: loss 4.689453125, covariance difference 1.0293548107147217\n",
      "Validation: loss 5.7404655995946126, covariance difference 8.935926101615697, sinkhorn epsilon 0.0\n",
      "Iteration  1555\n",
      "Training: loss 4.7007341384887695, covariance difference 1.0292083024978638\n",
      "Validation: loss 5.65390629053318, covariance difference 8.440580069414258, sinkhorn epsilon 1.7843498698554628e-14\n",
      "Iteration  1556\n",
      "Training: loss 4.614166259765625, covariance difference 1.0132665634155273\n",
      "Validation: loss 5.658711535214557, covariance difference 8.671105148851034, sinkhorn epsilon 4.565542400946359e-14\n",
      "Iteration  1557\n",
      "Training: loss 4.618982791900635, covariance difference 1.015480637550354\n",
      "Validation: loss 5.681665243384497, covariance difference 8.722422339441302, sinkhorn epsilon 0.0\n",
      "Iteration  1558\n",
      "Training: loss 4.641932964324951, covariance difference 1.018010139465332\n",
      "Validation: loss 5.510670006590106, covariance difference 8.557571999834153, sinkhorn epsilon 0.0\n",
      "Iteration  1559\n",
      "Training: loss 4.470926284790039, covariance difference 0.98824542760849\n",
      "Validation: loss 5.655213341085442, covariance difference 8.8032757979062, sinkhorn epsilon 0.0\n",
      "Iteration  1560\n",
      "Training: loss 4.615487098693848, covariance difference 1.0137349367141724\n",
      "Validation: loss 5.636322501412171, covariance difference 8.537919536962045, sinkhorn epsilon 2.3584365701318283e-14\n",
      "Iteration  1561\n",
      "Training: loss 4.596592903137207, covariance difference 1.012540578842163\n",
      "Validation: loss 5.613489584873005, covariance difference 8.701604473552479, sinkhorn epsilon 0.0\n",
      "Iteration  1562\n",
      "Training: loss 4.573759078979492, covariance difference 1.0088136196136475\n",
      "Validation: loss 5.658963909039261, covariance difference 8.68555719225121, sinkhorn epsilon 0.0\n",
      "Iteration  1563\n",
      "Training: loss 4.619232654571533, covariance difference 1.0153218507766724\n",
      "Validation: loss 5.568611004560605, covariance difference 8.578801023109857, sinkhorn epsilon 0.0\n",
      "Iteration  1564\n",
      "Training: loss 4.528879642486572, covariance difference 0.9997646808624268\n",
      "Validation: loss 5.691462009697491, covariance difference 8.685651038532402, sinkhorn epsilon 0.0\n",
      "Iteration  1565\n",
      "Training: loss 4.651717185974121, covariance difference 1.0209200382232666\n",
      "Validation: loss 5.573822101062494, covariance difference 8.370626937493599, sinkhorn epsilon 0.0\n",
      "Iteration  1566\n",
      "Training: loss 4.534090042114258, covariance difference 0.999867856502533\n",
      "Validation: loss 5.674000707807005, covariance difference 8.61980367800281, sinkhorn epsilon 0.0\n",
      "Iteration  1567\n",
      "Training: loss 4.634269714355469, covariance difference 1.0183024406433105\n",
      "Validation: loss 5.713484833570224, covariance difference 8.80188418165772, sinkhorn epsilon 0.0\n",
      "Iteration  1568\n",
      "Training: loss 4.673752784729004, covariance difference 1.023087978363037\n",
      "Validation: loss 5.644610983002239, covariance difference 8.565153967375812, sinkhorn epsilon 0.0\n",
      "Iteration  1569\n",
      "Training: loss 4.604874610900879, covariance difference 1.0111078023910522\n",
      "Validation: loss 5.680045615423675, covariance difference 8.85298693138427, sinkhorn epsilon 0.0\n",
      "Iteration  1570\n",
      "Training: loss 4.640326023101807, covariance difference 1.0177785158157349\n",
      "Validation: loss 5.6983109552320546, covariance difference 8.62424681846566, sinkhorn epsilon 0.0\n",
      "Iteration  1571\n",
      "Training: loss 4.658580303192139, covariance difference 1.0224668979644775\n",
      "Validation: loss 5.6728050735175755, covariance difference 8.765634314745588, sinkhorn epsilon 0.0\n",
      "Iteration  1572\n",
      "Training: loss 4.633070945739746, covariance difference 1.018669843673706\n",
      "Validation: loss 5.640581784203497, covariance difference 8.616519199634824, sinkhorn epsilon 0.0\n",
      "Iteration  1573\n",
      "Training: loss 4.600851058959961, covariance difference 1.0132266283035278\n",
      "Validation: loss 5.635331806915447, covariance difference 8.592294257255002, sinkhorn epsilon 0.0\n",
      "Iteration  1574\n",
      "Training: loss 4.595599174499512, covariance difference 1.0105091333389282\n",
      "Validation: loss 5.747070263885215, covariance difference 8.903967044393992, sinkhorn epsilon 0.0\n",
      "Iteration  1575\n",
      "Training: loss 4.707343101501465, covariance difference 1.031175971031189\n",
      "Validation: loss 5.638798509343719, covariance difference 8.511200071941634, sinkhorn epsilon 0.0\n",
      "Iteration  1576\n",
      "Training: loss 4.599066734313965, covariance difference 1.0110737085342407\n",
      "Validation: loss 5.703474936315384, covariance difference 8.658567114455382, sinkhorn epsilon 0.0\n",
      "Iteration  1577\n",
      "Training: loss 4.663727760314941, covariance difference 1.024187684059143\n",
      "Validation: loss 5.680607270642874, covariance difference 8.52162601116083, sinkhorn epsilon 0.0\n",
      "Iteration  1578\n",
      "Training: loss 4.640875816345215, covariance difference 1.0189063549041748\n",
      "Validation: loss 5.60666179399919, covariance difference 8.465425082395695, sinkhorn epsilon 0.0\n",
      "Iteration  1579\n",
      "Training: loss 4.566926002502441, covariance difference 1.0067671537399292\n",
      "Validation: loss 5.624742111362748, covariance difference 8.64082241666592, sinkhorn epsilon 0.0\n",
      "Iteration  1580\n",
      "Training: loss 4.585010051727295, covariance difference 1.0112851858139038\n",
      "Validation: loss 5.652646220950567, covariance difference 8.578470427971084, sinkhorn epsilon 0.0\n",
      "Iteration  1581\n",
      "Training: loss 4.612913608551025, covariance difference 1.0131558179855347\n",
      "Validation: loss 5.651351908620929, covariance difference 8.690615462335339, sinkhorn epsilon 0.0\n",
      "Iteration  1582\n",
      "Training: loss 4.6116228103637695, covariance difference 1.0129739046096802\n",
      "Validation: loss 5.588899552878113, covariance difference 8.431381002492364, sinkhorn epsilon 0.0\n",
      "Iteration  1583\n",
      "Training: loss 4.549173355102539, covariance difference 1.0029114484786987\n",
      "Validation: loss 5.628211327338148, covariance difference 8.617261399566962, sinkhorn epsilon 0.0\n",
      "Iteration  1584\n",
      "Training: loss 4.5884809494018555, covariance difference 1.0105830430984497\n",
      "Validation: loss 5.623741725109493, covariance difference 8.76358062075961, sinkhorn epsilon 0.0\n",
      "Iteration  1585\n",
      "Training: loss 4.584010124206543, covariance difference 1.0086042881011963\n",
      "Validation: loss 5.7290782977757635, covariance difference 8.729290632716792, sinkhorn epsilon 0.0\n",
      "Iteration  1586\n",
      "Training: loss 4.689347267150879, covariance difference 1.0268311500549316\n",
      "Validation: loss 5.623652890589108, covariance difference 8.765836228825814, sinkhorn epsilon 0.0\n",
      "Iteration  1587\n",
      "Training: loss 4.58392333984375, covariance difference 1.0093697309494019\n",
      "Validation: loss 5.653020126694495, covariance difference 8.63496029517854, sinkhorn epsilon 0.0\n",
      "Iteration  1588\n",
      "Training: loss 4.613288402557373, covariance difference 1.0143611431121826\n",
      "Validation: loss 5.707163230700873, covariance difference 8.63052833842403, sinkhorn epsilon 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  1589\n",
      "Training: loss 4.667431354522705, covariance difference 1.0243792533874512\n",
      "Validation: loss 5.65280038234436, covariance difference 8.713571292267572, sinkhorn epsilon 0.0\n",
      "Iteration  1590\n",
      "Training: loss 4.613069534301758, covariance difference 1.0143790245056152\n",
      "Validation: loss 5.676100952699197, covariance difference 8.72440124107961, sinkhorn epsilon 0.0\n",
      "Iteration  1591\n",
      "Training: loss 4.636364936828613, covariance difference 1.0198261737823486\n",
      "Validation: loss 5.672590056609411, covariance difference 8.488172688492753, sinkhorn epsilon 0.0\n",
      "Iteration  1592\n",
      "Training: loss 4.6328630447387695, covariance difference 1.0179377794265747\n",
      "Validation: loss 5.6516823709552035, covariance difference 8.359227742568006, sinkhorn epsilon 0.0\n",
      "Iteration  1593\n",
      "Training: loss 4.6119489669799805, covariance difference 1.0134814977645874\n",
      "Validation: loss 5.563995506026011, covariance difference 8.309278429269854, sinkhorn epsilon 0.0\n",
      "Iteration  1594\n",
      "Training: loss 4.524260520935059, covariance difference 0.9983834624290466\n",
      "Validation: loss 5.705697284047508, covariance difference 8.590192792261357, sinkhorn epsilon 0.0\n",
      "Iteration  1595\n",
      "Training: loss 4.665962219238281, covariance difference 1.023515224456787\n",
      "Validation: loss 5.631356061374111, covariance difference 8.632706370719228, sinkhorn epsilon 0.0\n",
      "Iteration  1596\n",
      "Training: loss 4.591624736785889, covariance difference 1.0097352266311646\n",
      "Validation: loss 5.657886664279426, covariance difference 8.70923874846114, sinkhorn epsilon 0.0\n",
      "Iteration  1597\n",
      "Training: loss 4.618163108825684, covariance difference 1.0147767066955566\n",
      "Validation: loss 5.678748142838242, covariance difference 8.443328305768748, sinkhorn epsilon 0.0\n",
      "Iteration  1598\n",
      "Training: loss 4.639016151428223, covariance difference 1.0173993110656738\n",
      "Validation: loss 5.6034593502215895, covariance difference 8.690963383792445, sinkhorn epsilon 5.216339714086566e-14\n",
      "Iteration  1599\n",
      "Training: loss 4.563727855682373, covariance difference 1.0038022994995117\n",
      "Validation: loss 5.664147929034215, covariance difference 8.653836306439558, sinkhorn epsilon 0.0\n",
      "Iteration  1600\n",
      "Training: loss 4.624415874481201, covariance difference 1.0146980285644531\n",
      "Validation: loss 5.680961409370647, covariance difference 8.412705413871963, sinkhorn epsilon 0.0\n",
      "Iteration  1601\n",
      "Training: loss 4.641226291656494, covariance difference 1.0194016695022583\n",
      "Validation: loss 5.6995412912301635, covariance difference 8.621060908572153, sinkhorn epsilon 0.0\n",
      "Iteration  1602\n",
      "Training: loss 4.659809589385986, covariance difference 1.0207010507583618\n",
      "Validation: loss 5.709788976240257, covariance difference 8.485200667971254, sinkhorn epsilon 0.0\n",
      "Iteration  1603\n",
      "Training: loss 4.670060157775879, covariance difference 1.0239958763122559\n",
      "Validation: loss 5.643217892462955, covariance difference 8.759752416879053, sinkhorn epsilon 1.6602135057621733e-14\n",
      "Iteration  1604\n",
      "Training: loss 4.603485584259033, covariance difference 1.0138726234436035\n",
      "Validation: loss 5.6651394022534785, covariance difference 8.587173952765557, sinkhorn epsilon 0.0\n",
      "Iteration  1605\n",
      "Training: loss 4.6254072189331055, covariance difference 1.0160322189331055\n",
      "Validation: loss 5.663821057434206, covariance difference 8.525941123608968, sinkhorn epsilon 0.0\n",
      "Iteration  1606\n",
      "Training: loss 4.624091148376465, covariance difference 1.0169482231140137\n",
      "Validation: loss 5.634496588975814, covariance difference 8.625593074402705, sinkhorn epsilon 0.0\n",
      "Iteration  1607\n",
      "Training: loss 4.5947651863098145, covariance difference 1.010528564453125\n",
      "Validation: loss 5.612763733167267, covariance difference 8.748363701297071, sinkhorn epsilon 0.0\n",
      "Iteration  1608\n",
      "Training: loss 4.573028087615967, covariance difference 1.0072476863861084\n",
      "Validation: loss 5.674895397405439, covariance difference 8.586660391990659, sinkhorn epsilon 0.0\n",
      "Iteration  1609\n",
      "Training: loss 4.635163307189941, covariance difference 1.0179266929626465\n",
      "Validation: loss 5.701687083243563, covariance difference 8.794123862255399, sinkhorn epsilon 0.0\n",
      "Iteration  1610\n",
      "Training: loss 4.661960124969482, covariance difference 1.0228201150894165\n",
      "Validation: loss 5.6603362474602905, covariance difference 8.583708642360234, sinkhorn epsilon 7.364865062014434e-14\n",
      "Iteration  1611\n",
      "Training: loss 4.620604991912842, covariance difference 1.0150805711746216\n",
      "Validation: loss 5.64048762306206, covariance difference 8.637692577106515, sinkhorn epsilon 0.0\n",
      "Iteration  1612\n",
      "Training: loss 4.600756645202637, covariance difference 1.013867735862732\n",
      "Validation: loss 5.644624648199176, covariance difference 8.49513822077804, sinkhorn epsilon 0.0\n",
      "Iteration  1613\n",
      "Training: loss 4.604892730712891, covariance difference 1.0127990245819092\n",
      "Validation: loss 5.722911826990455, covariance difference 8.625590271441814, sinkhorn epsilon 0.0\n",
      "Iteration  1614\n",
      "Training: loss 4.683199405670166, covariance difference 1.0282483100891113\n",
      "Validation: loss 5.651740923087319, covariance difference 8.490613259297625, sinkhorn epsilon 0.0\n",
      "Iteration  1615\n",
      "Training: loss 4.61201286315918, covariance difference 1.0151739120483398\n",
      "Validation: loss 5.645401729961659, covariance difference 8.586112265834892, sinkhorn epsilon 0.0\n",
      "Iteration  1616\n",
      "Training: loss 4.605672359466553, covariance difference 1.0129737854003906\n",
      "Validation: loss 5.623712541188697, covariance difference 8.471555077458998, sinkhorn epsilon 1.6651544638908608e-14\n",
      "Iteration  1617\n",
      "Training: loss 4.583993911743164, covariance difference 1.0092498064041138\n",
      "Validation: loss 5.656597175805933, covariance difference 8.674604069926003, sinkhorn epsilon 3.973498338108544e-14\n",
      "Iteration  1618\n",
      "Training: loss 4.616868495941162, covariance difference 1.0151550769805908\n",
      "Validation: loss 5.705708206813569, covariance difference 8.839273691441004, sinkhorn epsilon 0.0\n",
      "Iteration  1619\n",
      "Training: loss 4.6659770011901855, covariance difference 1.0232559442520142\n",
      "Validation: loss 5.617727679169329, covariance difference 8.5703325067187, sinkhorn epsilon 0.0\n",
      "Iteration  1620\n",
      "Training: loss 4.577995300292969, covariance difference 1.0080677270889282\n",
      "Validation: loss 5.679278810152805, covariance difference 8.776072109799275, sinkhorn epsilon 0.0\n",
      "Iteration  1621\n",
      "Training: loss 4.639549255371094, covariance difference 1.0200501680374146\n",
      "Validation: loss 5.688004554954267, covariance difference 8.823531895483221, sinkhorn epsilon 0.0\n",
      "Iteration  1622\n",
      "Training: loss 4.648279190063477, covariance difference 1.0197603702545166\n",
      "Validation: loss 5.612572387795377, covariance difference 8.532098357522358, sinkhorn epsilon 0.0\n",
      "Iteration  1623\n",
      "Training: loss 4.572840213775635, covariance difference 1.0077829360961914\n",
      "Validation: loss 5.631940536882315, covariance difference 8.562112280247462, sinkhorn epsilon 0.0\n",
      "Iteration  1624\n",
      "Training: loss 4.592210292816162, covariance difference 1.0109819173812866\n",
      "Validation: loss 5.652721417308602, covariance difference 8.774551378965098, sinkhorn epsilon 0.0\n",
      "Iteration  1625\n",
      "Training: loss 4.612985610961914, covariance difference 1.0148749351501465\n",
      "Validation: loss 5.591548550872014, covariance difference 8.46149433693923, sinkhorn epsilon 0.0\n",
      "Iteration  1626\n",
      "Training: loss 4.551817417144775, covariance difference 1.0037872791290283\n",
      "Validation: loss 5.631297149942299, covariance difference 8.48863728939708, sinkhorn epsilon 0.0\n",
      "Iteration  1627\n",
      "Training: loss 4.59156608581543, covariance difference 1.0097994804382324\n",
      "Validation: loss 5.686117227904836, covariance difference 8.675674105313373, sinkhorn epsilon 0.0\n",
      "Iteration  1628\n",
      "Training: loss 4.646380424499512, covariance difference 1.0189595222473145\n",
      "Validation: loss 5.660392666302103, covariance difference 8.473903188262389, sinkhorn epsilon 0.0\n",
      "Iteration  1629\n",
      "Training: loss 4.620660781860352, covariance difference 1.0156850814819336\n",
      "Validation: loss 5.6833274875488335, covariance difference 8.692974738819032, sinkhorn epsilon 6.952444022785255e-14\n",
      "Iteration  1630\n",
      "Training: loss 4.643599510192871, covariance difference 1.0200635194778442\n",
      "Validation: loss 5.564752250455136, covariance difference 8.301941368752564, sinkhorn epsilon 0.0\n",
      "Iteration  1631\n",
      "Training: loss 4.525020599365234, covariance difference 0.9979145526885986\n",
      "Validation: loss 5.614374091886748, covariance difference 8.497194130536577, sinkhorn epsilon 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  1632\n",
      "Training: loss 4.574638843536377, covariance difference 1.0067594051361084\n",
      "Validation: loss 5.627238495448227, covariance difference 8.460922128948711, sinkhorn epsilon 6.143291315138666e-14\n",
      "Iteration  1633\n",
      "Training: loss 4.587507247924805, covariance difference 1.0105057954788208\n",
      "Validation: loss 5.709703812440076, covariance difference 8.587565508199566, sinkhorn epsilon 0.0\n",
      "Iteration  1634\n",
      "Training: loss 4.669968128204346, covariance difference 1.0244396924972534\n",
      "Validation: loss 5.661186410235226, covariance difference 8.480172377224875, sinkhorn epsilon 0.0\n",
      "Iteration  1635\n",
      "Training: loss 4.621456146240234, covariance difference 1.0136269330978394\n",
      "Validation: loss 5.59752667475856, covariance difference 8.465316813057775, sinkhorn epsilon 0.0\n",
      "Iteration  1636\n",
      "Training: loss 4.557791709899902, covariance difference 1.0038330554962158\n",
      "Validation: loss 5.667473905965265, covariance difference 8.398496791076825, sinkhorn epsilon 0.0\n",
      "Iteration  1637\n",
      "Training: loss 4.627743721008301, covariance difference 1.017065405845642\n",
      "Validation: loss 5.555118296608168, covariance difference 8.485834354294257, sinkhorn epsilon 0.0\n",
      "Iteration  1638\n",
      "Training: loss 4.515386581420898, covariance difference 0.9958602786064148\n",
      "Validation: loss 5.652365287499675, covariance difference 8.735599654680763, sinkhorn epsilon 0.0\n",
      "Iteration  1639\n",
      "Training: loss 4.61263370513916, covariance difference 1.0153353214263916\n",
      "Validation: loss 5.637986256532572, covariance difference 8.720038584819367, sinkhorn epsilon 0.0\n",
      "Iteration  1640\n",
      "Training: loss 4.598251819610596, covariance difference 1.010274052619934\n",
      "Validation: loss 5.674643903081868, covariance difference 8.854106996159747, sinkhorn epsilon 0.0\n",
      "Iteration  1641\n",
      "Training: loss 4.634912014007568, covariance difference 1.017452359199524\n",
      "Validation: loss 5.628521588404597, covariance difference 8.504469612113477, sinkhorn epsilon 0.0\n",
      "Iteration  1642\n",
      "Training: loss 4.588790416717529, covariance difference 1.012444019317627\n",
      "Validation: loss 5.666002110894594, covariance difference 8.488065452738573, sinkhorn epsilon 0.0\n",
      "Iteration  1643\n",
      "Training: loss 4.626271724700928, covariance difference 1.0148884057998657\n",
      "Validation: loss 5.663191587519186, covariance difference 8.853554302508511, sinkhorn epsilon 0.0\n",
      "Iteration  1644\n",
      "Training: loss 4.62346076965332, covariance difference 1.0159450769424438\n",
      "Validation: loss 5.656261727437439, covariance difference 8.810837133221888, sinkhorn epsilon 0.0\n",
      "Iteration  1645\n",
      "Training: loss 4.616519927978516, covariance difference 1.0147424936294556\n",
      "Validation: loss 5.676703464757882, covariance difference 8.702918109980995, sinkhorn epsilon 0.0\n",
      "Iteration  1646\n",
      "Training: loss 4.636971473693848, covariance difference 1.0185551643371582\n",
      "Validation: loss 5.651203975321248, covariance difference 8.591526750022275, sinkhorn epsilon 4.6617592791201795e-14\n",
      "Iteration  1647\n",
      "Training: loss 4.611478805541992, covariance difference 1.0122861862182617\n",
      "Validation: loss 5.686993396976632, covariance difference 8.705566192561301, sinkhorn epsilon 0.0\n",
      "Iteration  1648\n",
      "Training: loss 4.647261619567871, covariance difference 1.019567608833313\n",
      "Validation: loss 5.668579484865034, covariance difference 8.812321256775851, sinkhorn epsilon 0.0\n",
      "Iteration  1649\n",
      "Training: loss 4.628835201263428, covariance difference 1.0172616243362427\n",
      "Validation: loss 5.674531023193263, covariance difference 8.569891045393975, sinkhorn epsilon 0.0\n",
      "Iteration  1650\n",
      "Training: loss 4.634801387786865, covariance difference 1.0168001651763916\n",
      "Validation: loss 5.6389312123246, covariance difference 8.708715145600213, sinkhorn epsilon 0.0\n",
      "Iteration  1651\n",
      "Training: loss 4.59920597076416, covariance difference 1.0104938745498657\n",
      "Validation: loss 5.695515582583472, covariance difference 8.755009272777935, sinkhorn epsilon 0.0\n",
      "Iteration  1652\n",
      "Training: loss 4.6557793617248535, covariance difference 1.0205645561218262\n",
      "Validation: loss 5.711359018464192, covariance difference 8.799239117208463, sinkhorn epsilon 0.0\n",
      "Iteration  1653\n",
      "Training: loss 4.671627521514893, covariance difference 1.0241987705230713\n",
      "Validation: loss 5.63778176165634, covariance difference 8.517573400607152, sinkhorn epsilon 0.0\n",
      "Iteration  1654\n",
      "Training: loss 4.598050594329834, covariance difference 1.012285590171814\n",
      "Validation: loss 5.556488864273381, covariance difference 8.193898562466439, sinkhorn epsilon 0.0\n",
      "Iteration  1655\n",
      "Training: loss 4.516757011413574, covariance difference 0.9973588585853577\n",
      "Validation: loss 5.650171395487442, covariance difference 8.613083883573525, sinkhorn epsilon 0.0\n",
      "Iteration  1656\n",
      "Training: loss 4.610435962677002, covariance difference 1.0138366222381592\n",
      "Validation: loss 5.639714151441854, covariance difference 8.450797180066596, sinkhorn epsilon 0.0\n",
      "Iteration  1657\n",
      "Training: loss 4.599985122680664, covariance difference 1.010090708732605\n",
      "Validation: loss 5.60301542145913, covariance difference 8.455078179363415, sinkhorn epsilon 0.0\n",
      "Iteration  1658\n",
      "Training: loss 4.563284873962402, covariance difference 1.0051853656768799\n",
      "Validation: loss 5.638824899253148, covariance difference 8.327734644659017, sinkhorn epsilon 0.0\n",
      "Iteration  1659\n",
      "Training: loss 4.599096298217773, covariance difference 1.011344075202942\n",
      "Validation: loss 5.639264529031344, covariance difference 8.526703751555477, sinkhorn epsilon 0.0\n",
      "Iteration  1660\n",
      "Training: loss 4.599532127380371, covariance difference 1.0111680030822754\n",
      "Validation: loss 5.678625915716186, covariance difference 8.535886423592418, sinkhorn epsilon 0.0\n",
      "Iteration  1661\n",
      "Training: loss 4.638894081115723, covariance difference 1.0169464349746704\n",
      "Validation: loss 5.643904630273752, covariance difference 8.462600506115127, sinkhorn epsilon 0.0\n",
      "Iteration  1662\n",
      "Training: loss 4.604172229766846, covariance difference 1.012217402458191\n",
      "Validation: loss 5.725169085956966, covariance difference 8.810452479870055, sinkhorn epsilon 0.0\n",
      "Iteration  1663\n",
      "Training: loss 4.6854400634765625, covariance difference 1.0280193090438843\n",
      "Validation: loss 5.572617936367163, covariance difference 8.448578326425453, sinkhorn epsilon 0.0\n",
      "Iteration  1664\n",
      "Training: loss 4.532886981964111, covariance difference 0.9999098777770996\n",
      "Validation: loss 5.679447279421101, covariance difference 8.72092194831948, sinkhorn epsilon 0.0\n",
      "Iteration  1665\n",
      "Training: loss 4.639715671539307, covariance difference 1.018110752105713\n",
      "Validation: loss 5.730514879591377, covariance difference 8.774609740440333, sinkhorn epsilon 0.0\n",
      "Iteration  1666\n",
      "Training: loss 4.6907782554626465, covariance difference 1.0281628370285034\n",
      "Validation: loss 5.681230547043463, covariance difference 8.610243118945885, sinkhorn epsilon 0.0\n",
      "Iteration  1667\n",
      "Training: loss 4.641501426696777, covariance difference 1.0191174745559692\n",
      "Validation: loss 5.664821363173992, covariance difference 8.38289905579458, sinkhorn epsilon 0.0\n",
      "Iteration  1668\n",
      "Training: loss 4.625090599060059, covariance difference 1.0163896083831787\n",
      "Validation: loss 5.71589163281524, covariance difference 8.642122542968595, sinkhorn epsilon 0.0\n",
      "Iteration  1669\n",
      "Training: loss 4.676163673400879, covariance difference 1.0256284475326538\n",
      "Validation: loss 5.724910372066248, covariance difference 8.882752186793354, sinkhorn epsilon 0.0\n",
      "Iteration  1670\n",
      "Training: loss 4.685176849365234, covariance difference 1.0278666019439697\n",
      "Validation: loss 5.7531667231348065, covariance difference 8.59960671456949, sinkhorn epsilon 0.0\n",
      "Iteration  1671\n",
      "Training: loss 4.713434219360352, covariance difference 1.0303176641464233\n",
      "Validation: loss 5.668862830127367, covariance difference 8.642487340311177, sinkhorn epsilon 0.0\n",
      "Iteration  1672\n",
      "Training: loss 4.629127025604248, covariance difference 1.0161317586898804\n",
      "Validation: loss 5.750340987111603, covariance difference 8.733021675229525, sinkhorn epsilon 0.0\n",
      "Iteration  1673\n",
      "Training: loss 4.71060848236084, covariance difference 1.0313993692398071\n",
      "Validation: loss 5.626426611885168, covariance difference 8.66815148853924, sinkhorn epsilon 0.0\n",
      "Iteration  1674\n",
      "Training: loss 4.5866923332214355, covariance difference 1.0095458030700684\n",
      "Validation: loss 5.6646266812356725, covariance difference 8.458744899881852, sinkhorn epsilon 0.0\n",
      "Iteration  1675\n",
      "Training: loss 4.624899864196777, covariance difference 1.0176657438278198\n",
      "Validation: loss 5.611497044978904, covariance difference 8.511035657676828, sinkhorn epsilon 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  1676\n",
      "Training: loss 4.571765899658203, covariance difference 1.0060310363769531\n",
      "Validation: loss 5.722763016826834, covariance difference 8.950018219084209, sinkhorn epsilon 0.0\n",
      "Iteration  1677\n",
      "Training: loss 4.683032989501953, covariance difference 1.0249462127685547\n",
      "Validation: loss 5.692102265937722, covariance difference 8.636845101928477, sinkhorn epsilon 0.0\n",
      "Iteration  1678\n",
      "Training: loss 4.652368068695068, covariance difference 1.0223468542099\n",
      "Validation: loss 5.668162695241266, covariance difference 8.769165956176662, sinkhorn epsilon 0.0\n",
      "Iteration  1679\n",
      "Training: loss 4.628427505493164, covariance difference 1.016663670539856\n",
      "Validation: loss 5.629677837656743, covariance difference 8.471082600807906, sinkhorn epsilon 0.0\n",
      "Iteration  1680\n",
      "Training: loss 4.5899457931518555, covariance difference 1.0097748041152954\n",
      "Validation: loss 5.649569551556338, covariance difference 8.648457235243278, sinkhorn epsilon 0.0\n",
      "Iteration  1681\n",
      "Training: loss 4.609834671020508, covariance difference 1.0118049383163452\n",
      "Validation: loss 5.642600289196963, covariance difference 8.506988577370377, sinkhorn epsilon 0.0\n",
      "Iteration  1682\n",
      "Training: loss 4.602868556976318, covariance difference 1.0134981870651245\n",
      "Validation: loss 5.564638399280846, covariance difference 8.7361143715239, sinkhorn epsilon 5.871694622433694e-14\n",
      "Iteration  1683\n",
      "Training: loss 4.524909019470215, covariance difference 0.9990800023078918\n",
      "Validation: loss 5.655993932652352, covariance difference 8.61786960609931, sinkhorn epsilon 0.0\n",
      "Iteration  1684\n",
      "Training: loss 4.616264343261719, covariance difference 1.0133200883865356\n",
      "Validation: loss 5.639483098388428, covariance difference 8.386188418685084, sinkhorn epsilon 0.0\n",
      "Iteration  1685\n",
      "Training: loss 4.599748611450195, covariance difference 1.0129538774490356\n",
      "Validation: loss 5.59211078920225, covariance difference 8.681587455834224, sinkhorn epsilon 0.0\n",
      "Iteration  1686\n",
      "Training: loss 4.552379608154297, covariance difference 1.0047770738601685\n",
      "Validation: loss 5.628546516637443, covariance difference 8.381024384865917, sinkhorn epsilon 0.0\n",
      "Iteration  1687\n",
      "Training: loss 4.588811874389648, covariance difference 1.0094325542449951\n",
      "Validation: loss 5.678157301379587, covariance difference 8.748108471816401, sinkhorn epsilon 0.0\n",
      "Iteration  1688\n",
      "Training: loss 4.638424873352051, covariance difference 1.0185626745224\n",
      "Validation: loss 5.609597445886181, covariance difference 8.85036255524758, sinkhorn epsilon 0.0\n",
      "Iteration  1689\n",
      "Training: loss 4.5698676109313965, covariance difference 1.00604248046875\n",
      "Validation: loss 5.656058531811737, covariance difference 8.288239007153638, sinkhorn epsilon 0.0\n",
      "Iteration  1690\n",
      "Training: loss 4.616328716278076, covariance difference 1.0151174068450928\n",
      "Validation: loss 5.680364159752495, covariance difference 8.757185732655755, sinkhorn epsilon 0.0\n",
      "Iteration  1691\n",
      "Training: loss 4.6406331062316895, covariance difference 1.019155740737915\n",
      "Validation: loss 5.613413713385167, covariance difference 8.606509377068901, sinkhorn epsilon 4.5621609862560557e-14\n",
      "Iteration  1692\n",
      "Training: loss 4.57368278503418, covariance difference 1.0063021183013916\n",
      "Validation: loss 5.574318603755326, covariance difference 8.397013005371683, sinkhorn epsilon 0.0\n",
      "Iteration  1693\n",
      "Training: loss 4.53458833694458, covariance difference 0.9988661408424377\n",
      "Validation: loss 5.5832233259036155, covariance difference 8.620922187304377, sinkhorn epsilon 0.0\n",
      "Iteration  1694\n",
      "Training: loss 4.543487548828125, covariance difference 1.0011096000671387\n",
      "Validation: loss 5.661265598042418, covariance difference 8.857684601346804, sinkhorn epsilon 0.0\n",
      "Iteration  1695\n",
      "Training: loss 4.621533393859863, covariance difference 1.0157639980316162\n",
      "Validation: loss 5.70203332010777, covariance difference 8.583857978661465, sinkhorn epsilon 0.0\n",
      "Iteration  1696\n",
      "Training: loss 4.6623029708862305, covariance difference 1.0225870609283447\n",
      "Validation: loss 5.651961684245444, covariance difference 8.585100641125226, sinkhorn epsilon 0.0\n",
      "Iteration  1697\n",
      "Training: loss 4.612218856811523, covariance difference 1.0132278203964233\n",
      "Validation: loss 5.707741245157058, covariance difference 8.654004881604491, sinkhorn epsilon 0.0\n",
      "Iteration  1698\n",
      "Training: loss 4.668010234832764, covariance difference 1.023506760597229\n",
      "Validation: loss 5.659341323075989, covariance difference 8.4812784093622, sinkhorn epsilon 2.781877238157032e-14\n",
      "Iteration  1699\n",
      "Training: loss 4.6196088790893555, covariance difference 1.0147521495819092\n",
      "Validation: loss 5.645546118427456, covariance difference 8.523457055702835, sinkhorn epsilon 0.0\n",
      "Iteration  1700\n",
      "Training: loss 4.605814456939697, covariance difference 1.0128096342086792\n",
      "Validation: loss 5.705904910391579, covariance difference 8.510834075056033, sinkhorn epsilon 0.0\n",
      "Iteration  1701\n",
      "Training: loss 4.666172981262207, covariance difference 1.025259017944336\n",
      "Validation: loss 5.7104500703343914, covariance difference 8.831484947239527, sinkhorn epsilon 8.587242890114696e-14\n",
      "Iteration  1702\n",
      "Training: loss 4.670724391937256, covariance difference 1.024698257446289\n",
      "Validation: loss 5.708645416911753, covariance difference 8.966511341436659, sinkhorn epsilon 0.0\n",
      "Iteration  1703\n",
      "Training: loss 4.668910980224609, covariance difference 1.0253551006317139\n",
      "Validation: loss 5.5567040404640995, covariance difference 8.163654230127053, sinkhorn epsilon 0.0\n",
      "Iteration  1704\n",
      "Training: loss 4.516972541809082, covariance difference 0.9968289732933044\n",
      "Validation: loss 5.66555399026067, covariance difference 8.599052461653773, sinkhorn epsilon 0.0\n",
      "Iteration  1705\n",
      "Training: loss 4.625818252563477, covariance difference 1.0150302648544312\n",
      "Validation: loss 5.636027197125371, covariance difference 8.486953535906617, sinkhorn epsilon 0.0\n",
      "Iteration  1706\n",
      "Training: loss 4.596295356750488, covariance difference 1.0131168365478516\n",
      "Validation: loss 5.661995743815469, covariance difference 8.599866055432306, sinkhorn epsilon 0.0\n",
      "Iteration  1707\n",
      "Training: loss 4.622265815734863, covariance difference 1.0146005153656006\n",
      "Validation: loss 5.683776812724838, covariance difference 8.747238481406612, sinkhorn epsilon 0.0\n",
      "Iteration  1708\n",
      "Training: loss 4.644052505493164, covariance difference 1.0200889110565186\n",
      "Validation: loss 5.622491323329043, covariance difference 8.667548559868086, sinkhorn epsilon 0.0\n",
      "Iteration  1709\n",
      "Training: loss 4.582759380340576, covariance difference 1.008891224861145\n",
      "Validation: loss 5.7078840689842885, covariance difference 8.606816501878008, sinkhorn epsilon 0.0\n",
      "Iteration  1710\n",
      "Training: loss 4.66815185546875, covariance difference 1.0227043628692627\n",
      "Validation: loss 5.651116248837692, covariance difference 8.477704035949062, sinkhorn epsilon 0.0\n",
      "Iteration  1711\n",
      "Training: loss 4.6113810539245605, covariance difference 1.0144647359848022\n",
      "Validation: loss 5.598441891206096, covariance difference 8.398822708045996, sinkhorn epsilon 0.0\n",
      "Iteration  1712\n",
      "Training: loss 4.558707237243652, covariance difference 1.004920482635498\n",
      "Validation: loss 5.690893634785779, covariance difference 8.83199750820884, sinkhorn epsilon 0.0\n",
      "Iteration  1713\n",
      "Training: loss 4.6511735916137695, covariance difference 1.0216379165649414\n",
      "Validation: loss 5.726052581280113, covariance difference 8.788789523713927, sinkhorn epsilon 0.0\n",
      "Iteration  1714\n",
      "Training: loss 4.686321258544922, covariance difference 1.027291178703308\n",
      "Validation: loss 5.602912669371275, covariance difference 8.43487775468289, sinkhorn epsilon 0.0\n",
      "Iteration  1715\n",
      "Training: loss 4.563180923461914, covariance difference 1.0062354803085327\n",
      "Validation: loss 5.645890908050273, covariance difference 8.613467534088352, sinkhorn epsilon 0.0\n",
      "Iteration  1716\n",
      "Training: loss 4.606159210205078, covariance difference 1.0136665105819702\n",
      "Validation: loss 5.705125717201701, covariance difference 8.631192202585801, sinkhorn epsilon 0.0\n",
      "Iteration  1717\n",
      "Training: loss 4.665393829345703, covariance difference 1.0228554010391235\n",
      "Validation: loss 5.596149420061672, covariance difference 8.574000250994336, sinkhorn epsilon 0.0\n",
      "Iteration  1718\n",
      "Training: loss 4.556417942047119, covariance difference 1.0027800798416138\n",
      "Validation: loss 5.656588297350874, covariance difference 8.491962563367554, sinkhorn epsilon 0.0\n",
      "Iteration  1719\n",
      "Training: loss 4.616863250732422, covariance difference 1.0162389278411865\n",
      "Validation: loss 5.641218793860258, covariance difference 8.714052772234792, sinkhorn epsilon 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  1720\n",
      "Training: loss 4.60148811340332, covariance difference 1.0129574537277222\n",
      "Validation: loss 5.61729499565605, covariance difference 8.606074572895928, sinkhorn epsilon 0.0\n",
      "Iteration  1721\n",
      "Training: loss 4.577563285827637, covariance difference 1.0070041418075562\n",
      "Validation: loss 5.639539090853134, covariance difference 8.639660829295552, sinkhorn epsilon 0.0\n",
      "Iteration  1722\n",
      "Training: loss 4.5998077392578125, covariance difference 1.0120307207107544\n",
      "Validation: loss 5.607632193747067, covariance difference 8.538947080317644, sinkhorn epsilon 0.0\n",
      "Iteration  1723\n",
      "Training: loss 4.567904472351074, covariance difference 1.007652759552002\n",
      "Validation: loss 5.563813554833359, covariance difference 8.307953961561642, sinkhorn epsilon 0.0\n",
      "Iteration  1724\n",
      "Training: loss 4.524082183837891, covariance difference 0.9983347058296204\n",
      "Validation: loss 5.696609317863687, covariance difference 8.60099013398872, sinkhorn epsilon 0.0\n",
      "Iteration  1725\n",
      "Training: loss 4.656878471374512, covariance difference 1.0211879014968872\n",
      "Validation: loss 5.7175131482484804, covariance difference 8.841806711826411, sinkhorn epsilon 0.0\n",
      "Iteration  1726\n",
      "Training: loss 4.67778205871582, covariance difference 1.025376319885254\n",
      "Validation: loss 5.646605682110428, covariance difference 8.710839866274823, sinkhorn epsilon 0.0\n",
      "Iteration  1727\n",
      "Training: loss 4.606873512268066, covariance difference 1.011807918548584\n",
      "Validation: loss 5.657054016027942, covariance difference 8.476014331548878, sinkhorn epsilon 0.0\n",
      "Iteration  1728\n",
      "Training: loss 4.617321968078613, covariance difference 1.0146479606628418\n",
      "Validation: loss 5.6976966012305805, covariance difference 8.702706351693005, sinkhorn epsilon 0.0\n",
      "Iteration  1729\n",
      "Training: loss 4.657965660095215, covariance difference 1.023059606552124\n",
      "Validation: loss 5.620548354378529, covariance difference 8.827365833401702, sinkhorn epsilon 0.0\n",
      "Iteration  1730\n",
      "Training: loss 4.580816745758057, covariance difference 1.008831262588501\n",
      "Validation: loss 5.582054178331897, covariance difference 8.555429207905712, sinkhorn epsilon 0.0\n",
      "Iteration  1731\n",
      "Training: loss 4.542323589324951, covariance difference 1.0017062425613403\n",
      "Validation: loss 5.6457956635715085, covariance difference 8.545720886686862, sinkhorn epsilon 0.0\n",
      "Iteration  1732\n",
      "Training: loss 4.606064319610596, covariance difference 1.012465000152588\n",
      "Validation: loss 5.653299375377676, covariance difference 8.54303803289326, sinkhorn epsilon 0.0\n",
      "Iteration  1733\n",
      "Training: loss 4.613552093505859, covariance difference 1.0146538019180298\n",
      "Validation: loss 5.629829860421899, covariance difference 8.476579112751194, sinkhorn epsilon 0.0\n",
      "Iteration  1734\n",
      "Training: loss 4.5900983810424805, covariance difference 1.0095027685165405\n",
      "Validation: loss 5.646807951645435, covariance difference 8.477405185751588, sinkhorn epsilon 6.055208261217307e-14\n",
      "Iteration  1735\n",
      "Training: loss 4.6070756912231445, covariance difference 1.0130020380020142\n",
      "Validation: loss 5.6378299220761035, covariance difference 8.540654100095265, sinkhorn epsilon 0.0\n",
      "Iteration  1736\n",
      "Training: loss 4.598099708557129, covariance difference 1.0117168426513672\n",
      "Validation: loss 5.675115663407179, covariance difference 8.528565451528536, sinkhorn epsilon 0.0\n",
      "Iteration  1737\n",
      "Training: loss 4.635386943817139, covariance difference 1.0194584131240845\n",
      "Validation: loss 5.631713019010269, covariance difference 8.500422719449976, sinkhorn epsilon 0.0\n",
      "Iteration  1738\n",
      "Training: loss 4.591981887817383, covariance difference 1.0097838640213013\n",
      "Validation: loss 5.618686016481877, covariance difference 8.50626041207675, sinkhorn epsilon 0.0\n",
      "Iteration  1739\n",
      "Training: loss 4.578949928283691, covariance difference 1.0070843696594238\n",
      "Validation: loss 5.673218480678554, covariance difference 8.437908417900863, sinkhorn epsilon 0.0\n",
      "Iteration  1740\n",
      "Training: loss 4.633487701416016, covariance difference 1.0185660123825073\n",
      "Validation: loss 5.652902362688964, covariance difference 8.773656364000123, sinkhorn epsilon 0.0\n",
      "Iteration  1741\n",
      "Training: loss 4.613171577453613, covariance difference 1.0139083862304688\n",
      "Validation: loss 5.5640444660984, covariance difference 8.518075120811197, sinkhorn epsilon 0.0\n",
      "Iteration  1742\n",
      "Training: loss 4.524319648742676, covariance difference 0.9994314908981323\n",
      "Validation: loss 5.685587382411786, covariance difference 8.560248139756405, sinkhorn epsilon 0.0\n",
      "Iteration  1743\n",
      "Training: loss 4.645854473114014, covariance difference 1.0204585790634155\n",
      "Validation: loss 5.6376377799568065, covariance difference 8.737465937082163, sinkhorn epsilon 0.0\n",
      "Iteration  1744\n",
      "Training: loss 4.597908020019531, covariance difference 1.0109379291534424\n",
      "Validation: loss 5.699699484351882, covariance difference 8.84226904133496, sinkhorn epsilon 0.0\n",
      "Iteration  1745\n",
      "Training: loss 4.65996789932251, covariance difference 1.0242388248443604\n",
      "Validation: loss 5.70389476387931, covariance difference 8.84024471033161, sinkhorn epsilon 0.0\n",
      "Iteration  1746\n",
      "Training: loss 4.6641645431518555, covariance difference 1.024746298789978\n",
      "Validation: loss 5.5994411315684935, covariance difference 8.389734489353462, sinkhorn epsilon 0.0\n",
      "Iteration  1747\n",
      "Training: loss 4.559709548950195, covariance difference 1.0040816068649292\n",
      "Validation: loss 5.678815764618701, covariance difference 8.632141346657326, sinkhorn epsilon 0.0\n",
      "Iteration  1748\n",
      "Training: loss 4.6390838623046875, covariance difference 1.0178170204162598\n",
      "Validation: loss 5.688025900827008, covariance difference 8.485438730372715, sinkhorn epsilon 0.0\n",
      "Iteration  1749\n",
      "Training: loss 4.648291110992432, covariance difference 1.0201458930969238\n",
      "Validation: loss 5.6769435075982155, covariance difference 8.70927003308367, sinkhorn epsilon 0.0\n",
      "Iteration  1750\n",
      "Training: loss 4.637213230133057, covariance difference 1.0181546211242676\n",
      "Validation: loss 5.729152008624431, covariance difference 8.69095145002738, sinkhorn epsilon 0.0\n",
      "Iteration  1751\n",
      "Training: loss 4.689422607421875, covariance difference 1.0288176536560059\n",
      "Validation: loss 5.677744889970763, covariance difference 8.536883780360544, sinkhorn epsilon 0.0\n",
      "Iteration  1752\n",
      "Training: loss 4.638011932373047, covariance difference 1.0203181505203247\n",
      "Validation: loss 5.6841831026341465, covariance difference 8.656961402194943, sinkhorn epsilon 0.0\n",
      "Iteration  1753\n",
      "Training: loss 4.644453048706055, covariance difference 1.0176219940185547\n",
      "Validation: loss 5.66983840078812, covariance difference 8.550056032409788, sinkhorn epsilon 3.17750944736297e-14\n",
      "Iteration  1754\n",
      "Training: loss 4.630105972290039, covariance difference 1.0189909934997559\n",
      "Validation: loss 5.676178276458881, covariance difference 8.582575964061961, sinkhorn epsilon 0.0\n",
      "Iteration  1755\n",
      "Training: loss 4.636451721191406, covariance difference 1.0191538333892822\n",
      "Validation: loss 5.672272329641038, covariance difference 8.56941908417879, sinkhorn epsilon 0.0\n",
      "Iteration  1756\n",
      "Training: loss 4.632543563842773, covariance difference 1.0179418325424194\n",
      "Validation: loss 5.692618432874772, covariance difference 8.655614562777387, sinkhorn epsilon 0.0\n",
      "Iteration  1757\n",
      "Training: loss 4.652888298034668, covariance difference 1.0220617055892944\n",
      "Validation: loss 5.647004314025342, covariance difference 8.655412856135463, sinkhorn epsilon 0.0\n",
      "Iteration  1758\n",
      "Training: loss 4.607274055480957, covariance difference 1.012534737586975\n",
      "Validation: loss 5.6244517330903925, covariance difference 8.55545666422332, sinkhorn epsilon 0.0\n",
      "Iteration  1759\n",
      "Training: loss 4.584719657897949, covariance difference 1.0089445114135742\n",
      "Validation: loss 5.748092194639135, covariance difference 8.796791171569197, sinkhorn epsilon 3.0400553149963376e-14\n",
      "Iteration  1760\n",
      "Training: loss 4.70836067199707, covariance difference 1.0299631357192993\n",
      "Validation: loss 5.693724542462216, covariance difference 8.684318458105881, sinkhorn epsilon 0.0\n",
      "Iteration  1761\n",
      "Training: loss 4.653992652893066, covariance difference 1.0214027166366577\n",
      "Validation: loss 5.623946709397982, covariance difference 8.859747148233721, sinkhorn epsilon 0.0\n",
      "Iteration  1762\n",
      "Training: loss 4.584217071533203, covariance difference 1.009524941444397\n",
      "Validation: loss 5.607665949771963, covariance difference 8.529977208310584, sinkhorn epsilon 0.0\n",
      "Iteration  1763\n",
      "Training: loss 4.567930698394775, covariance difference 1.0070205926895142\n",
      "Validation: loss 5.634682238144681, covariance difference 8.492166256796379, sinkhorn epsilon 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  1764\n",
      "Training: loss 4.594948768615723, covariance difference 1.0117985010147095\n",
      "Validation: loss 5.6460253894074635, covariance difference 8.567335486140749, sinkhorn epsilon 0.0\n",
      "Iteration  1765\n",
      "Training: loss 4.60629415512085, covariance difference 1.0123635530471802\n",
      "Validation: loss 5.674335989161579, covariance difference 8.701626934029097, sinkhorn epsilon 0.0\n",
      "Iteration  1766\n",
      "Training: loss 4.634604454040527, covariance difference 1.0168455839157104\n",
      "Validation: loss 5.570988689168118, covariance difference 8.442675121226126, sinkhorn epsilon 0.0\n",
      "Iteration  1767\n",
      "Training: loss 4.531252861022949, covariance difference 0.9997765421867371\n",
      "Validation: loss 5.6892417830363895, covariance difference 8.611128278666586, sinkhorn epsilon 0.0\n",
      "Iteration  1768\n",
      "Training: loss 4.649507522583008, covariance difference 1.020443320274353\n",
      "Validation: loss 5.666648035189178, covariance difference 8.82243306406138, sinkhorn epsilon 0.0\n",
      "Iteration  1769\n",
      "Training: loss 4.626920700073242, covariance difference 1.0173219442367554\n",
      "Validation: loss 5.720444824176024, covariance difference 8.731443789034522, sinkhorn epsilon 0.0\n",
      "Iteration  1770\n",
      "Training: loss 4.680723190307617, covariance difference 1.0274616479873657\n",
      "Validation: loss 5.642532429381097, covariance difference 8.576327037865855, sinkhorn epsilon 0.0\n",
      "Iteration  1771\n",
      "Training: loss 4.602808952331543, covariance difference 1.0128140449523926\n",
      "Validation: loss 5.637987719013426, covariance difference 8.646838612587565, sinkhorn epsilon 0.0\n",
      "Iteration  1772\n",
      "Training: loss 4.598251819610596, covariance difference 1.0127339363098145\n",
      "Validation: loss 5.714993033760273, covariance difference 8.611353426294144, sinkhorn epsilon 0.0\n",
      "Iteration  1773\n",
      "Training: loss 4.675268650054932, covariance difference 1.0253185033798218\n",
      "Validation: loss 5.670109306010433, covariance difference 8.520116066713893, sinkhorn epsilon 0.0\n",
      "Iteration  1774\n",
      "Training: loss 4.630378723144531, covariance difference 1.0177518129348755\n",
      "Validation: loss 5.6309849686057545, covariance difference 8.526126540544025, sinkhorn epsilon 1.5624789057730744e-14\n",
      "Iteration  1775\n",
      "Training: loss 4.591253757476807, covariance difference 1.0094730854034424\n",
      "Validation: loss 5.608309688819714, covariance difference 8.675809553114606, sinkhorn epsilon 0.0\n",
      "Iteration  1776\n",
      "Training: loss 4.568577766418457, covariance difference 1.0065269470214844\n",
      "Validation: loss 5.652736667308513, covariance difference 8.694777119350283, sinkhorn epsilon 0.0\n",
      "Iteration  1777\n",
      "Training: loss 4.613001823425293, covariance difference 1.0152342319488525\n",
      "Validation: loss 5.635132094728402, covariance difference 8.517916481604649, sinkhorn epsilon 0.0\n",
      "Iteration  1778\n",
      "Training: loss 4.595401287078857, covariance difference 1.010910153388977\n",
      "Validation: loss 5.627932952388877, covariance difference 8.602130178200191, sinkhorn epsilon 0.0\n",
      "Iteration  1779\n",
      "Training: loss 4.588200569152832, covariance difference 1.0092235803604126\n",
      "Validation: loss 5.58930119061381, covariance difference 8.454750700172767, sinkhorn epsilon 0.0\n",
      "Iteration  1780\n",
      "Training: loss 4.549570083618164, covariance difference 1.0028197765350342\n",
      "Validation: loss 5.657585870230957, covariance difference 8.667719740202593, sinkhorn epsilon 2.886864682524202e-14\n",
      "Iteration  1781\n",
      "Training: loss 4.617855072021484, covariance difference 1.015304446220398\n",
      "Validation: loss 5.682285331519406, covariance difference 8.769103842447924, sinkhorn epsilon 0.0\n",
      "Iteration  1782\n",
      "Training: loss 4.642546653747559, covariance difference 1.0209803581237793\n",
      "Validation: loss 5.675634999476124, covariance difference 8.879718114454281, sinkhorn epsilon 0.0\n",
      "Iteration  1783\n",
      "Training: loss 4.635903358459473, covariance difference 1.018393635749817\n",
      "Validation: loss 5.686462506370559, covariance difference 8.751394811062909, sinkhorn epsilon 0.0\n",
      "Iteration  1784\n",
      "Training: loss 4.646730899810791, covariance difference 1.0204541683197021\n",
      "Validation: loss 5.7187542687629485, covariance difference 8.792688651626799, sinkhorn epsilon 0.0\n",
      "Iteration  1785\n",
      "Training: loss 4.679022312164307, covariance difference 1.0256975889205933\n",
      "Validation: loss 5.608924182493415, covariance difference 8.446123643509596, sinkhorn epsilon 0.0\n",
      "Iteration  1786\n",
      "Training: loss 4.569189071655273, covariance difference 1.0075032711029053\n",
      "Validation: loss 5.6507496303749765, covariance difference 8.61187461792066, sinkhorn epsilon 0.0\n",
      "Iteration  1787\n",
      "Training: loss 4.611017227172852, covariance difference 1.0142500400543213\n",
      "Validation: loss 5.619139917299788, covariance difference 8.684678249214471, sinkhorn epsilon 0.0\n",
      "Iteration  1788\n",
      "Training: loss 4.579402923583984, covariance difference 1.0087890625\n",
      "Validation: loss 5.635744737930883, covariance difference 8.522736063024327, sinkhorn epsilon 0.0\n",
      "Iteration  1789\n",
      "Training: loss 4.5960164070129395, covariance difference 1.0102616548538208\n",
      "Validation: loss 5.637392815173447, covariance difference 8.611304728143054, sinkhorn epsilon 1.8030352045894766e-14\n",
      "Iteration  1790\n",
      "Training: loss 4.597661018371582, covariance difference 1.0110477209091187\n",
      "Validation: loss 5.592443998618604, covariance difference 8.474132244372951, sinkhorn epsilon 0.0\n",
      "Iteration  1791\n",
      "Training: loss 4.5527119636535645, covariance difference 1.0024677515029907\n",
      "Validation: loss 5.725851157371574, covariance difference 8.701811376011879, sinkhorn epsilon 0.0\n",
      "Iteration  1792\n",
      "Training: loss 4.68612003326416, covariance difference 1.0274384021759033\n",
      "Validation: loss 5.604595008916436, covariance difference 8.52524292732099, sinkhorn epsilon 0.0\n",
      "Iteration  1793\n",
      "Training: loss 4.564859390258789, covariance difference 1.0043048858642578\n",
      "Validation: loss 5.718188293571088, covariance difference 8.80572551127292, sinkhorn epsilon 0.0\n",
      "Iteration  1794\n",
      "Training: loss 4.678455829620361, covariance difference 1.02532160282135\n",
      "Validation: loss 5.661765768263599, covariance difference 8.703352679103878, sinkhorn epsilon 0.0\n",
      "Iteration  1795\n",
      "Training: loss 4.622019290924072, covariance difference 1.016026258468628\n",
      "Validation: loss 5.6827930328436596, covariance difference 8.584285457688404, sinkhorn epsilon 0.0\n",
      "Iteration  1796\n",
      "Training: loss 4.64306116104126, covariance difference 1.0189075469970703\n",
      "Validation: loss 5.6083984443006205, covariance difference 8.690128759854984, sinkhorn epsilon 0.0\n",
      "Iteration  1797\n",
      "Training: loss 4.568666458129883, covariance difference 1.0061860084533691\n",
      "Validation: loss 5.738420061108451, covariance difference 8.71886252817238, sinkhorn epsilon 3.786794347142938e-14\n",
      "Iteration  1798\n",
      "Training: loss 4.698687553405762, covariance difference 1.029721736907959\n",
      "Validation: loss 5.639266138031125, covariance difference 8.760227699069128, sinkhorn epsilon 0.0\n",
      "Iteration  1799\n",
      "Training: loss 4.599534034729004, covariance difference 1.011767029762268\n",
      "Validation: loss 5.709096454717738, covariance difference 8.67716403461524, sinkhorn epsilon 0.0\n",
      "Iteration  1800\n",
      "Training: loss 4.669366836547852, covariance difference 1.0235460996627808\n",
      "Validation: loss 5.709590058014707, covariance difference 8.929498961279565, sinkhorn epsilon 0.0\n",
      "Iteration  1801\n",
      "Training: loss 4.669855117797852, covariance difference 1.0236619710922241\n",
      "Validation: loss 5.609990829157071, covariance difference 8.607399794203095, sinkhorn epsilon 0.0\n",
      "Iteration  1802\n",
      "Training: loss 4.570265293121338, covariance difference 1.0071696043014526\n",
      "Validation: loss 5.631604094610383, covariance difference 8.678996800702242, sinkhorn epsilon 0.0\n",
      "Iteration  1803\n",
      "Training: loss 4.591869354248047, covariance difference 1.0117450952529907\n",
      "Validation: loss 5.60705468743638, covariance difference 8.402462176131229, sinkhorn epsilon 0.0\n",
      "Iteration  1804\n",
      "Training: loss 4.567325592041016, covariance difference 1.005860686302185\n",
      "Validation: loss 5.669279916040455, covariance difference 8.671071408285165, sinkhorn epsilon 0.0\n",
      "Iteration  1805\n",
      "Training: loss 4.629543781280518, covariance difference 1.0174795389175415\n",
      "Validation: loss 5.680235722336398, covariance difference 8.976631863641463, sinkhorn epsilon 0.0\n",
      "Iteration  1806\n",
      "Training: loss 4.640511512756348, covariance difference 1.021540641784668\n",
      "Validation: loss 5.673511826762686, covariance difference 8.5136757945193, sinkhorn epsilon 0.0\n",
      "Iteration  1807\n",
      "Training: loss 4.633774280548096, covariance difference 1.0160417556762695\n",
      "Validation: loss 5.612447016374212, covariance difference 8.571220112221908, sinkhorn epsilon 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  1808\n",
      "Training: loss 4.572711944580078, covariance difference 1.0072264671325684\n",
      "Validation: loss 5.619354683277326, covariance difference 8.616687563964229, sinkhorn epsilon 0.0\n",
      "Iteration  1809\n",
      "Training: loss 4.5796284675598145, covariance difference 1.00687837600708\n",
      "Validation: loss 5.674963460272737, covariance difference 8.748803384052595, sinkhorn epsilon 0.0\n",
      "Iteration  1810\n",
      "Training: loss 4.635227680206299, covariance difference 1.0192466974258423\n",
      "Validation: loss 5.6952613282414815, covariance difference 8.629284713258526, sinkhorn epsilon 0.0\n",
      "Iteration  1811\n",
      "Training: loss 4.655529022216797, covariance difference 1.0200239419937134\n",
      "Validation: loss 5.662501479920897, covariance difference 8.515487453315016, sinkhorn epsilon 0.0\n",
      "Iteration  1812\n",
      "Training: loss 4.622769355773926, covariance difference 1.0169646739959717\n",
      "Validation: loss 5.648294947431637, covariance difference 8.58485631299722, sinkhorn epsilon 0.0\n",
      "Iteration  1813\n",
      "Training: loss 4.6085591316223145, covariance difference 1.0118632316589355\n",
      "Validation: loss 5.686630546286937, covariance difference 8.551858643476196, sinkhorn epsilon 0.0\n",
      "Iteration  1814\n",
      "Training: loss 4.646894931793213, covariance difference 1.020362377166748\n",
      "Validation: loss 5.656932251994531, covariance difference 8.43551074278793, sinkhorn epsilon 0.0\n",
      "Iteration  1815\n",
      "Training: loss 4.617203712463379, covariance difference 1.0147461891174316\n",
      "Validation: loss 5.616552280020731, covariance difference 8.67388864099403, sinkhorn epsilon 0.0\n",
      "Iteration  1816\n",
      "Training: loss 4.576820373535156, covariance difference 1.0100677013397217\n",
      "Validation: loss 5.599112178762912, covariance difference 8.663787357976968, sinkhorn epsilon 0.0\n",
      "Iteration  1817\n",
      "Training: loss 4.559381484985352, covariance difference 1.0049744844436646\n",
      "Validation: loss 5.6684287392033905, covariance difference 8.450974503484503, sinkhorn epsilon 0.0\n",
      "Iteration  1818\n",
      "Training: loss 4.628687381744385, covariance difference 1.0181490182876587\n",
      "Validation: loss 5.623405239119134, covariance difference 8.80889502513941, sinkhorn epsilon 0.0\n",
      "Iteration  1819\n",
      "Training: loss 4.583672523498535, covariance difference 1.0074914693832397\n",
      "Validation: loss 5.6677766158679095, covariance difference 8.526143069682426, sinkhorn epsilon 0.0\n",
      "Iteration  1820\n",
      "Training: loss 4.628044128417969, covariance difference 1.016679048538208\n",
      "Validation: loss 5.5751425491436155, covariance difference 8.584300037868548, sinkhorn epsilon 0.0\n",
      "Iteration  1821\n",
      "Training: loss 4.535400390625, covariance difference 0.9997258186340332\n",
      "Validation: loss 5.688582318798836, covariance difference 8.696520536926, sinkhorn epsilon 0.0\n",
      "Iteration  1822\n",
      "Training: loss 4.64885139465332, covariance difference 1.022178053855896\n",
      "Validation: loss 5.665539629385087, covariance difference 8.779706133046057, sinkhorn epsilon 0.0\n",
      "Iteration  1823\n",
      "Training: loss 4.625794410705566, covariance difference 1.0164414644241333\n",
      "Validation: loss 5.554560862166596, covariance difference 8.508984262122485, sinkhorn epsilon 0.0\n",
      "Iteration  1824\n",
      "Training: loss 4.514829158782959, covariance difference 0.9960886836051941\n",
      "Validation: loss 5.664036520578846, covariance difference 8.424072368311196, sinkhorn epsilon 0.0\n",
      "Iteration  1825\n",
      "Training: loss 4.6243062019348145, covariance difference 1.0163317918777466\n",
      "Validation: loss 5.627446775797701, covariance difference 8.776096525395893, sinkhorn epsilon 0.0\n",
      "Iteration  1826\n",
      "Training: loss 4.587710857391357, covariance difference 1.0092154741287231\n",
      "Validation: loss 5.600165074086304, covariance difference 8.205424776962783, sinkhorn epsilon 0.0\n",
      "Iteration  1827\n",
      "Training: loss 4.560434341430664, covariance difference 1.0029881000518799\n",
      "Validation: loss 5.609697453744625, covariance difference 8.351532014409761, sinkhorn epsilon 0.0\n",
      "Iteration  1828\n",
      "Training: loss 4.569967746734619, covariance difference 1.0043381452560425\n",
      "Validation: loss 5.7044831191364995, covariance difference 8.660433562867508, sinkhorn epsilon 0.0\n",
      "Iteration  1829\n",
      "Training: loss 4.6647515296936035, covariance difference 1.0226399898529053\n",
      "Validation: loss 5.749571376778789, covariance difference 8.6931462860613, sinkhorn epsilon 0.0\n",
      "Iteration  1830\n",
      "Training: loss 4.709839820861816, covariance difference 1.0313314199447632\n",
      "Validation: loss 5.60847659001093, covariance difference 8.625094695870153, sinkhorn epsilon 0.0\n",
      "Iteration  1831\n",
      "Training: loss 4.568743705749512, covariance difference 1.0064353942871094\n",
      "Validation: loss 5.631300728080631, covariance difference 8.505325890149445, sinkhorn epsilon 0.0\n",
      "Iteration  1832\n",
      "Training: loss 4.5915703773498535, covariance difference 1.0089890956878662\n",
      "Validation: loss 5.636938996521722, covariance difference 8.645785214755742, sinkhorn epsilon 0.0\n",
      "Iteration  1833\n",
      "Training: loss 4.597207069396973, covariance difference 1.0124324560165405\n",
      "Validation: loss 5.758191226258536, covariance difference 8.772220604473874, sinkhorn epsilon 0.0\n",
      "Iteration  1834\n",
      "Training: loss 4.718459129333496, covariance difference 1.035693883895874\n",
      "Validation: loss 5.628432251914301, covariance difference 8.352571140239776, sinkhorn epsilon 0.0\n",
      "Iteration  1835\n",
      "Training: loss 4.588700771331787, covariance difference 1.0106008052825928\n",
      "Validation: loss 5.653067794059676, covariance difference 8.532492734725604, sinkhorn epsilon 0.0\n",
      "Iteration  1836\n",
      "Training: loss 4.613331317901611, covariance difference 1.0147714614868164\n",
      "Validation: loss 5.685653746052843, covariance difference 8.830929485973165, sinkhorn epsilon 0.0\n",
      "Iteration  1837\n",
      "Training: loss 4.645922660827637, covariance difference 1.0201387405395508\n",
      "Validation: loss 5.662422184366365, covariance difference 8.739632720398221, sinkhorn epsilon 2.300835077512411e-14\n",
      "Iteration  1838\n",
      "Training: loss 4.622690200805664, covariance difference 1.0182260274887085\n",
      "Validation: loss 5.608035790745472, covariance difference 8.494658516687842, sinkhorn epsilon 0.0\n",
      "Iteration  1839\n",
      "Training: loss 4.568306922912598, covariance difference 1.005352258682251\n",
      "Validation: loss 5.603453236087589, covariance difference 8.542593109419299, sinkhorn epsilon 0.0\n",
      "Iteration  1840\n",
      "Training: loss 4.563717842102051, covariance difference 1.003886103630066\n",
      "Validation: loss 5.683458059922138, covariance difference 8.66130043227553, sinkhorn epsilon 0.0\n",
      "Iteration  1841\n",
      "Training: loss 4.643730640411377, covariance difference 1.0186526775360107\n",
      "Validation: loss 5.620075515059898, covariance difference 8.443974086117283, sinkhorn epsilon 0.0\n",
      "Iteration  1842\n",
      "Training: loss 4.580328941345215, covariance difference 1.0083717107772827\n",
      "Validation: loss 5.7068894814076465, covariance difference 8.87960417491832, sinkhorn epsilon 0.0\n",
      "Iteration  1843\n",
      "Training: loss 4.667162895202637, covariance difference 1.0232034921646118\n",
      "Validation: loss 5.598244709602294, covariance difference 8.572571705354832, sinkhorn epsilon 0.0\n",
      "Iteration  1844\n",
      "Training: loss 4.55850887298584, covariance difference 1.003466248512268\n",
      "Validation: loss 5.658663942020604, covariance difference 8.547639568527735, sinkhorn epsilon 0.0\n",
      "Iteration  1845\n",
      "Training: loss 4.61893367767334, covariance difference 1.015663743019104\n",
      "Validation: loss 5.622918379056765, covariance difference 8.561994302652217, sinkhorn epsilon 0.0\n",
      "Iteration  1846\n",
      "Training: loss 4.583188056945801, covariance difference 1.0085071325302124\n",
      "Validation: loss 5.683969249603262, covariance difference 8.696649578488907, sinkhorn epsilon 0.0\n",
      "Iteration  1847\n",
      "Training: loss 4.6442461013793945, covariance difference 1.0184403657913208\n",
      "Validation: loss 5.656227085868988, covariance difference 8.732262551666047, sinkhorn epsilon 0.0\n",
      "Iteration  1848\n",
      "Training: loss 4.6164960861206055, covariance difference 1.0148403644561768\n",
      "Validation: loss 5.678830908229072, covariance difference 8.628011534831419, sinkhorn epsilon 0.0\n",
      "Iteration  1849\n",
      "Training: loss 4.63909912109375, covariance difference 1.019235610961914\n",
      "Validation: loss 5.607157439732232, covariance difference 8.730562501859522, sinkhorn epsilon 0.0\n",
      "Iteration  1850\n",
      "Training: loss 4.5674262046813965, covariance difference 1.006519079208374\n",
      "Validation: loss 5.609093351836314, covariance difference 8.619228329058544, sinkhorn epsilon 0.0\n",
      "Iteration  1851\n",
      "Training: loss 4.569363594055176, covariance difference 1.0067235231399536\n",
      "Validation: loss 5.605424677240097, covariance difference 8.513080845334313, sinkhorn epsilon 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  1852\n",
      "Training: loss 4.565694332122803, covariance difference 1.0061732530593872\n",
      "Validation: loss 5.66709801479337, covariance difference 8.524941214399666, sinkhorn epsilon 0.0\n",
      "Iteration  1853\n",
      "Training: loss 4.62736701965332, covariance difference 1.0156879425048828\n",
      "Validation: loss 5.693739671443208, covariance difference 8.534766604696092, sinkhorn epsilon 0.0\n",
      "Iteration  1854\n",
      "Training: loss 4.654007911682129, covariance difference 1.0198231935501099\n",
      "Validation: loss 5.6567438679114765, covariance difference 8.722118609887854, sinkhorn epsilon 0.0\n",
      "Iteration  1855\n",
      "Training: loss 4.617013454437256, covariance difference 1.0147794485092163\n",
      "Validation: loss 5.6048852992206255, covariance difference 8.527091094698573, sinkhorn epsilon 0.0\n",
      "Iteration  1856\n",
      "Training: loss 4.565154075622559, covariance difference 1.0053527355194092\n",
      "Validation: loss 5.691414721218095, covariance difference 8.661349473000861, sinkhorn epsilon 0.0\n",
      "Iteration  1857\n",
      "Training: loss 4.651679039001465, covariance difference 1.0205578804016113\n",
      "Validation: loss 5.710342027139611, covariance difference 8.704506976605787, sinkhorn epsilon 4.889430919994673e-15\n",
      "Iteration  1858\n",
      "Training: loss 4.670609951019287, covariance difference 1.025283694267273\n",
      "Validation: loss 5.665835567970632, covariance difference 8.948717191476481, sinkhorn epsilon 0.0\n",
      "Iteration  1859\n",
      "Training: loss 4.626101016998291, covariance difference 1.0176481008529663\n",
      "Validation: loss 5.703886588645293, covariance difference 8.509336589574623, sinkhorn epsilon 0.0\n",
      "Iteration  1860\n",
      "Training: loss 4.66415548324585, covariance difference 1.0237013101577759\n",
      "Validation: loss 5.674434639235107, covariance difference 8.601551678887045, sinkhorn epsilon 0.0\n",
      "Iteration  1861\n",
      "Training: loss 4.634705066680908, covariance difference 1.0192312002182007\n",
      "Validation: loss 5.680147548464377, covariance difference 8.74236904736841, sinkhorn epsilon 0.0\n",
      "Iteration  1862\n",
      "Training: loss 4.640415668487549, covariance difference 1.0175623893737793\n",
      "Validation: loss 5.675303125964451, covariance difference 8.65452115686328, sinkhorn epsilon 0.0\n",
      "Iteration  1863\n",
      "Training: loss 4.6355671882629395, covariance difference 1.0183476209640503\n",
      "Validation: loss 5.61145217753739, covariance difference 8.615405012141572, sinkhorn epsilon 0.0\n",
      "Iteration  1864\n",
      "Training: loss 4.571721076965332, covariance difference 1.0068528652191162\n",
      "Validation: loss 5.643159443190008, covariance difference 8.73751961777867, sinkhorn epsilon 0.0\n",
      "Iteration  1865\n",
      "Training: loss 4.603424072265625, covariance difference 1.012971043586731\n",
      "Validation: loss 5.689112520376662, covariance difference 8.813761364364185, sinkhorn epsilon 0.0\n",
      "Iteration  1866\n",
      "Training: loss 4.649381637573242, covariance difference 1.0204724073410034\n",
      "Validation: loss 5.685933400425187, covariance difference 8.616546952644919, sinkhorn epsilon 0.0\n",
      "Iteration  1867\n",
      "Training: loss 4.646197319030762, covariance difference 1.0181753635406494\n",
      "Validation: loss 5.610842037808389, covariance difference 8.34265357629833, sinkhorn epsilon 0.0\n",
      "Iteration  1868\n",
      "Training: loss 4.571110725402832, covariance difference 1.0047657489776611\n",
      "Validation: loss 5.670714645969515, covariance difference 8.70105829240575, sinkhorn epsilon 0.0\n",
      "Iteration  1869\n",
      "Training: loss 4.630979061126709, covariance difference 1.0169787406921387\n",
      "Validation: loss 5.706120984318323, covariance difference 8.678672986843946, sinkhorn epsilon 0.0\n",
      "Iteration  1870\n",
      "Training: loss 4.666390419006348, covariance difference 1.025264859199524\n",
      "Validation: loss 5.686843573788911, covariance difference 8.627393282079549, sinkhorn epsilon 0.0\n",
      "Iteration  1871\n",
      "Training: loss 4.647111892700195, covariance difference 1.0205572843551636\n",
      "Validation: loss 5.657847363270805, covariance difference 8.626147958803543, sinkhorn epsilon 0.0\n",
      "Iteration  1872\n",
      "Training: loss 4.618119239807129, covariance difference 1.0151605606079102\n",
      "Validation: loss 5.666800528200341, covariance difference 8.64300539223026, sinkhorn epsilon 0.0\n",
      "Iteration  1873\n",
      "Training: loss 4.627065658569336, covariance difference 1.0182279348373413\n",
      "Validation: loss 5.675472259318113, covariance difference 8.779844777716308, sinkhorn epsilon 0.0\n",
      "Iteration  1874\n",
      "Training: loss 4.635740756988525, covariance difference 1.0170351266860962\n",
      "Validation: loss 5.57850959003774, covariance difference 8.60596238606024, sinkhorn epsilon 0.0\n",
      "Iteration  1875\n",
      "Training: loss 4.538774013519287, covariance difference 0.9994549751281738\n",
      "Validation: loss 5.678971751748633, covariance difference 8.515336886371648, sinkhorn epsilon 0.0\n",
      "Iteration  1876\n",
      "Training: loss 4.639240264892578, covariance difference 1.0185749530792236\n",
      "Validation: loss 5.712389281852913, covariance difference 8.690117694250505, sinkhorn epsilon 0.0\n",
      "Iteration  1877\n",
      "Training: loss 4.672659873962402, covariance difference 1.025951862335205\n",
      "Validation: loss 5.61247821403698, covariance difference 8.738605631822091, sinkhorn epsilon 0.0\n",
      "Iteration  1878\n",
      "Training: loss 4.572751522064209, covariance difference 1.0083894729614258\n",
      "Validation: loss 5.619716084598661, covariance difference 8.575279148261403, sinkhorn epsilon 0.0\n",
      "Iteration  1879\n",
      "Training: loss 4.579981803894043, covariance difference 1.0089870691299438\n",
      "Validation: loss 5.669097430724061, covariance difference 8.728506642055914, sinkhorn epsilon 0.0\n",
      "Iteration  1880\n",
      "Training: loss 4.629366397857666, covariance difference 1.0176502466201782\n",
      "Validation: loss 5.6353216282526395, covariance difference 8.485283169932595, sinkhorn epsilon 0.0\n",
      "Iteration  1881\n",
      "Training: loss 4.595593452453613, covariance difference 1.0095371007919312\n",
      "Validation: loss 5.739329577601165, covariance difference 8.636696216153863, sinkhorn epsilon 0.0\n",
      "Iteration  1882\n",
      "Training: loss 4.699582099914551, covariance difference 1.0299726724624634\n",
      "Validation: loss 5.648117914451649, covariance difference 8.403538185572327, sinkhorn epsilon 0.0\n",
      "Iteration  1883\n",
      "Training: loss 4.608382701873779, covariance difference 1.0137325525283813\n",
      "Validation: loss 5.6471066586589345, covariance difference 8.488312575418915, sinkhorn epsilon 5.258759270543075e-14\n",
      "Iteration  1884\n",
      "Training: loss 4.60737419128418, covariance difference 1.0121614933013916\n",
      "Validation: loss 5.57397952101466, covariance difference 8.427700514671823, sinkhorn epsilon 0.0\n",
      "Iteration  1885\n",
      "Training: loss 4.534236907958984, covariance difference 1.000149130821228\n",
      "Validation: loss 5.60156682796184, covariance difference 8.57204587601717, sinkhorn epsilon 0.0\n",
      "Iteration  1886\n",
      "Training: loss 4.561834812164307, covariance difference 1.0051836967468262\n",
      "Validation: loss 5.650329775133028, covariance difference 8.730769472933503, sinkhorn epsilon 0.0\n",
      "Iteration  1887\n",
      "Training: loss 4.610601425170898, covariance difference 1.0139975547790527\n",
      "Validation: loss 5.5900395109268075, covariance difference 8.325399736860348, sinkhorn epsilon 0.0\n",
      "Iteration  1888\n",
      "Training: loss 4.550303936004639, covariance difference 1.0039818286895752\n",
      "Validation: loss 5.688290205899463, covariance difference 8.77491913650291, sinkhorn epsilon 0.0\n",
      "Iteration  1889\n",
      "Training: loss 4.648558616638184, covariance difference 1.020369529724121\n",
      "Validation: loss 5.664868641694914, covariance difference 8.61301621280308, sinkhorn epsilon 0.0\n",
      "Iteration  1890\n",
      "Training: loss 4.625136375427246, covariance difference 1.0177184343338013\n",
      "Validation: loss 5.674455736592537, covariance difference 8.565056792846535, sinkhorn epsilon 0.0\n",
      "Iteration  1891\n",
      "Training: loss 4.634723663330078, covariance difference 1.0170859098434448\n",
      "Validation: loss 5.7180720473463005, covariance difference 8.80534190874163, sinkhorn epsilon 0.0\n",
      "Iteration  1892\n",
      "Training: loss 4.678339958190918, covariance difference 1.027366280555725\n",
      "Validation: loss 5.706970931666566, covariance difference 8.76791923919724, sinkhorn epsilon 0.0\n",
      "Iteration  1893\n",
      "Training: loss 4.66724157333374, covariance difference 1.0222605466842651\n",
      "Validation: loss 5.582841106737776, covariance difference 8.563082990521599, sinkhorn epsilon 0.0\n",
      "Iteration  1894\n",
      "Training: loss 4.543108940124512, covariance difference 1.001451015472412\n",
      "Validation: loss 5.680431741671984, covariance difference 8.767245639427125, sinkhorn epsilon 0.0\n",
      "Iteration  1895\n",
      "Training: loss 4.640700340270996, covariance difference 1.0207133293151855\n",
      "Validation: loss 5.614165902976054, covariance difference 8.4717633964409, sinkhorn epsilon 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  1896\n",
      "Training: loss 4.574419021606445, covariance difference 1.0083609819412231\n",
      "Validation: loss 5.640258561747487, covariance difference 8.727476224251381, sinkhorn epsilon 0.0\n",
      "Iteration  1897\n",
      "Training: loss 4.600527286529541, covariance difference 1.0125495195388794\n",
      "Validation: loss 5.644231941040935, covariance difference 8.596095659502092, sinkhorn epsilon 0.0\n",
      "Iteration  1898\n",
      "Training: loss 4.6045002937316895, covariance difference 1.0111945867538452\n",
      "Validation: loss 5.696844713619514, covariance difference 8.684029845385748, sinkhorn epsilon 0.0\n",
      "Iteration  1899\n",
      "Training: loss 4.657108783721924, covariance difference 1.0215485095977783\n",
      "Validation: loss 5.649069684181719, covariance difference 8.576472154661799, sinkhorn epsilon 0.0\n",
      "Iteration  1900\n",
      "Training: loss 4.609339714050293, covariance difference 1.0132323503494263\n",
      "Validation: loss 5.667635923639642, covariance difference 8.690853038626805, sinkhorn epsilon 0.0\n",
      "Iteration  1901\n",
      "Training: loss 4.627904891967773, covariance difference 1.0176564455032349\n",
      "Validation: loss 5.735817858650656, covariance difference 8.780176467914627, sinkhorn epsilon 0.0\n",
      "Iteration  1902\n",
      "Training: loss 4.696081161499023, covariance difference 1.0297647714614868\n",
      "Validation: loss 5.704883397087043, covariance difference 8.566159021055634, sinkhorn epsilon 0.0\n",
      "Iteration  1903\n",
      "Training: loss 4.665153503417969, covariance difference 1.0247342586517334\n",
      "Validation: loss 5.619196913091705, covariance difference 8.619335574038939, sinkhorn epsilon 0.0\n",
      "Iteration  1904\n",
      "Training: loss 4.579461574554443, covariance difference 1.0097894668579102\n",
      "Validation: loss 5.684857469548076, covariance difference 8.456676968104171, sinkhorn epsilon 0.0\n",
      "Iteration  1905\n",
      "Training: loss 4.6451311111450195, covariance difference 1.0197678804397583\n",
      "Validation: loss 5.599226920059014, covariance difference 8.604699376852226, sinkhorn epsilon 0.0\n",
      "Iteration  1906\n",
      "Training: loss 4.559494972229004, covariance difference 1.0038470029830933\n",
      "Validation: loss 5.713041474479518, covariance difference 8.610294641204396, sinkhorn epsilon 0.0\n",
      "Iteration  1907\n",
      "Training: loss 4.673309326171875, covariance difference 1.0263316631317139\n",
      "Validation: loss 5.6824353340038645, covariance difference 8.636915434475135, sinkhorn epsilon 0.0\n",
      "Iteration  1908\n",
      "Training: loss 4.642699241638184, covariance difference 1.0197978019714355\n",
      "Validation: loss 5.680126854575003, covariance difference 8.592344997268283, sinkhorn epsilon 0.0\n",
      "Iteration  1909\n",
      "Training: loss 4.640395641326904, covariance difference 1.018627643585205\n",
      "Validation: loss 5.662391564055239, covariance difference 8.759397062455829, sinkhorn epsilon 0.0\n",
      "Iteration  1910\n",
      "Training: loss 4.622656345367432, covariance difference 1.0149301290512085\n",
      "Validation: loss 5.682527767251233, covariance difference 8.594811626882228, sinkhorn epsilon 0.0\n",
      "Iteration  1911\n",
      "Training: loss 4.6427998542785645, covariance difference 1.0205457210540771\n",
      "Validation: loss 5.7333982344548735, covariance difference 8.501653412560339, sinkhorn epsilon 0.0\n",
      "Iteration  1912\n",
      "Training: loss 4.693667411804199, covariance difference 1.0291908979415894\n",
      "Validation: loss 5.724025914809887, covariance difference 8.674535740986947, sinkhorn epsilon 0.0\n",
      "Iteration  1913\n",
      "Training: loss 4.6842942237854, covariance difference 1.026379942893982\n",
      "Validation: loss 5.685706819793188, covariance difference 8.639590947924926, sinkhorn epsilon 0.0\n",
      "Iteration  1914\n",
      "Training: loss 4.645975589752197, covariance difference 1.0205391645431519\n",
      "Validation: loss 5.693475182082139, covariance difference 8.664270115980127, sinkhorn epsilon 0.0\n",
      "Iteration  1915\n",
      "Training: loss 4.653738975524902, covariance difference 1.020762324333191\n",
      "Validation: loss 5.625645327235348, covariance difference 8.72265982661949, sinkhorn epsilon 0.0\n",
      "Iteration  1916\n",
      "Training: loss 4.585914611816406, covariance difference 1.0095117092132568\n",
      "Validation: loss 5.61942356170108, covariance difference 8.708836102626373, sinkhorn epsilon 0.0\n",
      "Iteration  1917\n",
      "Training: loss 4.57969331741333, covariance difference 1.0070208311080933\n",
      "Validation: loss 5.65112126914245, covariance difference 8.647882227470776, sinkhorn epsilon 0.0\n",
      "Iteration  1918\n",
      "Training: loss 4.611389636993408, covariance difference 1.014083743095398\n",
      "Validation: loss 5.649375577633958, covariance difference 8.516979184609403, sinkhorn epsilon 0.0\n",
      "Iteration  1919\n",
      "Training: loss 4.609643936157227, covariance difference 1.0141832828521729\n",
      "Validation: loss 5.6934469354156505, covariance difference 8.598427935931829, sinkhorn epsilon 0.0\n",
      "Iteration  1920\n",
      "Training: loss 4.653715133666992, covariance difference 1.0216178894042969\n",
      "Validation: loss 5.608033575747584, covariance difference 8.551659891794275, sinkhorn epsilon 0.0\n",
      "Iteration  1921\n",
      "Training: loss 4.568303108215332, covariance difference 1.0075664520263672\n",
      "Validation: loss 5.563661671409703, covariance difference 8.547625442846865, sinkhorn epsilon 0.0\n",
      "Iteration  1922\n",
      "Training: loss 4.523926258087158, covariance difference 0.9979069232940674\n",
      "Validation: loss 5.605020612890625, covariance difference 8.4239175261023, sinkhorn epsilon 0.0\n",
      "Iteration  1923\n",
      "Training: loss 4.565290451049805, covariance difference 1.0064727067947388\n",
      "Validation: loss 5.719526625013911, covariance difference 8.607291216230688, sinkhorn epsilon 0.0\n",
      "Iteration  1924\n",
      "Training: loss 4.679795265197754, covariance difference 1.0268393754959106\n",
      "Validation: loss 5.6780443910716825, covariance difference 8.555160630108835, sinkhorn epsilon 0.0\n",
      "Iteration  1925\n",
      "Training: loss 4.638308048248291, covariance difference 1.0176491737365723\n",
      "Validation: loss 5.618244410726721, covariance difference 8.531707920773433, sinkhorn epsilon 0.0\n",
      "Iteration  1926\n",
      "Training: loss 4.578512191772461, covariance difference 1.0072497129440308\n",
      "Validation: loss 5.5819673434556085, covariance difference 8.725118171276124, sinkhorn epsilon 0.0\n",
      "Iteration  1927\n",
      "Training: loss 4.542237281799316, covariance difference 1.000317096710205\n",
      "Validation: loss 5.646856126228396, covariance difference 8.787729677440396, sinkhorn epsilon 0.0\n",
      "Iteration  1928\n",
      "Training: loss 4.607125282287598, covariance difference 1.012135624885559\n",
      "Validation: loss 5.631481804887027, covariance difference 8.56745637185707, sinkhorn epsilon 0.0\n",
      "Iteration  1929\n",
      "Training: loss 4.59174919128418, covariance difference 1.0110927820205688\n",
      "Validation: loss 5.682099927607349, covariance difference 8.545726845780957, sinkhorn epsilon 0.0\n",
      "Iteration  1930\n",
      "Training: loss 4.642370223999023, covariance difference 1.0211855173110962\n",
      "Validation: loss 5.631375220788366, covariance difference 8.54225746726091, sinkhorn epsilon 0.0\n",
      "Iteration  1931\n",
      "Training: loss 4.591639995574951, covariance difference 1.009677767753601\n",
      "Validation: loss 5.580176337136109, covariance difference 8.222133711514813, sinkhorn epsilon 0.0\n",
      "Iteration  1932\n",
      "Training: loss 4.540444374084473, covariance difference 1.0018690824508667\n",
      "Validation: loss 5.646223378965732, covariance difference 8.708364374617693, sinkhorn epsilon 0.0\n",
      "Iteration  1933\n",
      "Training: loss 4.606492042541504, covariance difference 1.0145317316055298\n",
      "Validation: loss 5.650307031726762, covariance difference 8.639139179902413, sinkhorn epsilon 0.0\n",
      "Iteration  1934\n",
      "Training: loss 4.610571384429932, covariance difference 1.0131887197494507\n",
      "Validation: loss 5.705045165143604, covariance difference 8.714017587739077, sinkhorn epsilon 0.0\n",
      "Iteration  1935\n",
      "Training: loss 4.665313720703125, covariance difference 1.0242986679077148\n",
      "Validation: loss 5.621491532010058, covariance difference 8.60543035764693, sinkhorn epsilon 0.0\n",
      "Iteration  1936\n",
      "Training: loss 4.581764221191406, covariance difference 1.0090864896774292\n",
      "Validation: loss 5.721202214428686, covariance difference 8.686658310334352, sinkhorn epsilon 0.0\n",
      "Iteration  1937\n",
      "Training: loss 4.681469917297363, covariance difference 1.026967167854309\n",
      "Validation: loss 5.633850282208627, covariance difference 8.55859442075777, sinkhorn epsilon 0.0\n",
      "Iteration  1938\n",
      "Training: loss 4.594115257263184, covariance difference 1.010412335395813\n",
      "Validation: loss 5.658125920675244, covariance difference 8.71201651445541, sinkhorn epsilon 0.0\n",
      "Iteration  1939\n",
      "Training: loss 4.61839485168457, covariance difference 1.0149829387664795\n",
      "Validation: loss 5.703254092767689, covariance difference 8.665529136012431, sinkhorn epsilon 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  1940\n",
      "Training: loss 4.663521766662598, covariance difference 1.0242552757263184\n",
      "Validation: loss 5.635921999423703, covariance difference 8.85861072911596, sinkhorn epsilon 0.0\n",
      "Iteration  1941\n",
      "Training: loss 4.596189975738525, covariance difference 1.0102170705795288\n",
      "Validation: loss 5.595414501684004, covariance difference 8.477794270101672, sinkhorn epsilon 0.0\n",
      "Iteration  1942\n",
      "Training: loss 4.555673599243164, covariance difference 1.0038411617279053\n",
      "Validation: loss 5.617093811699467, covariance difference 8.513779373990292, sinkhorn epsilon 0.0\n",
      "Iteration  1943\n",
      "Training: loss 4.577358245849609, covariance difference 1.0074694156646729\n",
      "Validation: loss 5.64302458401939, covariance difference 8.849205646221753, sinkhorn epsilon 0.0\n",
      "Iteration  1944\n",
      "Training: loss 4.603288650512695, covariance difference 1.0122532844543457\n",
      "Validation: loss 5.614787532027204, covariance difference 8.584938825072143, sinkhorn epsilon 2.9135880773941904e-14\n",
      "Iteration  1945\n",
      "Training: loss 4.575055122375488, covariance difference 1.0087748765945435\n",
      "Validation: loss 5.606471061242423, covariance difference 8.492748976996952, sinkhorn epsilon 0.0\n",
      "Iteration  1946\n",
      "Training: loss 4.566738128662109, covariance difference 1.007086157798767\n",
      "Validation: loss 5.680978996493131, covariance difference 8.633964587185753, sinkhorn epsilon 0.0\n",
      "Iteration  1947\n",
      "Training: loss 4.641246795654297, covariance difference 1.0201789140701294\n",
      "Validation: loss 5.606568495455232, covariance difference 8.717602410054623, sinkhorn epsilon 0.0\n",
      "Iteration  1948\n",
      "Training: loss 4.566833019256592, covariance difference 1.006263017654419\n",
      "Validation: loss 5.6374620398332835, covariance difference 8.636058923755566, sinkhorn epsilon 0.0\n",
      "Iteration  1949\n",
      "Training: loss 4.59773063659668, covariance difference 1.0105122327804565\n",
      "Validation: loss 5.689297204295893, covariance difference 8.4117884693938, sinkhorn epsilon 0.0\n",
      "Iteration  1950\n",
      "Training: loss 4.649561882019043, covariance difference 1.0199553966522217\n",
      "Validation: loss 5.658381777748338, covariance difference 8.76649671738164, sinkhorn epsilon 0.0\n",
      "Iteration  1951\n",
      "Training: loss 4.61865234375, covariance difference 1.0145987272262573\n",
      "Validation: loss 5.637629559634308, covariance difference 8.634395764611092, sinkhorn epsilon 0.0\n",
      "Iteration  1952\n",
      "Training: loss 4.597894191741943, covariance difference 1.0117789506912231\n",
      "Validation: loss 5.639327118022593, covariance difference 8.601274419820875, sinkhorn epsilon 0.0\n",
      "Iteration  1953\n",
      "Training: loss 4.599588394165039, covariance difference 1.0116206407546997\n",
      "Validation: loss 5.62562333683339, covariance difference 8.653350030236638, sinkhorn epsilon 0.0\n",
      "Iteration  1954\n",
      "Training: loss 4.585893154144287, covariance difference 1.0081028938293457\n",
      "Validation: loss 5.671106079684085, covariance difference 8.677247234346861, sinkhorn epsilon 0.0\n",
      "Iteration  1955\n",
      "Training: loss 4.631372451782227, covariance difference 1.0171852111816406\n",
      "Validation: loss 5.661409063081308, covariance difference 8.567613111980007, sinkhorn epsilon 0.0\n",
      "Iteration  1956\n",
      "Training: loss 4.621676445007324, covariance difference 1.0159939527511597\n",
      "Validation: loss 5.702163034956743, covariance difference 8.551559459365265, sinkhorn epsilon 0.0\n",
      "Iteration  1957\n",
      "Training: loss 4.6624274253845215, covariance difference 1.0231785774230957\n",
      "Validation: loss 5.713877532033167, covariance difference 8.610654856346407, sinkhorn epsilon 0.0\n",
      "Iteration  1958\n",
      "Training: loss 4.674130916595459, covariance difference 1.0237772464752197\n",
      "Validation: loss 5.6138752633155775, covariance difference 8.549558429236116, sinkhorn epsilon 0.0\n",
      "Iteration  1959\n",
      "Training: loss 4.5741286277771, covariance difference 1.0060346126556396\n",
      "Validation: loss 5.651285786386431, covariance difference 8.587191718528084, sinkhorn epsilon 2.802368350449173e-14\n",
      "Iteration  1960\n",
      "Training: loss 4.6115546226501465, covariance difference 1.0123963356018066\n",
      "Validation: loss 5.761194418459652, covariance difference 8.867324790713182, sinkhorn epsilon 0.0\n",
      "Iteration  1961\n",
      "Training: loss 4.72144889831543, covariance difference 1.0341777801513672\n",
      "Validation: loss 5.624581752745378, covariance difference 8.736503421334818, sinkhorn epsilon 0.0\n",
      "Iteration  1962\n",
      "Training: loss 4.584845542907715, covariance difference 1.0075693130493164\n",
      "Validation: loss 5.714715944262559, covariance difference 8.756562024335492, sinkhorn epsilon 0.0\n",
      "Iteration  1963\n",
      "Training: loss 4.674983978271484, covariance difference 1.0262428522109985\n",
      "Validation: loss 5.672829462965007, covariance difference 8.675228125079911, sinkhorn epsilon 0.0\n",
      "Iteration  1964\n",
      "Training: loss 4.633098602294922, covariance difference 1.0172713994979858\n",
      "Validation: loss 5.63438630730821, covariance difference 8.586403080875726, sinkhorn epsilon 0.0\n",
      "Iteration  1965\n",
      "Training: loss 4.5946550369262695, covariance difference 1.010171890258789\n",
      "Validation: loss 5.685393442662289, covariance difference 8.626043356808909, sinkhorn epsilon 0.0\n",
      "Iteration  1966\n",
      "Training: loss 4.645662307739258, covariance difference 1.0202175378799438\n",
      "Validation: loss 5.652960339428849, covariance difference 8.590496614462499, sinkhorn epsilon 0.0\n",
      "Iteration  1967\n",
      "Training: loss 4.613227844238281, covariance difference 1.0156853199005127\n",
      "Validation: loss 5.657180158064216, covariance difference 8.547796042119417, sinkhorn epsilon 0.0\n",
      "Iteration  1968\n",
      "Training: loss 4.617448806762695, covariance difference 1.0154600143432617\n",
      "Validation: loss 5.671591666094527, covariance difference 8.427352873584258, sinkhorn epsilon 0.0\n",
      "Iteration  1969\n",
      "Training: loss 4.63185977935791, covariance difference 1.0157595872879028\n",
      "Validation: loss 5.615838623489142, covariance difference 8.582360735147095, sinkhorn epsilon 0.0\n",
      "Iteration  1970\n",
      "Training: loss 4.576092720031738, covariance difference 1.00806725025177\n",
      "Validation: loss 5.6542119265244395, covariance difference 8.62694039543937, sinkhorn epsilon 0.0\n",
      "Iteration  1971\n",
      "Training: loss 4.614466667175293, covariance difference 1.0136662721633911\n",
      "Validation: loss 5.60674664075937, covariance difference 8.51270595552166, sinkhorn epsilon 0.0\n",
      "Iteration  1972\n",
      "Training: loss 4.567017078399658, covariance difference 1.0057857036590576\n",
      "Validation: loss 5.661920449533767, covariance difference 8.462544892874934, sinkhorn epsilon 0.0\n",
      "Iteration  1973\n",
      "Training: loss 4.622187614440918, covariance difference 1.0160280466079712\n",
      "Validation: loss 5.623395578404452, covariance difference 8.307977040824005, sinkhorn epsilon 0.0\n",
      "Iteration  1974\n",
      "Training: loss 4.583660125732422, covariance difference 1.0099859237670898\n",
      "Validation: loss 5.70529476373958, covariance difference 8.853953428510717, sinkhorn epsilon 0.0\n",
      "Iteration  1975\n",
      "Training: loss 4.665564060211182, covariance difference 1.0231174230575562\n",
      "Validation: loss 5.654844815110947, covariance difference 8.61545735724172, sinkhorn epsilon 0.0\n",
      "Iteration  1976\n",
      "Training: loss 4.615113258361816, covariance difference 1.0154435634613037\n",
      "Validation: loss 5.707956467219791, covariance difference 8.741483658056785, sinkhorn epsilon 0.0\n",
      "Iteration  1977\n",
      "Training: loss 4.668228626251221, covariance difference 1.0237843990325928\n",
      "Validation: loss 5.645701400078682, covariance difference 8.47001405774079, sinkhorn epsilon 0.0\n",
      "Iteration  1978\n",
      "Training: loss 4.605956077575684, covariance difference 1.0149890184402466\n",
      "Validation: loss 5.637243852626388, covariance difference 8.74269871164776, sinkhorn epsilon 1.6851094797422827e-14\n",
      "Iteration  1979\n",
      "Training: loss 4.597512245178223, covariance difference 1.009803056716919\n",
      "Validation: loss 5.597815495703843, covariance difference 8.710039003618908, sinkhorn epsilon 0.0\n",
      "Iteration  1980\n",
      "Training: loss 4.558080673217773, covariance difference 1.0041202306747437\n",
      "Validation: loss 5.591207263519301, covariance difference 8.400975048759065, sinkhorn epsilon 0.0\n",
      "Iteration  1981\n",
      "Training: loss 4.551471710205078, covariance difference 1.0037915706634521\n",
      "Validation: loss 5.746595868548988, covariance difference 8.71151439033556, sinkhorn epsilon 0.0\n",
      "Iteration  1982\n",
      "Training: loss 4.706860065460205, covariance difference 1.0304588079452515\n",
      "Validation: loss 5.700479256610454, covariance difference 8.479170961138097, sinkhorn epsilon 0.0\n",
      "Iteration  1983\n",
      "Training: loss 4.660743713378906, covariance difference 1.0220086574554443\n",
      "Validation: loss 5.660702452342046, covariance difference 8.643810361415941, sinkhorn epsilon 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  1984\n",
      "Training: loss 4.6209564208984375, covariance difference 1.0161775350570679\n",
      "Validation: loss 5.670922458044952, covariance difference 8.579040915812705, sinkhorn epsilon 0.0\n",
      "Iteration  1985\n",
      "Training: loss 4.631191730499268, covariance difference 1.0176451206207275\n",
      "Validation: loss 5.662974557128322, covariance difference 8.688645447569913, sinkhorn epsilon 6.258828645872519e-14\n",
      "Iteration  1986\n",
      "Training: loss 4.623233795166016, covariance difference 1.0169435739517212\n",
      "Validation: loss 5.636645106224884, covariance difference 8.588402034926675, sinkhorn epsilon 0.0\n",
      "Iteration  1987\n",
      "Training: loss 4.596909523010254, covariance difference 1.011296033859253\n",
      "Validation: loss 5.670585917545982, covariance difference 8.914900966552702, sinkhorn epsilon 0.0\n",
      "Iteration  1988\n",
      "Training: loss 4.630849838256836, covariance difference 1.0159637928009033\n",
      "Validation: loss 5.641813214613643, covariance difference 8.658083833596082, sinkhorn epsilon 0.0\n",
      "Iteration  1989\n",
      "Training: loss 4.602070331573486, covariance difference 1.0099079608917236\n",
      "Validation: loss 5.620253295593853, covariance difference 8.520556258110274, sinkhorn epsilon 0.0\n",
      "Iteration  1990\n",
      "Training: loss 4.580521583557129, covariance difference 1.0085569620132446\n",
      "Validation: loss 5.671503765015576, covariance difference 8.423725065628798, sinkhorn epsilon 0.0\n",
      "Iteration  1991\n",
      "Training: loss 4.631771564483643, covariance difference 1.017479419708252\n",
      "Validation: loss 5.595955153686156, covariance difference 8.612320277969694, sinkhorn epsilon 0.0\n",
      "Iteration  1992\n",
      "Training: loss 4.556211471557617, covariance difference 1.0050616264343262\n",
      "Validation: loss 5.664531768454216, covariance difference 8.768840034950106, sinkhorn epsilon 0.0\n",
      "Iteration  1993\n",
      "Training: loss 4.624795913696289, covariance difference 1.0166218280792236\n",
      "Validation: loss 5.631806742116497, covariance difference 8.622930569027236, sinkhorn epsilon 0.0\n",
      "Iteration  1994\n",
      "Training: loss 4.592076778411865, covariance difference 1.0101077556610107\n",
      "Validation: loss 5.716352868086256, covariance difference 8.689901579248867, sinkhorn epsilon 5.480064740083053e-14\n",
      "Iteration  1995\n",
      "Training: loss 4.676630020141602, covariance difference 1.0229202508926392\n",
      "Validation: loss 5.616420300045283, covariance difference 8.437188215129716, sinkhorn epsilon 0.0\n",
      "Iteration  1996\n",
      "Training: loss 4.576687812805176, covariance difference 1.005889654159546\n",
      "Validation: loss 5.630165978422365, covariance difference 8.465701488481118, sinkhorn epsilon 0.0\n",
      "Iteration  1997\n",
      "Training: loss 4.590423107147217, covariance difference 1.0113292932510376\n",
      "Validation: loss 5.674144742655582, covariance difference 8.616926887586603, sinkhorn epsilon 0.0\n",
      "Iteration  1998\n",
      "Training: loss 4.634408950805664, covariance difference 1.0168488025665283\n",
      "Validation: loss 5.740547301879085, covariance difference 8.80153930629007, sinkhorn epsilon 0.0\n",
      "Iteration  1999\n",
      "Training: loss 4.7008161544799805, covariance difference 1.0305678844451904\n",
      "Validation: loss 5.586926796973543, covariance difference 8.57872766266142, sinkhorn epsilon 0.0\n",
      "Iteration  2000\n",
      "Training: loss 4.547191619873047, covariance difference 1.0021095275878906\n",
      "Validation: loss 5.644605134513718, covariance difference 8.49492720567394, sinkhorn epsilon 4.870017630916299e-14\n",
      "Iteration  2001\n",
      "Training: loss 4.6048736572265625, covariance difference 1.0127376317977905\n",
      "Validation: loss 5.633033326951441, covariance difference 8.620721867560238, sinkhorn epsilon 0.0\n",
      "Iteration  2002\n",
      "Training: loss 4.593297958374023, covariance difference 1.008902907371521\n",
      "Validation: loss 5.618944964647577, covariance difference 8.292636005003406, sinkhorn epsilon 0.0\n",
      "Iteration  2003\n",
      "Training: loss 4.579209327697754, covariance difference 1.0089565515518188\n",
      "Validation: loss 5.684084363088705, covariance difference 8.646894712480064, sinkhorn epsilon 0.0\n",
      "Iteration  2004\n",
      "Training: loss 4.644348621368408, covariance difference 1.020827054977417\n",
      "Validation: loss 5.62857060050328, covariance difference 8.51951378423612, sinkhorn epsilon 0.0\n",
      "Iteration  2005\n",
      "Training: loss 4.588823318481445, covariance difference 1.0099663734436035\n",
      "Validation: loss 5.5914610807895295, covariance difference 8.459302859187344, sinkhorn epsilon 0.0\n",
      "Iteration  2006\n",
      "Training: loss 4.551731109619141, covariance difference 1.0034900903701782\n",
      "Validation: loss 5.706267202300802, covariance difference 8.626154227873554, sinkhorn epsilon 0.0\n",
      "Iteration  2007\n",
      "Training: loss 4.666535377502441, covariance difference 1.0245332717895508\n",
      "Validation: loss 5.670995793300295, covariance difference 8.774961880064884, sinkhorn epsilon 0.0\n",
      "Iteration  2008\n",
      "Training: loss 4.631259918212891, covariance difference 1.0185061693191528\n",
      "Validation: loss 5.805015397163, covariance difference 8.591645642368539, sinkhorn epsilon 0.0\n",
      "Iteration  2009\n",
      "Training: loss 4.7652788162231445, covariance difference 1.0404934883117676\n",
      "Validation: loss 5.603561836185895, covariance difference 8.67959253893563, sinkhorn epsilon 0.0\n",
      "Iteration  2010\n",
      "Training: loss 4.563831329345703, covariance difference 1.0058218240737915\n",
      "Validation: loss 5.716898684434008, covariance difference 8.682353420423015, sinkhorn epsilon 0.0\n",
      "Iteration  2011\n",
      "Training: loss 4.6771626472473145, covariance difference 1.0263036489486694\n",
      "Validation: loss 5.666362375321181, covariance difference 8.620837042955598, sinkhorn epsilon 0.0\n",
      "Iteration  2012\n",
      "Training: loss 4.626626968383789, covariance difference 1.0170269012451172\n",
      "Validation: loss 5.6146228510445315, covariance difference 8.407013934563878, sinkhorn epsilon 0.0\n",
      "Iteration  2013\n",
      "Training: loss 4.574887752532959, covariance difference 1.0069772005081177\n",
      "Validation: loss 5.680921984864458, covariance difference 8.660171623907923, sinkhorn epsilon 0.0\n",
      "Iteration  2014\n",
      "Training: loss 4.6411919593811035, covariance difference 1.0192835330963135\n",
      "Validation: loss 5.610727458189098, covariance difference 8.53766730349267, sinkhorn epsilon 3.4176134258543224e-14\n",
      "Iteration  2015\n",
      "Training: loss 4.570996284484863, covariance difference 1.0071256160736084\n",
      "Validation: loss 5.561663239017076, covariance difference 8.743354006808927, sinkhorn epsilon 0.0\n",
      "Iteration  2016\n",
      "Training: loss 4.5219316482543945, covariance difference 0.9972485899925232\n",
      "Validation: loss 5.716751303857704, covariance difference 8.486520964701258, sinkhorn epsilon 4.846059798944659e-14\n",
      "Iteration  2017\n",
      "Training: loss 4.6770219802856445, covariance difference 1.025103211402893\n",
      "Validation: loss 5.634040218175554, covariance difference 8.61936089063477, sinkhorn epsilon 0.0\n",
      "Iteration  2018\n",
      "Training: loss 4.594310760498047, covariance difference 1.011212706565857\n",
      "Validation: loss 5.663272873679658, covariance difference 8.668812841157502, sinkhorn epsilon 0.0\n",
      "Iteration  2019\n",
      "Training: loss 4.623541355133057, covariance difference 1.0157710313796997\n",
      "Validation: loss 5.699196549578455, covariance difference 8.511831876226246, sinkhorn epsilon 0.0\n",
      "Iteration  2020\n",
      "Training: loss 4.65946102142334, covariance difference 1.0230008363723755\n",
      "Validation: loss 5.675339501931258, covariance difference 8.564405350438427, sinkhorn epsilon 0.0\n",
      "Iteration  2021\n",
      "Training: loss 4.63560152053833, covariance difference 1.0182231664657593\n",
      "Validation: loss 5.605298719312967, covariance difference 8.59653252515375, sinkhorn epsilon 0.0\n",
      "Iteration  2022\n",
      "Training: loss 4.5655670166015625, covariance difference 1.0039241313934326\n",
      "Validation: loss 5.686839106394537, covariance difference 8.518502922489544, sinkhorn epsilon 0.0\n",
      "Iteration  2023\n",
      "Training: loss 4.6471076011657715, covariance difference 1.0191941261291504\n",
      "Validation: loss 5.654773111253355, covariance difference 8.600628247628983, sinkhorn epsilon 0.0\n",
      "Iteration  2024\n",
      "Training: loss 4.615041255950928, covariance difference 1.0126657485961914\n",
      "Validation: loss 5.664935043327788, covariance difference 8.670192148350091, sinkhorn epsilon 0.0\n",
      "Iteration  2025\n",
      "Training: loss 4.6252031326293945, covariance difference 1.0162938833236694\n",
      "Validation: loss 5.654892620349902, covariance difference 8.565935931374401, sinkhorn epsilon 1.7297993492795644e-14\n",
      "Iteration  2026\n",
      "Training: loss 4.6151628494262695, covariance difference 1.0130853652954102\n",
      "Validation: loss 5.679950961056016, covariance difference 8.510802272454264, sinkhorn epsilon 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  2027\n",
      "Training: loss 4.6402201652526855, covariance difference 1.0186220407485962\n",
      "Validation: loss 5.634867066979705, covariance difference 8.587531911074846, sinkhorn epsilon 0.0\n",
      "Iteration  2028\n",
      "Training: loss 4.595134735107422, covariance difference 1.0105797052383423\n",
      "Validation: loss 5.636194869920947, covariance difference 8.757658503910832, sinkhorn epsilon 0.0\n",
      "Iteration  2029\n",
      "Training: loss 4.596463203430176, covariance difference 1.0107685327529907\n",
      "Validation: loss 5.579077426716815, covariance difference 8.599176898464972, sinkhorn epsilon 0.0\n",
      "Iteration  2030\n",
      "Training: loss 4.539344787597656, covariance difference 1.000700831413269\n",
      "Validation: loss 5.604026213404852, covariance difference 8.417822501666254, sinkhorn epsilon 0.0\n",
      "Iteration  2031\n",
      "Training: loss 4.564291000366211, covariance difference 1.006935477256775\n",
      "Validation: loss 5.672975650178317, covariance difference 8.64063530307735, sinkhorn epsilon 0.0\n",
      "Iteration  2032\n",
      "Training: loss 4.633240699768066, covariance difference 1.0190515518188477\n",
      "Validation: loss 5.658144500376463, covariance difference 8.436935883422443, sinkhorn epsilon 0.0\n",
      "Iteration  2033\n",
      "Training: loss 4.618412971496582, covariance difference 1.0140252113342285\n",
      "Validation: loss 5.690774579900631, covariance difference 8.646470632981838, sinkhorn epsilon 0.0\n",
      "Iteration  2034\n",
      "Training: loss 4.65104341506958, covariance difference 1.0209006071090698\n",
      "Validation: loss 5.638186807624349, covariance difference 8.560210502218853, sinkhorn epsilon 0.0\n",
      "Iteration  2035\n",
      "Training: loss 4.598454475402832, covariance difference 1.013197422027588\n",
      "Validation: loss 5.685124264407213, covariance difference 8.824671583358311, sinkhorn epsilon 0.0\n",
      "Iteration  2036\n",
      "Training: loss 4.645398139953613, covariance difference 1.0196998119354248\n",
      "Validation: loss 5.715306161320065, covariance difference 8.696291731741898, sinkhorn epsilon 0.0\n",
      "Iteration  2037\n",
      "Training: loss 4.675576210021973, covariance difference 1.0261027812957764\n",
      "Validation: loss 5.6000014239065985, covariance difference 8.460051979489991, sinkhorn epsilon 0.0\n",
      "Iteration  2038\n",
      "Training: loss 4.560272216796875, covariance difference 1.0041455030441284\n",
      "Validation: loss 5.6449141449204285, covariance difference 8.62033596373606, sinkhorn epsilon 0.0\n",
      "Iteration  2039\n",
      "Training: loss 4.605178356170654, covariance difference 1.0133808851242065\n",
      "Validation: loss 5.681129044981435, covariance difference 8.666912748058504, sinkhorn epsilon 0.0\n",
      "Iteration  2040\n",
      "Training: loss 4.641393661499023, covariance difference 1.0173221826553345\n",
      "Validation: loss 5.560125730263442, covariance difference 8.533405437194402, sinkhorn epsilon 0.0\n",
      "Iteration  2041\n",
      "Training: loss 4.52039098739624, covariance difference 0.9967142343521118\n",
      "Validation: loss 5.623464628877142, covariance difference 8.560058959789135, sinkhorn epsilon 0.0\n",
      "Iteration  2042\n",
      "Training: loss 4.58373498916626, covariance difference 1.008387565612793\n",
      "Validation: loss 5.6973438681751984, covariance difference 8.785038046920546, sinkhorn epsilon 0.0\n",
      "Iteration  2043\n",
      "Training: loss 4.657607555389404, covariance difference 1.0208812952041626\n",
      "Validation: loss 5.60111424971276, covariance difference 8.555888207865488, sinkhorn epsilon 0.0\n",
      "Iteration  2044\n",
      "Training: loss 4.561386585235596, covariance difference 1.003693699836731\n",
      "Validation: loss 5.680759026584003, covariance difference 8.762734378938488, sinkhorn epsilon 0.0\n",
      "Iteration  2045\n",
      "Training: loss 4.641034126281738, covariance difference 1.0180951356887817\n",
      "Validation: loss 5.643967688036584, covariance difference 8.614932147249766, sinkhorn epsilon 0.0\n",
      "Iteration  2046\n",
      "Training: loss 4.60423469543457, covariance difference 1.0130144357681274\n",
      "Validation: loss 5.644717538359219, covariance difference 8.578944414420206, sinkhorn epsilon 0.0\n",
      "Iteration  2047\n",
      "Training: loss 4.604982376098633, covariance difference 1.0129541158676147\n",
      "Validation: loss 5.700256973080674, covariance difference 8.479720443105435, sinkhorn epsilon 0.0\n",
      "Iteration  2048\n",
      "Training: loss 4.660525321960449, covariance difference 1.0220351219177246\n",
      "Validation: loss 5.701943577291987, covariance difference 8.568303378165819, sinkhorn epsilon 0.0\n",
      "Iteration  2049\n",
      "Training: loss 4.66220235824585, covariance difference 1.0235164165496826\n",
      "Validation: loss 5.659725135841498, covariance difference 8.604735966865416, sinkhorn epsilon 0.0\n",
      "Iteration  2050\n",
      "Training: loss 4.619998455047607, covariance difference 1.014377474784851\n",
      "Validation: loss 5.630509281132674, covariance difference 8.40954569693345, sinkhorn epsilon 0.0\n",
      "Iteration  2051\n",
      "Training: loss 4.590777397155762, covariance difference 1.010166883468628\n",
      "Validation: loss 5.787756866575034, covariance difference 8.802721751775183, sinkhorn epsilon 0.0\n",
      "Iteration  2052\n",
      "Training: loss 4.748023986816406, covariance difference 1.039577841758728\n",
      "Validation: loss 5.653699434805048, covariance difference 8.771237097143805, sinkhorn epsilon 0.0\n",
      "Iteration  2053\n",
      "Training: loss 4.613975524902344, covariance difference 1.0176154375076294\n",
      "Validation: loss 5.707774846406491, covariance difference 8.449790384898758, sinkhorn epsilon 0.0\n",
      "Iteration  2054\n",
      "Training: loss 4.668042182922363, covariance difference 1.0250799655914307\n",
      "Validation: loss 5.689488713229158, covariance difference 8.817853949547837, sinkhorn epsilon 0.0\n",
      "Iteration  2055\n",
      "Training: loss 4.649757385253906, covariance difference 1.0207282304763794\n",
      "Validation: loss 5.631931576417951, covariance difference 8.53917715037121, sinkhorn epsilon 0.0\n",
      "Iteration  2056\n",
      "Training: loss 4.592203617095947, covariance difference 1.0094670057296753\n",
      "Validation: loss 5.615479565978013, covariance difference 8.761494181676177, sinkhorn epsilon 0.0\n",
      "Iteration  2057\n",
      "Training: loss 4.575748443603516, covariance difference 1.0072128772735596\n",
      "Validation: loss 5.645858247123095, covariance difference 8.479613112177693, sinkhorn epsilon 0.0\n",
      "Iteration  2058\n",
      "Training: loss 4.606125831604004, covariance difference 1.0136178731918335\n",
      "Validation: loss 5.728991430015741, covariance difference 8.784575034802513, sinkhorn epsilon 0.0\n",
      "Iteration  2059\n",
      "Training: loss 4.689255237579346, covariance difference 1.0289102792739868\n",
      "Validation: loss 5.673400147523456, covariance difference 8.693654491809028, sinkhorn epsilon 0.0\n",
      "Iteration  2060\n",
      "Training: loss 4.6336669921875, covariance difference 1.017524003982544\n",
      "Validation: loss 5.643462533077253, covariance difference 8.615234445558327, sinkhorn epsilon 2.4429112079705798e-14\n",
      "Iteration  2061\n",
      "Training: loss 4.60373067855835, covariance difference 1.0126417875289917\n",
      "Validation: loss 5.748265572287082, covariance difference 8.56911088999159, sinkhorn epsilon 4.3986767654509896e-14\n",
      "Iteration  2062\n",
      "Training: loss 4.708534240722656, covariance difference 1.032385230064392\n",
      "Validation: loss 5.662081896377054, covariance difference 8.830917801877238, sinkhorn epsilon 1.6895196936602565e-14\n",
      "Iteration  2063\n",
      "Training: loss 4.622349739074707, covariance difference 1.0167282819747925\n",
      "Validation: loss 5.624345779733533, covariance difference 8.56169881128773, sinkhorn epsilon 0.0\n",
      "Iteration  2064\n",
      "Training: loss 4.5846052169799805, covariance difference 1.0091123580932617\n",
      "Validation: loss 5.655332770041933, covariance difference 8.625827776930977, sinkhorn epsilon 0.0\n",
      "Iteration  2065\n",
      "Training: loss 4.6156005859375, covariance difference 1.01399827003479\n",
      "Validation: loss 5.58207183462835, covariance difference 8.36762536729091, sinkhorn epsilon 0.0\n",
      "Iteration  2066\n",
      "Training: loss 4.542341709136963, covariance difference 1.0022023916244507\n",
      "Validation: loss 5.717112579603492, covariance difference 8.79454616806581, sinkhorn epsilon 0.0\n",
      "Iteration  2067\n",
      "Training: loss 4.677381992340088, covariance difference 1.0280004739761353\n",
      "Validation: loss 5.630604040143678, covariance difference 8.292396754787829, sinkhorn epsilon 8.645448263749034e-14\n",
      "Iteration  2068\n",
      "Training: loss 4.590872287750244, covariance difference 1.0106842517852783\n",
      "Validation: loss 5.627325716803677, covariance difference 8.69713094582268, sinkhorn epsilon 0.0\n",
      "Iteration  2069\n",
      "Training: loss 4.587599277496338, covariance difference 1.009240746498108\n",
      "Validation: loss 5.6313331981278205, covariance difference 8.508741889230867, sinkhorn epsilon 4.7076173097783854e-14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  2070\n",
      "Training: loss 4.591607093811035, covariance difference 1.0107051134109497\n",
      "Validation: loss 5.588773939828483, covariance difference 8.651427197102613, sinkhorn epsilon 0.0\n",
      "Iteration  2071\n",
      "Training: loss 4.549038410186768, covariance difference 1.0048222541809082\n",
      "Validation: loss 5.640151672338872, covariance difference 8.772387807288945, sinkhorn epsilon 5.5835592318908964e-14\n",
      "Iteration  2072\n",
      "Training: loss 4.60042142868042, covariance difference 1.0112918615341187\n",
      "Validation: loss 5.614025112276953, covariance difference 8.62410309632833, sinkhorn epsilon 0.0\n",
      "Iteration  2073\n",
      "Training: loss 4.574295997619629, covariance difference 1.0087511539459229\n",
      "Validation: loss 5.727446306561171, covariance difference 8.641755292080976, sinkhorn epsilon 0.0\n",
      "Iteration  2074\n",
      "Training: loss 4.687716484069824, covariance difference 1.0288290977478027\n",
      "Validation: loss 5.640925998404486, covariance difference 8.574735644016748, sinkhorn epsilon 0.0\n",
      "Iteration  2075\n",
      "Training: loss 4.601190567016602, covariance difference 1.0115032196044922\n",
      "Validation: loss 5.5552250894036215, covariance difference 8.316378947498297, sinkhorn epsilon 2.4841376025564675e-14\n",
      "Iteration  2076\n",
      "Training: loss 4.515493392944336, covariance difference 0.9969707727432251\n",
      "Validation: loss 5.646671568172758, covariance difference 8.461142299043553, sinkhorn epsilon 0.0\n",
      "Iteration  2077\n",
      "Training: loss 4.606940269470215, covariance difference 1.0137341022491455\n",
      "Validation: loss 5.641894059186622, covariance difference 8.696319713929762, sinkhorn epsilon 0.0\n",
      "Iteration  2078\n",
      "Training: loss 4.602155685424805, covariance difference 1.013013243675232\n",
      "Validation: loss 5.677311359436767, covariance difference 8.619290549281917, sinkhorn epsilon 0.0\n",
      "Iteration  2079\n",
      "Training: loss 4.637578964233398, covariance difference 1.0192177295684814\n",
      "Validation: loss 5.609831977803759, covariance difference 8.500181121824644, sinkhorn epsilon 0.0\n",
      "Iteration  2080\n",
      "Training: loss 4.570099830627441, covariance difference 1.0059620141983032\n",
      "Validation: loss 5.694686008495034, covariance difference 8.574045831582934, sinkhorn epsilon 0.0\n",
      "Iteration  2081\n",
      "Training: loss 4.65495491027832, covariance difference 1.023130178451538\n",
      "Validation: loss 5.609413138699972, covariance difference 8.528495359678312, sinkhorn epsilon 0.0\n",
      "Iteration  2082\n",
      "Training: loss 4.569666862487793, covariance difference 1.0066158771514893\n",
      "Validation: loss 5.661091088410082, covariance difference 8.528994080660368, sinkhorn epsilon 0.0\n",
      "Iteration  2083\n",
      "Training: loss 4.621358871459961, covariance difference 1.0170596837997437\n",
      "Validation: loss 5.673460594126853, covariance difference 8.695953354145415, sinkhorn epsilon 0.0\n",
      "Iteration  2084\n",
      "Training: loss 4.633734226226807, covariance difference 1.0176259279251099\n",
      "Validation: loss 5.618936319121648, covariance difference 8.327903418185844, sinkhorn epsilon 0.0\n",
      "Iteration  2085\n",
      "Training: loss 4.57920503616333, covariance difference 1.0078080892562866\n",
      "Validation: loss 5.672764341200426, covariance difference 8.481281017083552, sinkhorn epsilon 0.0\n",
      "Iteration  2086\n",
      "Training: loss 4.633040904998779, covariance difference 1.018183946609497\n",
      "Validation: loss 5.649874220357257, covariance difference 8.473233780392649, sinkhorn epsilon 0.0\n",
      "Iteration  2087\n",
      "Training: loss 4.610137939453125, covariance difference 1.0148223638534546\n",
      "Validation: loss 5.606104824127826, covariance difference 8.543629343912196, sinkhorn epsilon 0.0\n",
      "Iteration  2088\n",
      "Training: loss 4.566359519958496, covariance difference 1.0056143999099731\n",
      "Validation: loss 5.6766638294315, covariance difference 8.668879693431707, sinkhorn epsilon 0.0\n",
      "Iteration  2089\n",
      "Training: loss 4.636928558349609, covariance difference 1.017472743988037\n",
      "Validation: loss 5.625100894939718, covariance difference 8.468488816107715, sinkhorn epsilon 0.0\n",
      "Iteration  2090\n",
      "Training: loss 4.585369110107422, covariance difference 1.0081424713134766\n",
      "Validation: loss 5.630962940535819, covariance difference 8.758927815565961, sinkhorn epsilon 0.0\n",
      "Iteration  2091\n",
      "Training: loss 4.591230392456055, covariance difference 1.0100234746932983\n",
      "Validation: loss 5.667162478013568, covariance difference 8.757737086757013, sinkhorn epsilon 0.0\n",
      "Iteration  2092\n",
      "Training: loss 4.627426624298096, covariance difference 1.0159367322921753\n",
      "Validation: loss 5.695530393958211, covariance difference 8.619710804871904, sinkhorn epsilon 0.0\n",
      "Iteration  2093\n",
      "Training: loss 4.6557936668396, covariance difference 1.0236481428146362\n",
      "Validation: loss 5.572433659472088, covariance difference 8.59202677082342, sinkhorn epsilon 0.0\n",
      "Iteration  2094\n",
      "Training: loss 4.532698631286621, covariance difference 0.9988497495651245\n",
      "Validation: loss 5.703857980078516, covariance difference 8.372923636370261, sinkhorn epsilon 0.0\n",
      "Iteration  2095\n",
      "Training: loss 4.664127349853516, covariance difference 1.022630214691162\n",
      "Validation: loss 5.69585158151515, covariance difference 8.518649220671369, sinkhorn epsilon 0.0\n",
      "Iteration  2096\n",
      "Training: loss 4.6561198234558105, covariance difference 1.0225023031234741\n",
      "Validation: loss 5.588566184157591, covariance difference 8.340444013225598, sinkhorn epsilon 0.0\n",
      "Iteration  2097\n",
      "Training: loss 4.548830986022949, covariance difference 1.0040879249572754\n",
      "Validation: loss 5.722360489375368, covariance difference 8.698698607509096, sinkhorn epsilon 0.0\n",
      "Iteration  2098\n",
      "Training: loss 4.682628631591797, covariance difference 1.026803731918335\n",
      "Validation: loss 5.668727359361478, covariance difference 8.778923798122316, sinkhorn epsilon 0.0\n",
      "Iteration  2099\n",
      "Training: loss 4.628992080688477, covariance difference 1.0172327756881714\n",
      "Validation: loss 5.698874122127646, covariance difference 8.658884355909995, sinkhorn epsilon 0.0\n",
      "Iteration  2100\n",
      "Training: loss 4.659139633178711, covariance difference 1.0223021507263184\n",
      "Validation: loss 5.663185860180779, covariance difference 8.7396124953679, sinkhorn epsilon 0.0\n",
      "Iteration  2101\n",
      "Training: loss 4.623456954956055, covariance difference 1.0159229040145874\n",
      "Validation: loss 5.609211709802365, covariance difference 8.541388776671852, sinkhorn epsilon 0.0\n",
      "Iteration  2102\n",
      "Training: loss 4.569468975067139, covariance difference 1.0068752765655518\n",
      "Validation: loss 5.675584770862342, covariance difference 8.897931912735437, sinkhorn epsilon 0.0\n",
      "Iteration  2103\n",
      "Training: loss 4.635852336883545, covariance difference 1.0193634033203125\n",
      "Validation: loss 5.66263596235176, covariance difference 8.664594217444142, sinkhorn epsilon 0.0\n",
      "Iteration  2104\n",
      "Training: loss 4.622905731201172, covariance difference 1.0155044794082642\n",
      "Validation: loss 5.705597465530805, covariance difference 8.76658294239642, sinkhorn epsilon 0.0\n",
      "Iteration  2105\n",
      "Training: loss 4.665865898132324, covariance difference 1.023572325706482\n",
      "Validation: loss 5.677492749239486, covariance difference 8.66311522519981, sinkhorn epsilon 0.0\n",
      "Iteration  2106\n",
      "Training: loss 4.637756824493408, covariance difference 1.0176942348480225\n",
      "Validation: loss 5.612130909305535, covariance difference 8.427569203402477, sinkhorn epsilon 0.0\n",
      "Iteration  2107\n",
      "Training: loss 4.572399616241455, covariance difference 1.0051463842391968\n",
      "Validation: loss 5.6172635005146, covariance difference 8.47635670926545, sinkhorn epsilon 0.0\n",
      "Iteration  2108\n",
      "Training: loss 4.577531814575195, covariance difference 1.0077933073043823\n",
      "Validation: loss 5.712576302432199, covariance difference 8.649448301284476, sinkhorn epsilon 4.323504023259738e-14\n",
      "Iteration  2109\n",
      "Training: loss 4.672845840454102, covariance difference 1.0252196788787842\n",
      "Validation: loss 5.6280632259415455, covariance difference 8.50306262237484, sinkhorn epsilon 0.0\n",
      "Iteration  2110\n",
      "Training: loss 4.58833122253418, covariance difference 1.01121187210083\n",
      "Validation: loss 5.652821012930858, covariance difference 8.753053506390325, sinkhorn epsilon 0.0\n",
      "Iteration  2111\n",
      "Training: loss 4.61308479309082, covariance difference 1.0164874792099\n",
      "Validation: loss 5.686300182971265, covariance difference 8.702688013888515, sinkhorn epsilon 0.0\n",
      "Iteration  2112\n",
      "Training: loss 4.646568775177002, covariance difference 1.019689679145813\n",
      "Validation: loss 5.534688117256122, covariance difference 8.192361515629306, sinkhorn epsilon 0.0\n",
      "Iteration  2113\n",
      "Training: loss 4.494956970214844, covariance difference 0.9937065839767456\n",
      "Validation: loss 5.743253140209267, covariance difference 8.78818681604713, sinkhorn epsilon 4.740660754688327e-14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  2114\n",
      "Training: loss 4.703524589538574, covariance difference 1.0325095653533936\n",
      "Validation: loss 5.669713250961384, covariance difference 8.585662035084624, sinkhorn epsilon 0.0\n",
      "Iteration  2115\n",
      "Training: loss 4.629981994628906, covariance difference 1.0165506601333618\n",
      "Validation: loss 5.651692734377417, covariance difference 8.626755172835239, sinkhorn epsilon 4.914654212295544e-14\n",
      "Iteration  2116\n",
      "Training: loss 4.611964702606201, covariance difference 1.0151039361953735\n",
      "Validation: loss 5.631548938982802, covariance difference 8.791209181330437, sinkhorn epsilon 0.0\n",
      "Iteration  2117\n",
      "Training: loss 4.591817378997803, covariance difference 1.0096925497055054\n",
      "Validation: loss 5.696200100989314, covariance difference 8.458010909499723, sinkhorn epsilon 0.0\n",
      "Iteration  2118\n",
      "Training: loss 4.656467914581299, covariance difference 1.0224149227142334\n",
      "Validation: loss 5.7216347413500594, covariance difference 8.860165500519988, sinkhorn epsilon 0.0\n",
      "Iteration  2119\n",
      "Training: loss 4.681899070739746, covariance difference 1.024619698524475\n",
      "Validation: loss 5.587209493715795, covariance difference 8.269657187762851, sinkhorn epsilon 0.0\n",
      "Iteration  2120\n",
      "Training: loss 4.547478199005127, covariance difference 1.002274513244629\n",
      "Validation: loss 5.58217885796894, covariance difference 8.452030657918389, sinkhorn epsilon 0.0\n",
      "Iteration  2121\n",
      "Training: loss 4.54243278503418, covariance difference 1.0006568431854248\n",
      "Validation: loss 5.752500541361351, covariance difference 8.575677010487897, sinkhorn epsilon 0.0\n",
      "Iteration  2122\n",
      "Training: loss 4.712764739990234, covariance difference 1.0317496061325073\n",
      "Validation: loss 5.695713307632743, covariance difference 8.692035278163337, sinkhorn epsilon 0.0\n",
      "Iteration  2123\n",
      "Training: loss 4.655971527099609, covariance difference 1.0213515758514404\n",
      "Validation: loss 5.731203296850139, covariance difference 8.65568442132827, sinkhorn epsilon 0.0\n",
      "Iteration  2124\n",
      "Training: loss 4.691457748413086, covariance difference 1.0292047262191772\n",
      "Validation: loss 5.63848512092098, covariance difference 8.617664609539188, sinkhorn epsilon 0.0\n",
      "Iteration  2125\n",
      "Training: loss 4.598750114440918, covariance difference 1.012033462524414\n",
      "Validation: loss 5.6868666463764495, covariance difference 8.7616672347125, sinkhorn epsilon 2.912894444417409e-14\n",
      "Iteration  2126\n",
      "Training: loss 4.647136688232422, covariance difference 1.0203816890716553\n",
      "Validation: loss 5.6788452850801, covariance difference 8.48335309837722, sinkhorn epsilon 0.0\n",
      "Iteration  2127\n",
      "Training: loss 4.639115333557129, covariance difference 1.0172237157821655\n",
      "Validation: loss 5.747134889357151, covariance difference 8.767092435646854, sinkhorn epsilon 0.0\n",
      "Iteration  2128\n",
      "Training: loss 4.707399368286133, covariance difference 1.0315409898757935\n",
      "Validation: loss 5.705778738179845, covariance difference 8.642875728773253, sinkhorn epsilon 0.0\n",
      "Iteration  2129\n",
      "Training: loss 4.666049003601074, covariance difference 1.0241832733154297\n",
      "Validation: loss 5.651677787476253, covariance difference 8.602257361207732, sinkhorn epsilon 0.0\n",
      "Iteration  2130\n",
      "Training: loss 4.611948013305664, covariance difference 1.0138911008834839\n",
      "Validation: loss 5.691949666909501, covariance difference 8.714004804896197, sinkhorn epsilon 0.0\n",
      "Iteration  2131\n",
      "Training: loss 4.6522135734558105, covariance difference 1.022085428237915\n",
      "Validation: loss 5.660403663735205, covariance difference 8.669601150462443, sinkhorn epsilon 0.0\n",
      "Iteration  2132\n",
      "Training: loss 4.620668411254883, covariance difference 1.0164684057235718\n",
      "Validation: loss 5.654093009997503, covariance difference 8.432647802187482, sinkhorn epsilon 0.0\n",
      "Iteration  2133\n",
      "Training: loss 4.614360332489014, covariance difference 1.0163767337799072\n",
      "Validation: loss 5.5909783249318945, covariance difference 8.638821021530942, sinkhorn epsilon 0.0\n",
      "Iteration  2134\n",
      "Training: loss 4.55124568939209, covariance difference 1.002866506576538\n",
      "Validation: loss 5.645232648293556, covariance difference 8.611089958663774, sinkhorn epsilon 0.0\n",
      "Iteration  2135\n",
      "Training: loss 4.605497360229492, covariance difference 1.0140883922576904\n",
      "Validation: loss 5.619621112272655, covariance difference 8.443376135127153, sinkhorn epsilon 0.0\n",
      "Iteration  2136\n",
      "Training: loss 4.579889297485352, covariance difference 1.0071996450424194\n",
      "Validation: loss 5.691249945992491, covariance difference 8.520318318641927, sinkhorn epsilon 0.0\n",
      "Iteration  2137\n",
      "Training: loss 4.6515092849731445, covariance difference 1.0215849876403809\n",
      "Validation: loss 5.669806725892827, covariance difference 8.679987471407413, sinkhorn epsilon 0.0\n",
      "Iteration  2138\n",
      "Training: loss 4.630070686340332, covariance difference 1.0184502601623535\n",
      "Validation: loss 5.53670799550258, covariance difference 8.280514356686469, sinkhorn epsilon 0.0\n",
      "Iteration  2139\n",
      "Training: loss 4.496972560882568, covariance difference 0.9930205345153809\n",
      "Validation: loss 5.637279312519958, covariance difference 8.443615634827395, sinkhorn epsilon 0.0\n",
      "Iteration  2140\n",
      "Training: loss 4.597544193267822, covariance difference 1.0116750001907349\n",
      "Validation: loss 5.673069699488051, covariance difference 8.618027386844764, sinkhorn epsilon 0.0\n",
      "Iteration  2141\n",
      "Training: loss 4.633334636688232, covariance difference 1.0171592235565186\n",
      "Validation: loss 5.666035514626237, covariance difference 8.622811953085865, sinkhorn epsilon 5.797101100366064e-14\n",
      "Iteration  2142\n",
      "Training: loss 4.626308917999268, covariance difference 1.0174157619476318\n",
      "Validation: loss 5.682489796605834, covariance difference 8.475694459329242, sinkhorn epsilon 0.0\n",
      "Iteration  2143\n",
      "Training: loss 4.642753601074219, covariance difference 1.0227493047714233\n",
      "Validation: loss 5.6770859094398, covariance difference 8.835722885702852, sinkhorn epsilon 0.0\n",
      "Iteration  2144\n",
      "Training: loss 4.637353897094727, covariance difference 1.0189632177352905\n",
      "Validation: loss 5.698590130096019, covariance difference 8.653237469277258, sinkhorn epsilon 0.0\n",
      "Iteration  2145\n",
      "Training: loss 4.658858299255371, covariance difference 1.022037386894226\n",
      "Validation: loss 5.6886258295587115, covariance difference 8.557640297679846, sinkhorn epsilon 0.0\n",
      "Iteration  2146\n",
      "Training: loss 4.648894309997559, covariance difference 1.0215075016021729\n",
      "Validation: loss 5.653354606121324, covariance difference 8.708203657898899, sinkhorn epsilon 0.0\n",
      "Iteration  2147\n",
      "Training: loss 4.613619327545166, covariance difference 1.014731764793396\n",
      "Validation: loss 5.6115332888267435, covariance difference 8.428709931118075, sinkhorn epsilon 0.0\n",
      "Iteration  2148\n",
      "Training: loss 4.57180643081665, covariance difference 1.006672978401184\n",
      "Validation: loss 5.686197492229691, covariance difference 8.454384675921952, sinkhorn epsilon 0.0\n",
      "Iteration  2149\n",
      "Training: loss 4.646469593048096, covariance difference 1.0200886726379395\n",
      "Validation: loss 5.651904053875454, covariance difference 8.585561041361824, sinkhorn epsilon 0.0\n",
      "Iteration  2150\n",
      "Training: loss 4.61217737197876, covariance difference 1.0151859521865845\n",
      "Validation: loss 5.605173892610375, covariance difference 8.399154106146282, sinkhorn epsilon 0.0\n",
      "Iteration  2151\n",
      "Training: loss 4.565447807312012, covariance difference 1.0040572881698608\n",
      "Validation: loss 5.653571796102042, covariance difference 8.49803680657638, sinkhorn epsilon 0.0\n",
      "Iteration  2152\n",
      "Training: loss 4.613836288452148, covariance difference 1.015975832939148\n",
      "Validation: loss 5.664867780653227, covariance difference 8.580895119988009, sinkhorn epsilon 0.0\n",
      "Iteration  2153\n",
      "Training: loss 4.625136852264404, covariance difference 1.014838695526123\n",
      "Validation: loss 5.676147455084002, covariance difference 8.483625592498965, sinkhorn epsilon 0.0\n",
      "Iteration  2154\n",
      "Training: loss 4.636410713195801, covariance difference 1.0182667970657349\n",
      "Validation: loss 5.5929883148717146, covariance difference 8.400092229246473, sinkhorn epsilon 0.0\n",
      "Iteration  2155\n",
      "Training: loss 4.553252696990967, covariance difference 1.0011954307556152\n",
      "Validation: loss 5.649781999685905, covariance difference 8.652676701266508, sinkhorn epsilon 0.0\n",
      "Iteration  2156\n",
      "Training: loss 4.610034942626953, covariance difference 1.0131418704986572\n",
      "Validation: loss 5.633513972823151, covariance difference 8.517238608553427, sinkhorn epsilon 0.0\n",
      "Iteration  2157\n",
      "Training: loss 4.593778610229492, covariance difference 1.0111966133117676\n",
      "Validation: loss 5.627273803793632, covariance difference 8.32105802691871, sinkhorn epsilon 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  2158\n",
      "Training: loss 4.587543487548828, covariance difference 1.009914755821228\n",
      "Validation: loss 5.729033418665715, covariance difference 8.70100883038233, sinkhorn epsilon 0.0\n",
      "Iteration  2159\n",
      "Training: loss 4.689301490783691, covariance difference 1.0259236097335815\n",
      "Validation: loss 5.612957026048875, covariance difference 8.739695027059364, sinkhorn epsilon 0.0\n",
      "Iteration  2160\n",
      "Training: loss 4.573221206665039, covariance difference 1.0058759450912476\n",
      "Validation: loss 5.632811771677036, covariance difference 8.651565412387734, sinkhorn epsilon 0.0\n",
      "Iteration  2161\n",
      "Training: loss 4.593076229095459, covariance difference 1.0101951360702515\n",
      "Validation: loss 5.606061665344297, covariance difference 8.597200337055172, sinkhorn epsilon 0.0\n",
      "Iteration  2162\n",
      "Training: loss 4.5663299560546875, covariance difference 1.0070539712905884\n",
      "Validation: loss 5.654862063168791, covariance difference 8.442350362588153, sinkhorn epsilon 0.0\n",
      "Iteration  2163\n",
      "Training: loss 4.615126132965088, covariance difference 1.0140198469161987\n",
      "Validation: loss 5.694507164954242, covariance difference 8.567120860584312, sinkhorn epsilon 0.0\n",
      "Iteration  2164\n",
      "Training: loss 4.654771327972412, covariance difference 1.019628643989563\n",
      "Validation: loss 5.623089647679656, covariance difference 8.478745275721382, sinkhorn epsilon 0.0\n",
      "Iteration  2165\n",
      "Training: loss 4.583346366882324, covariance difference 1.0101441144943237\n",
      "Validation: loss 5.618732537787999, covariance difference 8.530660696064329, sinkhorn epsilon 0.0\n",
      "Iteration  2166\n",
      "Training: loss 4.579001426696777, covariance difference 1.0081708431243896\n",
      "Validation: loss 5.721708825045852, covariance difference 8.622726899685869, sinkhorn epsilon 0.0\n",
      "Iteration  2167\n",
      "Training: loss 4.681976318359375, covariance difference 1.0258902311325073\n",
      "Validation: loss 5.724728654706712, covariance difference 8.921298991932074, sinkhorn epsilon 0.0\n",
      "Iteration  2168\n",
      "Training: loss 4.684990882873535, covariance difference 1.0262084007263184\n",
      "Validation: loss 5.652638456163021, covariance difference 8.657980997575638, sinkhorn epsilon 0.0\n",
      "Iteration  2169\n",
      "Training: loss 4.612902641296387, covariance difference 1.0148646831512451\n",
      "Validation: loss 5.655965029211663, covariance difference 8.621684595656372, sinkhorn epsilon 0.0\n",
      "Iteration  2170\n",
      "Training: loss 4.616218566894531, covariance difference 1.0162492990493774\n",
      "Validation: loss 5.630912605906283, covariance difference 8.598649272680797, sinkhorn epsilon 0.0\n",
      "Iteration  2171\n",
      "Training: loss 4.591166973114014, covariance difference 1.0091869831085205\n",
      "Validation: loss 5.5519106141821695, covariance difference 8.617149842495644, sinkhorn epsilon 0.0\n",
      "Iteration  2172\n",
      "Training: loss 4.512174606323242, covariance difference 0.9971686601638794\n",
      "Validation: loss 5.6625372320961365, covariance difference 8.787852718520584, sinkhorn epsilon 0.0\n",
      "Iteration  2173\n",
      "Training: loss 4.622790813446045, covariance difference 1.0167709589004517\n",
      "Validation: loss 5.610030705733997, covariance difference 8.62332476151154, sinkhorn epsilon 0.0\n",
      "Iteration  2174\n",
      "Training: loss 4.570298671722412, covariance difference 1.0074659585952759\n",
      "Validation: loss 5.6010732248749715, covariance difference 8.69881717395189, sinkhorn epsilon 5.687800306064578e-14\n",
      "Iteration  2175\n",
      "Training: loss 4.561336517333984, covariance difference 1.003773808479309\n",
      "Validation: loss 5.647756065189398, covariance difference 8.590429023791636, sinkhorn epsilon 0.0\n",
      "Iteration  2176\n",
      "Training: loss 4.608020305633545, covariance difference 1.0116980075836182\n",
      "Validation: loss 5.708990101542394, covariance difference 8.809980377991268, sinkhorn epsilon 0.0\n",
      "Iteration  2177\n",
      "Training: loss 4.669261455535889, covariance difference 1.0237352848052979\n",
      "Validation: loss 5.621957038311436, covariance difference 8.57660687276898, sinkhorn epsilon 0.0\n",
      "Iteration  2178\n",
      "Training: loss 4.582221508026123, covariance difference 1.0087428092956543\n",
      "Validation: loss 5.638553845373174, covariance difference 8.437550458117553, sinkhorn epsilon 0.0\n",
      "Iteration  2179\n",
      "Training: loss 4.598826885223389, covariance difference 1.0123648643493652\n",
      "Validation: loss 5.704123393113853, covariance difference 8.550334713517948, sinkhorn epsilon 0.0\n",
      "Iteration  2180\n",
      "Training: loss 4.664393424987793, covariance difference 1.0250535011291504\n",
      "Validation: loss 5.637957959007909, covariance difference 8.630872080641824, sinkhorn epsilon 0.0\n",
      "Iteration  2181\n",
      "Training: loss 4.598229885101318, covariance difference 1.0126928091049194\n",
      "Validation: loss 5.605101642840415, covariance difference 8.473114667231613, sinkhorn epsilon 0.0\n",
      "Iteration  2182\n",
      "Training: loss 4.565366268157959, covariance difference 1.0037790536880493\n",
      "Validation: loss 5.582865828060721, covariance difference 8.49187601498168, sinkhorn epsilon 0.0\n",
      "Iteration  2183\n",
      "Training: loss 4.543120384216309, covariance difference 1.0044031143188477\n",
      "Validation: loss 5.751196650270901, covariance difference 8.903972868244942, sinkhorn epsilon 0.0\n",
      "Iteration  2184\n",
      "Training: loss 4.711460590362549, covariance difference 1.032942533493042\n",
      "Validation: loss 5.727748455253586, covariance difference 8.768178533178899, sinkhorn epsilon 2.6965537335103587e-14\n",
      "Iteration  2185\n",
      "Training: loss 4.688016414642334, covariance difference 1.0278488397598267\n",
      "Validation: loss 5.6561101853060265, covariance difference 8.74729382846496, sinkhorn epsilon 5.5186904570209916e-14\n",
      "Iteration  2186\n",
      "Training: loss 4.6163811683654785, covariance difference 1.0132629871368408\n",
      "Validation: loss 5.65682766812687, covariance difference 8.536008021461162, sinkhorn epsilon 0.0\n",
      "Iteration  2187\n",
      "Training: loss 4.61710262298584, covariance difference 1.0141377449035645\n",
      "Validation: loss 5.6495462984725675, covariance difference 8.770710612678123, sinkhorn epsilon 0.0\n",
      "Iteration  2188\n",
      "Training: loss 4.609813690185547, covariance difference 1.0141894817352295\n",
      "Validation: loss 5.6360604622802954, covariance difference 8.599094979464978, sinkhorn epsilon 0.0\n",
      "Iteration  2189\n",
      "Training: loss 4.596329689025879, covariance difference 1.0090128183364868\n",
      "Validation: loss 5.630430811497498, covariance difference 8.505376922650036, sinkhorn epsilon 0.0\n",
      "Iteration  2190\n",
      "Training: loss 4.590695381164551, covariance difference 1.0106507539749146\n",
      "Validation: loss 5.680994889090241, covariance difference 8.619006889372145, sinkhorn epsilon 0.0\n",
      "Iteration  2191\n",
      "Training: loss 4.64125919342041, covariance difference 1.0210517644882202\n",
      "Validation: loss 5.569387415479499, covariance difference 8.647788035963535, sinkhorn epsilon 0.0\n",
      "Iteration  2192\n",
      "Training: loss 4.529655933380127, covariance difference 1.0007097721099854\n",
      "Validation: loss 5.656217154807883, covariance difference 8.49237367229877, sinkhorn epsilon 0.0\n",
      "Iteration  2193\n",
      "Training: loss 4.616484642028809, covariance difference 1.0160547494888306\n",
      "Validation: loss 5.667425361738909, covariance difference 8.525324620935752, sinkhorn epsilon 0.0\n",
      "Iteration  2194\n",
      "Training: loss 4.627697467803955, covariance difference 1.0182145833969116\n",
      "Validation: loss 5.659771591400668, covariance difference 8.641929031278693, sinkhorn epsilon 0.0\n",
      "Iteration  2195\n",
      "Training: loss 4.620048999786377, covariance difference 1.0158483982086182\n",
      "Validation: loss 5.60434491864861, covariance difference 8.296640875808004, sinkhorn epsilon 0.0\n",
      "Iteration  2196\n",
      "Training: loss 4.564609527587891, covariance difference 1.0062652826309204\n",
      "Validation: loss 5.660548253730374, covariance difference 8.597068266490886, sinkhorn epsilon 0.0\n",
      "Iteration  2197\n",
      "Training: loss 4.620812892913818, covariance difference 1.0157450437545776\n",
      "Validation: loss 5.594895109106139, covariance difference 8.54220538241904, sinkhorn epsilon 0.0\n",
      "Iteration  2198\n",
      "Training: loss 4.555163383483887, covariance difference 1.0035923719406128\n",
      "Validation: loss 5.664644248330849, covariance difference 8.597725169489044, sinkhorn epsilon 0.0\n",
      "Iteration  2199\n",
      "Training: loss 4.624908447265625, covariance difference 1.0171130895614624\n",
      "Validation: loss 5.674098859129931, covariance difference 8.803098760495871, sinkhorn epsilon 0.0\n",
      "Iteration  2200\n",
      "Training: loss 4.634364128112793, covariance difference 1.0183203220367432\n",
      "Validation: loss 5.65664157675788, covariance difference 8.635883787039099, sinkhorn epsilon 0.0\n",
      "Iteration  2201\n",
      "Training: loss 4.616906642913818, covariance difference 1.0148069858551025\n",
      "Validation: loss 5.624427596196622, covariance difference 8.652101428584857, sinkhorn epsilon 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  2202\n",
      "Training: loss 4.584681510925293, covariance difference 1.0080007314682007\n",
      "Validation: loss 5.625427544158638, covariance difference 8.5586774973143, sinkhorn epsilon 0.0\n",
      "Iteration  2203\n",
      "Training: loss 4.585691452026367, covariance difference 1.0111452341079712\n",
      "Validation: loss 5.6479631489113356, covariance difference 8.769545240579964, sinkhorn epsilon 0.0\n",
      "Iteration  2204\n",
      "Training: loss 4.608226776123047, covariance difference 1.0133062601089478\n",
      "Validation: loss 5.590695626291115, covariance difference 8.491242836833996, sinkhorn epsilon 0.0\n",
      "Iteration  2205\n",
      "Training: loss 4.550960063934326, covariance difference 1.0033609867095947\n",
      "Validation: loss 5.607639337799325, covariance difference 8.627540393371476, sinkhorn epsilon 0.0\n",
      "Iteration  2206\n",
      "Training: loss 4.567903995513916, covariance difference 1.0060089826583862\n",
      "Validation: loss 5.6723431065796, covariance difference 8.824282359140808, sinkhorn epsilon 0.0\n",
      "Iteration  2207\n",
      "Training: loss 4.6326069831848145, covariance difference 1.0183240175247192\n",
      "Validation: loss 5.66888974735043, covariance difference 8.70377070378267, sinkhorn epsilon 0.0\n",
      "Iteration  2208\n",
      "Training: loss 4.629153728485107, covariance difference 1.0169466733932495\n",
      "Validation: loss 5.681867832053562, covariance difference 8.678862775028184, sinkhorn epsilon 0.0\n",
      "Iteration  2209\n",
      "Training: loss 4.642129421234131, covariance difference 1.0188788175582886\n",
      "Validation: loss 5.640746785216858, covariance difference 8.487531182265004, sinkhorn epsilon 0.0\n",
      "Iteration  2210\n",
      "Training: loss 4.601010799407959, covariance difference 1.0120832920074463\n",
      "Validation: loss 5.703182765637675, covariance difference 8.600484589206447, sinkhorn epsilon 0.0\n",
      "Iteration  2211\n",
      "Training: loss 4.66344690322876, covariance difference 1.0225188732147217\n",
      "Validation: loss 5.593607909997872, covariance difference 8.40231839657957, sinkhorn epsilon 5.3401116433510394e-14\n",
      "Iteration  2212\n",
      "Training: loss 4.553876876831055, covariance difference 1.00211763381958\n",
      "Validation: loss 5.600130051095668, covariance difference 8.419183088195792, sinkhorn epsilon 0.0\n",
      "Iteration  2213\n",
      "Training: loss 4.5603928565979, covariance difference 1.005501627922058\n",
      "Validation: loss 5.681795295862555, covariance difference 8.687537877231716, sinkhorn epsilon 0.0\n",
      "Iteration  2214\n",
      "Training: loss 4.6420488357543945, covariance difference 1.0199109315872192\n",
      "Validation: loss 5.670306238472208, covariance difference 8.483044484620494, sinkhorn epsilon 0.0\n",
      "Iteration  2215\n",
      "Training: loss 4.630569934844971, covariance difference 1.0173784494400024\n",
      "Validation: loss 5.619367582208031, covariance difference 8.611016594445072, sinkhorn epsilon 0.0\n",
      "Iteration  2216\n",
      "Training: loss 4.579631805419922, covariance difference 1.0088601112365723\n",
      "Validation: loss 5.577530986139906, covariance difference 8.229698377982851, sinkhorn epsilon 0.0\n",
      "Iteration  2217\n",
      "Training: loss 4.537799835205078, covariance difference 1.0017204284667969\n",
      "Validation: loss 5.7008556039971605, covariance difference 8.6624274393071, sinkhorn epsilon 0.0\n",
      "Iteration  2218\n",
      "Training: loss 4.661128997802734, covariance difference 1.0220398902893066\n",
      "Validation: loss 5.654140536682281, covariance difference 8.660088681120335, sinkhorn epsilon 0.0\n",
      "Iteration  2219\n",
      "Training: loss 4.614404678344727, covariance difference 1.0161166191101074\n",
      "Validation: loss 5.626010743115369, covariance difference 8.717747076879332, sinkhorn epsilon 0.0\n",
      "Iteration  2220\n",
      "Training: loss 4.586280345916748, covariance difference 1.0105911493301392\n",
      "Validation: loss 5.660019943287601, covariance difference 8.577904946282692, sinkhorn epsilon 0.0\n",
      "Iteration  2221\n",
      "Training: loss 4.620293617248535, covariance difference 1.015891194343567\n",
      "Validation: loss 5.704779606933544, covariance difference 8.484287368285734, sinkhorn epsilon 0.0\n",
      "Iteration  2222\n",
      "Training: loss 4.665049076080322, covariance difference 1.02135169506073\n",
      "Validation: loss 5.720211238367891, covariance difference 8.847657446093617, sinkhorn epsilon 0.0\n",
      "Iteration  2223\n",
      "Training: loss 4.680475234985352, covariance difference 1.0262147188186646\n",
      "Validation: loss 5.6538533237499395, covariance difference 8.4507907318384, sinkhorn epsilon 0.0\n",
      "Iteration  2224\n",
      "Training: loss 4.6141228675842285, covariance difference 1.014316439628601\n",
      "Validation: loss 5.674467944582555, covariance difference 8.644575207821001, sinkhorn epsilon 0.0\n",
      "Iteration  2225\n",
      "Training: loss 4.634736061096191, covariance difference 1.0192707777023315\n",
      "Validation: loss 5.687670143575019, covariance difference 8.494747617384522, sinkhorn epsilon 0.0\n",
      "Iteration  2226\n",
      "Training: loss 4.647937774658203, covariance difference 1.0208706855773926\n",
      "Validation: loss 5.686352375154879, covariance difference 8.877368923093552, sinkhorn epsilon 0.0\n",
      "Iteration  2227\n",
      "Training: loss 4.646622657775879, covariance difference 1.0192710161209106\n",
      "Validation: loss 5.635019168156244, covariance difference 8.433991885460573, sinkhorn epsilon 0.0\n",
      "Iteration  2228\n",
      "Training: loss 4.595286846160889, covariance difference 1.010162115097046\n",
      "Validation: loss 5.6734895906645155, covariance difference 8.772630526219263, sinkhorn epsilon 0.0\n",
      "Iteration  2229\n",
      "Training: loss 4.633758544921875, covariance difference 1.0181254148483276\n",
      "Validation: loss 5.780976261526106, covariance difference 8.753220932755852, sinkhorn epsilon 0.0\n",
      "Iteration  2230\n",
      "Training: loss 4.741250038146973, covariance difference 1.0370416641235352\n",
      "Validation: loss 5.620824582136404, covariance difference 8.688322679315556, sinkhorn epsilon 0.0\n",
      "Iteration  2231\n",
      "Training: loss 4.5810933113098145, covariance difference 1.0088410377502441\n",
      "Validation: loss 5.595738876169645, covariance difference 8.656543481226993, sinkhorn epsilon 0.0\n",
      "Iteration  2232\n",
      "Training: loss 4.5560078620910645, covariance difference 1.0044554471969604\n",
      "Validation: loss 5.577684063292366, covariance difference 8.429792552109689, sinkhorn epsilon 0.0\n",
      "Iteration  2233\n",
      "Training: loss 4.5379533767700195, covariance difference 1.0010647773742676\n",
      "Validation: loss 5.649449093863444, covariance difference 8.639492757705137, sinkhorn epsilon 0.0\n",
      "Iteration  2234\n",
      "Training: loss 4.609717845916748, covariance difference 1.014093041419983\n",
      "Validation: loss 5.59094956849892, covariance difference 8.528127893204184, sinkhorn epsilon 0.0\n",
      "Iteration  2235\n",
      "Training: loss 4.551204681396484, covariance difference 1.0031379461288452\n",
      "Validation: loss 5.617080160974617, covariance difference 8.617740306567915, sinkhorn epsilon 0.0\n",
      "Iteration  2236\n",
      "Training: loss 4.577348709106445, covariance difference 1.0074717998504639\n",
      "Validation: loss 5.603414488173293, covariance difference 8.59354103943214, sinkhorn epsilon 0.0\n",
      "Iteration  2237\n",
      "Training: loss 4.563678741455078, covariance difference 1.003989577293396\n",
      "Validation: loss 5.692953775587093, covariance difference 8.734467538903964, sinkhorn epsilon 0.0\n",
      "Iteration  2238\n",
      "Training: loss 4.6532182693481445, covariance difference 1.0217605829238892\n",
      "Validation: loss 5.609416339486822, covariance difference 8.436986671553065, sinkhorn epsilon 0.0\n",
      "Iteration  2239\n",
      "Training: loss 4.569681167602539, covariance difference 1.0069589614868164\n",
      "Validation: loss 5.584083287120024, covariance difference 8.56768616169783, sinkhorn epsilon 0.0\n",
      "Iteration  2240\n",
      "Training: loss 4.544352054595947, covariance difference 1.0034496784210205\n",
      "Validation: loss 5.662012386078479, covariance difference 8.63342427636137, sinkhorn epsilon 0.0\n",
      "Iteration  2241\n",
      "Training: loss 4.622280120849609, covariance difference 1.016020655632019\n",
      "Validation: loss 5.730346993704823, covariance difference 9.109764462258102, sinkhorn epsilon 0.0\n",
      "Iteration  2242\n",
      "Training: loss 4.690601348876953, covariance difference 1.0280591249465942\n",
      "Validation: loss 5.649596893352471, covariance difference 8.647108905977698, sinkhorn epsilon 9.849277360992829e-14\n",
      "Iteration  2243\n",
      "Training: loss 4.609865188598633, covariance difference 1.01341712474823\n",
      "Validation: loss 5.676587119452145, covariance difference 8.80536580526524, sinkhorn epsilon 0.0\n",
      "Iteration  2244\n",
      "Training: loss 4.636855125427246, covariance difference 1.0198278427124023\n",
      "Validation: loss 5.624286348595071, covariance difference 8.628993315338693, sinkhorn epsilon 0.0\n",
      "Iteration  2245\n",
      "Training: loss 4.58455753326416, covariance difference 1.0085976123809814\n",
      "Validation: loss 5.647206224554241, covariance difference 8.763081220803983, sinkhorn epsilon 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  2246\n",
      "Training: loss 4.607470512390137, covariance difference 1.0130618810653687\n",
      "Validation: loss 5.66420961192923, covariance difference 8.611176928866874, sinkhorn epsilon 0.0\n",
      "Iteration  2247\n",
      "Training: loss 4.624477863311768, covariance difference 1.0183594226837158\n",
      "Validation: loss 5.596709780400095, covariance difference 8.584411483188331, sinkhorn epsilon 0.0\n",
      "Iteration  2248\n",
      "Training: loss 4.556977272033691, covariance difference 1.0023531913757324\n",
      "Validation: loss 5.528423418532751, covariance difference 8.455594215313468, sinkhorn epsilon 0.0\n",
      "Iteration  2249\n",
      "Training: loss 4.488691329956055, covariance difference 0.9910328388214111\n",
      "Validation: loss 5.676442548169385, covariance difference 8.789643156133327, sinkhorn epsilon 0.0\n",
      "Iteration  2250\n",
      "Training: loss 4.636706352233887, covariance difference 1.017971396446228\n",
      "Validation: loss 5.6812613427864225, covariance difference 8.572875586453456, sinkhorn epsilon 0.0\n",
      "Iteration  2251\n",
      "Training: loss 4.641529083251953, covariance difference 1.0221577882766724\n",
      "Validation: loss 5.596688910555595, covariance difference 8.535751834252778, sinkhorn epsilon 0.0\n",
      "Iteration  2252\n",
      "Training: loss 4.556958198547363, covariance difference 1.0047307014465332\n",
      "Validation: loss 5.674278253897009, covariance difference 8.785998764282503, sinkhorn epsilon 0.0\n",
      "Iteration  2253\n",
      "Training: loss 4.634542465209961, covariance difference 1.0169906616210938\n",
      "Validation: loss 5.672054214075765, covariance difference 8.602109714415608, sinkhorn epsilon 0.0\n",
      "Iteration  2254\n",
      "Training: loss 4.632321834564209, covariance difference 1.0182199478149414\n",
      "Validation: loss 5.614804557770372, covariance difference 8.470566449579326, sinkhorn epsilon 0.0\n",
      "Iteration  2255\n",
      "Training: loss 4.575077056884766, covariance difference 1.0083913803100586\n",
      "Validation: loss 5.643526379072225, covariance difference 8.773496015788316, sinkhorn epsilon 0.0\n",
      "Iteration  2256\n",
      "Training: loss 4.603795051574707, covariance difference 1.014926791191101\n",
      "Validation: loss 5.696647877393915, covariance difference 8.421387969336788, sinkhorn epsilon 0.0\n",
      "Iteration  2257\n",
      "Training: loss 4.656917572021484, covariance difference 1.0218175649642944\n",
      "Validation: loss 5.625287063090791, covariance difference 8.663386941103038, sinkhorn epsilon 0.0\n",
      "Iteration  2258\n",
      "Training: loss 4.585555553436279, covariance difference 1.008254051208496\n",
      "Validation: loss 5.638471215951442, covariance difference 8.668400327885728, sinkhorn epsilon 0.0\n",
      "Iteration  2259\n",
      "Training: loss 4.598739147186279, covariance difference 1.0122346878051758\n",
      "Validation: loss 5.617699885632934, covariance difference 8.470322636396297, sinkhorn epsilon 0.0\n",
      "Iteration  2260\n",
      "Training: loss 4.577969551086426, covariance difference 1.0090457201004028\n",
      "Validation: loss 5.71030541327661, covariance difference 8.705667650724813, sinkhorn epsilon 0.0\n",
      "Iteration  2261\n",
      "Training: loss 4.670575141906738, covariance difference 1.0246182680130005\n",
      "Validation: loss 5.682786152796371, covariance difference 8.68058313612543, sinkhorn epsilon 0.0\n",
      "Iteration  2262\n",
      "Training: loss 4.643054962158203, covariance difference 1.0207560062408447\n",
      "Validation: loss 5.64543548086687, covariance difference 8.780179379771374, sinkhorn epsilon 0.0\n",
      "Iteration  2263\n",
      "Training: loss 4.605703830718994, covariance difference 1.0128438472747803\n",
      "Validation: loss 5.700602151195043, covariance difference 8.49290780525175, sinkhorn epsilon 0.0\n",
      "Iteration  2264\n",
      "Training: loss 4.6608662605285645, covariance difference 1.02152681350708\n",
      "Validation: loss 5.695566885443972, covariance difference 8.643998801911899, sinkhorn epsilon 0.0\n",
      "Iteration  2265\n",
      "Training: loss 4.6558308601379395, covariance difference 1.0215376615524292\n",
      "Validation: loss 5.631183244004509, covariance difference 8.637820028318108, sinkhorn epsilon 0.0\n",
      "Iteration  2266\n",
      "Training: loss 4.591452598571777, covariance difference 1.0113476514816284\n",
      "Validation: loss 5.673055426055401, covariance difference 8.733846007914636, sinkhorn epsilon 0.0\n",
      "Iteration  2267\n",
      "Training: loss 4.633319854736328, covariance difference 1.0179765224456787\n",
      "Validation: loss 5.661201974869236, covariance difference 8.769752285938305, sinkhorn epsilon 0.0\n",
      "Iteration  2268\n",
      "Training: loss 4.621469497680664, covariance difference 1.0155211687088013\n",
      "Validation: loss 5.636161177696712, covariance difference 8.499836927486594, sinkhorn epsilon 0.0\n",
      "Iteration  2269\n",
      "Training: loss 4.5964250564575195, covariance difference 1.012042760848999\n",
      "Validation: loss 5.694979938420241, covariance difference 8.563583664372315, sinkhorn epsilon 0.0\n",
      "Iteration  2270\n",
      "Training: loss 4.655233383178711, covariance difference 1.0212136507034302\n",
      "Validation: loss 5.6224254237536, covariance difference 8.749310474894877, sinkhorn epsilon 0.0\n",
      "Iteration  2271\n",
      "Training: loss 4.5826897621154785, covariance difference 1.0099546909332275\n",
      "Validation: loss 5.610333664715281, covariance difference 8.517001806867334, sinkhorn epsilon 0.0\n",
      "Iteration  2272\n",
      "Training: loss 4.570601940155029, covariance difference 1.0058857202529907\n",
      "Validation: loss 5.7011544020678935, covariance difference 8.530189621672841, sinkhorn epsilon 5.160492030717842e-14\n",
      "Iteration  2273\n",
      "Training: loss 4.661421775817871, covariance difference 1.0211387872695923\n",
      "Validation: loss 5.584261058504369, covariance difference 8.599531986455675, sinkhorn epsilon 0.0\n",
      "Iteration  2274\n",
      "Training: loss 4.54453182220459, covariance difference 1.0015919208526611\n",
      "Validation: loss 5.69212911653834, covariance difference 8.575277800367088, sinkhorn epsilon 0.0\n",
      "Iteration  2275\n",
      "Training: loss 4.652393341064453, covariance difference 1.0202357769012451\n",
      "Validation: loss 5.617722694936947, covariance difference 8.566316134210862, sinkhorn epsilon 0.0\n",
      "Iteration  2276\n",
      "Training: loss 4.5779876708984375, covariance difference 1.0082159042358398\n",
      "Validation: loss 5.670213816963745, covariance difference 8.62288159551248, sinkhorn epsilon 0.0\n",
      "Iteration  2277\n",
      "Training: loss 4.630483627319336, covariance difference 1.0169702768325806\n",
      "Validation: loss 5.67016726065596, covariance difference 8.437690962649544, sinkhorn epsilon 0.0\n",
      "Iteration  2278\n",
      "Training: loss 4.630431652069092, covariance difference 1.0200152397155762\n",
      "Validation: loss 5.677881144583699, covariance difference 8.686355229233564, sinkhorn epsilon 0.0\n",
      "Iteration  2279\n",
      "Training: loss 4.638150215148926, covariance difference 1.018943190574646\n",
      "Validation: loss 5.690643759900426, covariance difference 8.660529291278866, sinkhorn epsilon 0.0\n",
      "Iteration  2280\n",
      "Training: loss 4.650897026062012, covariance difference 1.0196250677108765\n",
      "Validation: loss 5.622054384316224, covariance difference 8.536477327747289, sinkhorn epsilon 0.0\n",
      "Iteration  2281\n",
      "Training: loss 4.582322120666504, covariance difference 1.0077723264694214\n",
      "Validation: loss 5.68640935655368, covariance difference 8.776269390394043, sinkhorn epsilon 0.0\n",
      "Iteration  2282\n",
      "Training: loss 4.646677017211914, covariance difference 1.0211790800094604\n",
      "Validation: loss 5.662644175036373, covariance difference 8.530708552220123, sinkhorn epsilon 0.0\n",
      "Iteration  2283\n",
      "Training: loss 4.6229143142700195, covariance difference 1.0160993337631226\n",
      "Validation: loss 5.604235607860116, covariance difference 8.445569134522653, sinkhorn epsilon 1.7511755928483993e-14\n",
      "Iteration  2284\n",
      "Training: loss 4.564505577087402, covariance difference 1.0059117078781128\n",
      "Validation: loss 5.638184874293404, covariance difference 8.639402973377056, sinkhorn epsilon 0.0\n",
      "Iteration  2285\n",
      "Training: loss 4.598453044891357, covariance difference 1.0123533010482788\n",
      "Validation: loss 5.762808307121788, covariance difference 8.87833772482188, sinkhorn epsilon 4.040440313876188e-14\n",
      "Iteration  2286\n",
      "Training: loss 4.723077774047852, covariance difference 1.0356247425079346\n",
      "Validation: loss 5.6584878874239415, covariance difference 8.54065566917699, sinkhorn epsilon 0.0\n",
      "Iteration  2287\n",
      "Training: loss 4.618756294250488, covariance difference 1.0163556337356567\n",
      "Validation: loss 5.749313416700753, covariance difference 8.610548299285368, sinkhorn epsilon 0.0\n",
      "Iteration  2288\n",
      "Training: loss 4.709585189819336, covariance difference 1.0309703350067139\n",
      "Validation: loss 5.658809808396009, covariance difference 8.553279172317968, sinkhorn epsilon 0.0\n",
      "Iteration  2289\n",
      "Training: loss 4.619078159332275, covariance difference 1.0174717903137207\n",
      "Validation: loss 5.638526777777724, covariance difference 8.513151121620812, sinkhorn epsilon 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  2290\n",
      "Training: loss 4.598793983459473, covariance difference 1.012137770652771\n",
      "Validation: loss 5.6887424237997495, covariance difference 8.60341077858073, sinkhorn epsilon 0.0\n",
      "Iteration  2291\n",
      "Training: loss 4.648996353149414, covariance difference 1.0212842226028442\n",
      "Validation: loss 5.617506468180696, covariance difference 8.541341932672436, sinkhorn epsilon 0.0\n",
      "Iteration  2292\n",
      "Training: loss 4.577783107757568, covariance difference 1.0101581811904907\n",
      "Validation: loss 5.640428222297895, covariance difference 8.659582509974264, sinkhorn epsilon 0.0\n",
      "Iteration  2293\n",
      "Training: loss 4.6006927490234375, covariance difference 1.0127990245819092\n",
      "Validation: loss 5.758347971724494, covariance difference 8.748247219223138, sinkhorn epsilon 0.0\n",
      "Iteration  2294\n",
      "Training: loss 4.718611240386963, covariance difference 1.0342893600463867\n",
      "Validation: loss 5.665646426464321, covariance difference 8.398031368754612, sinkhorn epsilon 0.0\n",
      "Iteration  2295\n",
      "Training: loss 4.625913619995117, covariance difference 1.0182582139968872\n",
      "Validation: loss 5.693582421962694, covariance difference 8.622415728803198, sinkhorn epsilon 0.0\n",
      "Iteration  2296\n",
      "Training: loss 4.653853416442871, covariance difference 1.0212182998657227\n",
      "Validation: loss 5.758469394289636, covariance difference 9.028316079712415, sinkhorn epsilon 0.0\n",
      "Iteration  2297\n",
      "Training: loss 4.718733787536621, covariance difference 1.0320268869400024\n",
      "Validation: loss 5.625574881896395, covariance difference 8.437761980236864, sinkhorn epsilon 0.0\n",
      "Iteration  2298\n",
      "Training: loss 4.58583927154541, covariance difference 1.0100847482681274\n",
      "Validation: loss 5.574192907229667, covariance difference 8.592246719782816, sinkhorn epsilon 0.0\n",
      "Iteration  2299\n",
      "Training: loss 4.534462928771973, covariance difference 1.0017049312591553\n",
      "Validation: loss 5.676360882507895, covariance difference 8.771533856824723, sinkhorn epsilon 0.0\n",
      "Iteration  2300\n",
      "Training: loss 4.636624813079834, covariance difference 1.0181106328964233\n",
      "Validation: loss 5.6778499209853415, covariance difference 8.736884245180605, sinkhorn epsilon 0.0\n",
      "Iteration  2301\n",
      "Training: loss 4.638113975524902, covariance difference 1.0187997817993164\n",
      "Validation: loss 5.587219012802529, covariance difference 8.486353873980722, sinkhorn epsilon 0.0\n",
      "Iteration  2302\n",
      "Training: loss 4.547486305236816, covariance difference 1.0017595291137695\n",
      "Validation: loss 5.65711117173386, covariance difference 8.793176295817629, sinkhorn epsilon 0.0\n",
      "Iteration  2303\n",
      "Training: loss 4.617380142211914, covariance difference 1.0146129131317139\n",
      "Validation: loss 5.760100748989639, covariance difference 8.763236931199947, sinkhorn epsilon 0.0\n",
      "Iteration  2304\n",
      "Training: loss 4.720374584197998, covariance difference 1.0348871946334839\n",
      "Validation: loss 5.679473222887585, covariance difference 8.637709325612224, sinkhorn epsilon 0.0\n",
      "Iteration  2305\n",
      "Training: loss 4.639738082885742, covariance difference 1.0182119607925415\n",
      "Validation: loss 5.629406178804957, covariance difference 8.525166797569755, sinkhorn epsilon 0.0\n",
      "Iteration  2306\n",
      "Training: loss 4.589670181274414, covariance difference 1.0101739168167114\n",
      "Validation: loss 5.567515599882792, covariance difference 8.45094881032195, sinkhorn epsilon 0.0\n",
      "Iteration  2307\n",
      "Training: loss 4.527789115905762, covariance difference 0.997456967830658\n",
      "Validation: loss 5.5714377661615, covariance difference 8.627428284840166, sinkhorn epsilon 0.0\n",
      "Iteration  2308\n",
      "Training: loss 4.531706809997559, covariance difference 0.9997483491897583\n",
      "Validation: loss 5.605937664369273, covariance difference 8.494473407136413, sinkhorn epsilon 0.0\n",
      "Iteration  2309\n",
      "Training: loss 4.566206932067871, covariance difference 1.0070279836654663\n",
      "Validation: loss 5.626911540105565, covariance difference 8.513035414467096, sinkhorn epsilon 0.0\n",
      "Iteration  2310\n",
      "Training: loss 4.5871758460998535, covariance difference 1.0099692344665527\n",
      "Validation: loss 5.718686288736635, covariance difference 8.700983485565827, sinkhorn epsilon 0.0\n",
      "Iteration  2311\n",
      "Training: loss 4.678954124450684, covariance difference 1.027085542678833\n",
      "Validation: loss 5.628252287186597, covariance difference 8.783130714708268, sinkhorn epsilon 0.0\n",
      "Iteration  2312\n",
      "Training: loss 4.588520526885986, covariance difference 1.0104409456253052\n",
      "Validation: loss 5.65148596667676, covariance difference 8.755776097031495, sinkhorn epsilon 0.0\n",
      "Iteration  2313\n",
      "Training: loss 4.611749649047852, covariance difference 1.014586329460144\n",
      "Validation: loss 5.675189530961184, covariance difference 8.663599210209242, sinkhorn epsilon 0.0\n",
      "Iteration  2314\n",
      "Training: loss 4.635457992553711, covariance difference 1.0191251039505005\n",
      "Validation: loss 5.611399912311799, covariance difference 8.427556633028148, sinkhorn epsilon 0.0\n",
      "Iteration  2315\n",
      "Training: loss 4.571665287017822, covariance difference 1.0054527521133423\n",
      "Validation: loss 5.622175022015208, covariance difference 8.834484468937772, sinkhorn epsilon 0.0\n",
      "Iteration  2316\n",
      "Training: loss 4.582439422607422, covariance difference 1.0084373950958252\n",
      "Validation: loss 5.6759923554232214, covariance difference 9.018684459240497, sinkhorn epsilon 0.0\n",
      "Iteration  2317\n",
      "Training: loss 4.636260986328125, covariance difference 1.0183711051940918\n",
      "Validation: loss 5.730312689814898, covariance difference 8.684413511001665, sinkhorn epsilon 8.125405866194527e-14\n",
      "Iteration  2318\n",
      "Training: loss 4.690581321716309, covariance difference 1.028165578842163\n",
      "Validation: loss 5.650033535092941, covariance difference 8.592524915369763, sinkhorn epsilon 0.0\n",
      "Iteration  2319\n",
      "Training: loss 4.610298156738281, covariance difference 1.0149459838867188\n",
      "Validation: loss 5.633501420044237, covariance difference 8.556090381417835, sinkhorn epsilon 0.0\n",
      "Iteration  2320\n",
      "Training: loss 4.5937700271606445, covariance difference 1.0123658180236816\n",
      "Validation: loss 5.65375493791365, covariance difference 8.734501858231782, sinkhorn epsilon 0.0\n",
      "Iteration  2321\n",
      "Training: loss 4.614022731781006, covariance difference 1.014298915863037\n",
      "Validation: loss 5.690515860039451, covariance difference 8.849956164672559, sinkhorn epsilon 0.0\n",
      "Iteration  2322\n",
      "Training: loss 4.650780200958252, covariance difference 1.0221058130264282\n",
      "Validation: loss 5.670218191494283, covariance difference 8.634236863375108, sinkhorn epsilon 0.0\n",
      "Iteration  2323\n",
      "Training: loss 4.6304826736450195, covariance difference 1.018301248550415\n",
      "Validation: loss 5.65216717330601, covariance difference 8.642177003174188, sinkhorn epsilon 0.0\n",
      "Iteration  2324\n",
      "Training: loss 4.612435340881348, covariance difference 1.0139662027359009\n",
      "Validation: loss 5.6933902028619485, covariance difference 8.683979049080927, sinkhorn epsilon 0.0\n",
      "Iteration  2325\n",
      "Training: loss 4.653654098510742, covariance difference 1.0198416709899902\n",
      "Validation: loss 5.649428424091106, covariance difference 8.58975909963515, sinkhorn epsilon 0.0\n",
      "Iteration  2326\n",
      "Training: loss 4.6096930503845215, covariance difference 1.0116876363754272\n",
      "Validation: loss 5.625493480359206, covariance difference 8.403744613820288, sinkhorn epsilon 0.0\n",
      "Iteration  2327\n",
      "Training: loss 4.585757732391357, covariance difference 1.0082272291183472\n",
      "Validation: loss 5.634958850551229, covariance difference 8.49816258441102, sinkhorn epsilon 0.0\n",
      "Iteration  2328\n",
      "Training: loss 4.595223426818848, covariance difference 1.0117448568344116\n",
      "Validation: loss 5.621290145822686, covariance difference 8.544519869445239, sinkhorn epsilon 0.0\n",
      "Iteration  2329\n",
      "Training: loss 4.5815582275390625, covariance difference 1.0080735683441162\n",
      "Validation: loss 5.635455047688434, covariance difference 8.690775787199684, sinkhorn epsilon 0.0\n",
      "Iteration  2330\n",
      "Training: loss 4.595719814300537, covariance difference 1.0104893445968628\n",
      "Validation: loss 5.607586083373159, covariance difference 8.603402666819592, sinkhorn epsilon 0.0\n",
      "Iteration  2331\n",
      "Training: loss 4.5678510665893555, covariance difference 1.0059210062026978\n",
      "Validation: loss 5.5748785408603, covariance difference 8.40871542109437, sinkhorn epsilon 0.0\n",
      "Iteration  2332\n",
      "Training: loss 4.535143852233887, covariance difference 0.9996311664581299\n",
      "Validation: loss 5.663648602246937, covariance difference 8.409363400359974, sinkhorn epsilon 0.0\n",
      "Iteration  2333\n",
      "Training: loss 4.62391996383667, covariance difference 1.0151848793029785\n",
      "Validation: loss 5.702369725924415, covariance difference 8.913607011269674, sinkhorn epsilon 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  2334\n",
      "Training: loss 4.662641525268555, covariance difference 1.0231022834777832\n",
      "Validation: loss 5.701305305814554, covariance difference 8.759137245773104, sinkhorn epsilon 0.0\n",
      "Iteration  2335\n",
      "Training: loss 4.661563873291016, covariance difference 1.024367094039917\n",
      "Validation: loss 5.574679270090948, covariance difference 8.420264494508244, sinkhorn epsilon 0.0\n",
      "Iteration  2336\n",
      "Training: loss 4.53494930267334, covariance difference 1.0018068552017212\n",
      "Validation: loss 5.624599661210737, covariance difference 8.48198704020123, sinkhorn epsilon 3.6559965400591467e-14\n",
      "Iteration  2337\n",
      "Training: loss 4.584867477416992, covariance difference 1.0094765424728394\n",
      "Validation: loss 5.5782196596070905, covariance difference 8.494167829476572, sinkhorn epsilon 0.0\n",
      "Iteration  2338\n",
      "Training: loss 4.5384840965271, covariance difference 1.0027610063552856\n",
      "Validation: loss 5.671544116790415, covariance difference 8.66042480019916, sinkhorn epsilon 0.0\n",
      "Iteration  2339\n",
      "Training: loss 4.631821632385254, covariance difference 1.0150116682052612\n",
      "Validation: loss 5.556702865906949, covariance difference 8.46509948302024, sinkhorn epsilon 5.5546781006104653e-14\n",
      "Iteration  2340\n",
      "Training: loss 4.516971588134766, covariance difference 0.996275007724762\n",
      "Validation: loss 5.692469982800176, covariance difference 8.743436592510514, sinkhorn epsilon 0.0\n",
      "Iteration  2341\n",
      "Training: loss 4.652740478515625, covariance difference 1.0221704244613647\n",
      "Validation: loss 5.639792449398818, covariance difference 8.517814080644246, sinkhorn epsilon 0.0\n",
      "Iteration  2342\n",
      "Training: loss 4.60006046295166, covariance difference 1.012004017829895\n",
      "Validation: loss 5.63362787696415, covariance difference 8.513711561564994, sinkhorn epsilon 0.0\n",
      "Iteration  2343\n",
      "Training: loss 4.593898773193359, covariance difference 1.0104565620422363\n",
      "Validation: loss 5.6373380529662525, covariance difference 8.366494743182859, sinkhorn epsilon 0.0\n",
      "Iteration  2344\n",
      "Training: loss 4.597602367401123, covariance difference 1.010738492012024\n",
      "Validation: loss 5.6051772109971125, covariance difference 8.768012971799639, sinkhorn epsilon 0.0\n",
      "Iteration  2345\n",
      "Training: loss 4.565445899963379, covariance difference 1.0065399408340454\n",
      "Validation: loss 5.627668611385889, covariance difference 8.642279832470406, sinkhorn epsilon 0.0\n",
      "Iteration  2346\n",
      "Training: loss 4.58793306350708, covariance difference 1.0085762739181519\n",
      "Validation: loss 5.695962479019812, covariance difference 8.667383398845649, sinkhorn epsilon 2.785594319258933e-14\n",
      "Iteration  2347\n",
      "Training: loss 4.656230926513672, covariance difference 1.020602822303772\n",
      "Validation: loss 5.742768501782958, covariance difference 8.787314345044706, sinkhorn epsilon 0.0\n",
      "Iteration  2348\n",
      "Training: loss 4.70303201675415, covariance difference 1.03078031539917\n",
      "Validation: loss 5.65331090619052, covariance difference 8.672194882873011, sinkhorn epsilon 0.0\n",
      "Iteration  2349\n",
      "Training: loss 4.613574504852295, covariance difference 1.014953374862671\n",
      "Validation: loss 5.677667957990289, covariance difference 8.591859082764694, sinkhorn epsilon 0.0\n",
      "Iteration  2350\n",
      "Training: loss 4.6379313468933105, covariance difference 1.0183497667312622\n",
      "Validation: loss 5.61638621345074, covariance difference 8.391678129480937, sinkhorn epsilon 0.0\n",
      "Iteration  2351\n",
      "Training: loss 4.576654434204102, covariance difference 1.00606369972229\n",
      "Validation: loss 5.6847238251440695, covariance difference 8.85626625737263, sinkhorn epsilon 0.0\n",
      "Iteration  2352\n",
      "Training: loss 4.644989013671875, covariance difference 1.020000696182251\n",
      "Validation: loss 5.723522491571812, covariance difference 8.761801668796874, sinkhorn epsilon 0.0\n",
      "Iteration  2353\n",
      "Training: loss 4.683787822723389, covariance difference 1.0263395309448242\n",
      "Validation: loss 5.66186690510017, covariance difference 8.589971355028835, sinkhorn epsilon 0.0\n",
      "Iteration  2354\n",
      "Training: loss 4.622128486633301, covariance difference 1.016770362854004\n",
      "Validation: loss 5.643250882031176, covariance difference 8.650924304639572, sinkhorn epsilon 0.0\n",
      "Iteration  2355\n",
      "Training: loss 4.603517532348633, covariance difference 1.0144779682159424\n",
      "Validation: loss 5.70852004990347, covariance difference 8.747410573159643, sinkhorn epsilon 0.0\n",
      "Iteration  2356\n",
      "Training: loss 4.668783187866211, covariance difference 1.0236167907714844\n",
      "Validation: loss 5.681147050009715, covariance difference 8.829613389921905, sinkhorn epsilon 0.0\n",
      "Iteration  2357\n",
      "Training: loss 4.641415119171143, covariance difference 1.01840078830719\n",
      "Validation: loss 5.661784490841981, covariance difference 8.63721030731674, sinkhorn epsilon 0.0\n",
      "Iteration  2358\n",
      "Training: loss 4.622053146362305, covariance difference 1.0151852369308472\n",
      "Validation: loss 5.6760669497994805, covariance difference 8.44912271401937, sinkhorn epsilon 0.0\n",
      "Iteration  2359\n",
      "Training: loss 4.636331558227539, covariance difference 1.017733097076416\n",
      "Validation: loss 5.703447200977925, covariance difference 8.564498537657357, sinkhorn epsilon 0.0\n",
      "Iteration  2360\n",
      "Training: loss 4.663712024688721, covariance difference 1.0225993394851685\n",
      "Validation: loss 5.703857437732719, covariance difference 8.629440779891508, sinkhorn epsilon 0.0\n",
      "Iteration  2361\n",
      "Training: loss 4.66412353515625, covariance difference 1.0227367877960205\n",
      "Validation: loss 5.6614922097613025, covariance difference 8.620820983055683, sinkhorn epsilon 0.0\n",
      "Iteration  2362\n",
      "Training: loss 4.621760368347168, covariance difference 1.014927864074707\n",
      "Validation: loss 5.614560039933289, covariance difference 8.477552350025237, sinkhorn epsilon 0.0\n",
      "Iteration  2363\n",
      "Training: loss 4.574824333190918, covariance difference 1.007981300354004\n",
      "Validation: loss 5.683542061781847, covariance difference 8.624454385043006, sinkhorn epsilon 0.0\n",
      "Iteration  2364\n",
      "Training: loss 4.643806457519531, covariance difference 1.0217461585998535\n",
      "Validation: loss 5.7082878145501, covariance difference 8.568293240269403, sinkhorn epsilon 0.0\n",
      "Iteration  2365\n",
      "Training: loss 4.668552398681641, covariance difference 1.0241707563400269\n",
      "Validation: loss 5.664716857192748, covariance difference 8.863646937242514, sinkhorn epsilon 0.0\n",
      "Iteration  2366\n",
      "Training: loss 4.6249847412109375, covariance difference 1.0176258087158203\n",
      "Validation: loss 5.607489293461448, covariance difference 8.682845563826007, sinkhorn epsilon 0.0\n",
      "Iteration  2367\n",
      "Training: loss 4.567753791809082, covariance difference 1.0062694549560547\n",
      "Validation: loss 5.689512239840628, covariance difference 8.713499949604982, sinkhorn epsilon 0.0\n",
      "Iteration  2368\n",
      "Training: loss 4.649776935577393, covariance difference 1.0195767879486084\n",
      "Validation: loss 5.669554955563404, covariance difference 8.724756612740148, sinkhorn epsilon 0.0\n",
      "Iteration  2369\n",
      "Training: loss 4.629828929901123, covariance difference 1.0181348323822021\n",
      "Validation: loss 5.646014423945105, covariance difference 8.620564744552599, sinkhorn epsilon 0.0\n",
      "Iteration  2370\n",
      "Training: loss 4.6062822341918945, covariance difference 1.0115208625793457\n",
      "Validation: loss 5.6441408130125605, covariance difference 8.577919412614117, sinkhorn epsilon 0.0\n",
      "Iteration  2371\n",
      "Training: loss 4.604405403137207, covariance difference 1.0112625360488892\n",
      "Validation: loss 5.6170218201204865, covariance difference 8.705680388976264, sinkhorn epsilon 0.0\n",
      "Iteration  2372\n",
      "Training: loss 4.5772857666015625, covariance difference 1.0072672367095947\n",
      "Validation: loss 5.669959629924236, covariance difference 8.448887987629371, sinkhorn epsilon 0.0\n",
      "Iteration  2373\n",
      "Training: loss 4.630228042602539, covariance difference 1.0150831937789917\n",
      "Validation: loss 5.600890653381647, covariance difference 8.539551820366526, sinkhorn epsilon 0.0\n",
      "Iteration  2374\n",
      "Training: loss 4.561154842376709, covariance difference 1.005314826965332\n",
      "Validation: loss 5.6855248085562, covariance difference 8.74727279340735, sinkhorn epsilon 0.0\n",
      "Iteration  2375\n",
      "Training: loss 4.6457929611206055, covariance difference 1.019177794456482\n",
      "Validation: loss 5.6938901673616025, covariance difference 8.657879285811658, sinkhorn epsilon 0.0\n",
      "Iteration  2376\n",
      "Training: loss 4.654153823852539, covariance difference 1.0219650268554688\n",
      "Validation: loss 5.710907195357315, covariance difference 8.453812062659809, sinkhorn epsilon 0.0\n",
      "Iteration  2377\n",
      "Training: loss 4.671162128448486, covariance difference 1.025580883026123\n",
      "Validation: loss 5.674975779649323, covariance difference 8.827585627808842, sinkhorn epsilon 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  2378\n",
      "Training: loss 4.635239601135254, covariance difference 1.0188673734664917\n",
      "Validation: loss 5.699393717895793, covariance difference 8.740717218226541, sinkhorn epsilon 0.0\n",
      "Iteration  2379\n",
      "Training: loss 4.659665107727051, covariance difference 1.0226683616638184\n",
      "Validation: loss 5.591391546048985, covariance difference 8.321619320971442, sinkhorn epsilon 0.0\n",
      "Iteration  2380\n",
      "Training: loss 4.5516510009765625, covariance difference 1.0040675401687622\n",
      "Validation: loss 5.684167169426539, covariance difference 8.441722748100048, sinkhorn epsilon 0.0\n",
      "Iteration  2381\n",
      "Training: loss 4.644435405731201, covariance difference 1.0193636417388916\n",
      "Validation: loss 5.687574746627506, covariance difference 8.890537106614861, sinkhorn epsilon 0.0\n",
      "Iteration  2382\n",
      "Training: loss 4.647839546203613, covariance difference 1.0212602615356445\n",
      "Validation: loss 5.688210840614331, covariance difference 8.843014788167292, sinkhorn epsilon 0.0\n",
      "Iteration  2383\n",
      "Training: loss 4.648478984832764, covariance difference 1.0196410417556763\n",
      "Validation: loss 5.675881135127341, covariance difference 8.64529444176052, sinkhorn epsilon 0.0\n",
      "Iteration  2384\n",
      "Training: loss 4.6361494064331055, covariance difference 1.0177948474884033\n",
      "Validation: loss 5.642849816626093, covariance difference 8.530901930984518, sinkhorn epsilon 0.0\n",
      "Iteration  2385\n",
      "Training: loss 4.603115081787109, covariance difference 1.0137529373168945\n",
      "Validation: loss 5.648340013124035, covariance difference 8.903857380753232, sinkhorn epsilon 0.0\n",
      "Iteration  2386\n",
      "Training: loss 4.6086039543151855, covariance difference 1.014070749282837\n",
      "Validation: loss 5.6304468254397175, covariance difference 8.435982285125519, sinkhorn epsilon 0.0\n",
      "Iteration  2387\n",
      "Training: loss 4.590714454650879, covariance difference 1.0097893476486206\n",
      "Validation: loss 5.603394586066017, covariance difference 8.500393061181887, sinkhorn epsilon 0.0\n",
      "Iteration  2388\n",
      "Training: loss 4.563659191131592, covariance difference 1.0051133632659912\n",
      "Validation: loss 5.653817814669146, covariance difference 8.733893758064845, sinkhorn epsilon 0.0\n",
      "Iteration  2389\n",
      "Training: loss 4.614086151123047, covariance difference 1.0148946046829224\n",
      "Validation: loss 5.618715033619763, covariance difference 8.439144464477637, sinkhorn epsilon 0.0\n",
      "Iteration  2390\n",
      "Training: loss 4.578986167907715, covariance difference 1.0068942308425903\n",
      "Validation: loss 5.653732797858837, covariance difference 8.396792789711743, sinkhorn epsilon 0.0\n",
      "Iteration  2391\n",
      "Training: loss 4.613996505737305, covariance difference 1.0134103298187256\n",
      "Validation: loss 5.673104545954371, covariance difference 8.743785363700109, sinkhorn epsilon 0.0\n",
      "Iteration  2392\n",
      "Training: loss 4.633368492126465, covariance difference 1.0168511867523193\n",
      "Validation: loss 5.687904894948768, covariance difference 8.470132160633792, sinkhorn epsilon 0.0\n",
      "Iteration  2393\n",
      "Training: loss 4.648172378540039, covariance difference 1.0214061737060547\n",
      "Validation: loss 5.71303135876588, covariance difference 8.65375005129663, sinkhorn epsilon 0.0\n",
      "Iteration  2394\n",
      "Training: loss 4.673300743103027, covariance difference 1.0262902975082397\n",
      "Validation: loss 5.672877250374756, covariance difference 8.588265781553229, sinkhorn epsilon 0.0\n",
      "Iteration  2395\n",
      "Training: loss 4.633142471313477, covariance difference 1.0178452730178833\n",
      "Validation: loss 5.618330415442422, covariance difference 8.470556688839377, sinkhorn epsilon 0.0\n",
      "Iteration  2396\n",
      "Training: loss 4.578594207763672, covariance difference 1.0073696374893188\n",
      "Validation: loss 5.612855857940219, covariance difference 8.60258677463137, sinkhorn epsilon 0.0\n",
      "Iteration  2397\n",
      "Training: loss 4.5731306076049805, covariance difference 1.0081695318222046\n",
      "Validation: loss 5.6262355747832835, covariance difference 8.649719775261634, sinkhorn epsilon 0.0\n",
      "Iteration  2398\n",
      "Training: loss 4.58650016784668, covariance difference 1.0085840225219727\n",
      "Validation: loss 5.598875012347045, covariance difference 8.674731220150807, sinkhorn epsilon 0.0\n",
      "Iteration  2399\n",
      "Training: loss 4.559140205383301, covariance difference 1.0038739442825317\n",
      "Validation: loss 5.645240070211121, covariance difference 8.71108256951493, sinkhorn epsilon 0.0\n",
      "Iteration  2400\n",
      "Training: loss 4.6055145263671875, covariance difference 1.0145353078842163\n",
      "Validation: loss 5.738262644305781, covariance difference 8.80421105106783, sinkhorn epsilon 0.0\n",
      "Iteration  2401\n",
      "Training: loss 4.698525905609131, covariance difference 1.0281637907028198\n",
      "Validation: loss 5.674225595888915, covariance difference 8.766154152599865, sinkhorn epsilon 0.0\n",
      "Iteration  2402\n",
      "Training: loss 4.634495258331299, covariance difference 1.0179561376571655\n",
      "Validation: loss 5.637842555610713, covariance difference 8.502809278568291, sinkhorn epsilon 0.0\n",
      "Iteration  2403\n",
      "Training: loss 4.598111152648926, covariance difference 1.0101144313812256\n",
      "Validation: loss 5.6332613936371505, covariance difference 8.675930806288118, sinkhorn epsilon 0.0\n",
      "Iteration  2404\n",
      "Training: loss 4.593529224395752, covariance difference 1.0107823610305786\n",
      "Validation: loss 5.654797285692039, covariance difference 8.506837071975907, sinkhorn epsilon 0.0\n",
      "Iteration  2405\n",
      "Training: loss 4.6150617599487305, covariance difference 1.0140537023544312\n",
      "Validation: loss 5.611083088965861, covariance difference 8.429477781132196, sinkhorn epsilon 0.0\n",
      "Iteration  2406\n",
      "Training: loss 4.571347236633301, covariance difference 1.0076789855957031\n",
      "Validation: loss 5.5360502853630065, covariance difference 8.591979294085604, sinkhorn epsilon 0.0\n",
      "Iteration  2407\n",
      "Training: loss 4.496315002441406, covariance difference 0.994117796421051\n",
      "Validation: loss 5.591270145044612, covariance difference 8.382203900391682, sinkhorn epsilon 0.0\n",
      "Iteration  2408\n",
      "Training: loss 4.55153751373291, covariance difference 1.002532720565796\n",
      "Validation: loss 5.632977164468445, covariance difference 8.639268486221315, sinkhorn epsilon 0.0\n",
      "Iteration  2409\n",
      "Training: loss 4.5932416915893555, covariance difference 1.0097206830978394\n",
      "Validation: loss 5.678317109375564, covariance difference 8.729182231950206, sinkhorn epsilon 0.0\n",
      "Iteration  2410\n",
      "Training: loss 4.638585090637207, covariance difference 1.018054485321045\n",
      "Validation: loss 5.613645883807346, covariance difference 8.370082469825608, sinkhorn epsilon 0.0\n",
      "Iteration  2411\n",
      "Training: loss 4.57391357421875, covariance difference 1.0075746774673462\n",
      "Validation: loss 5.700619017064521, covariance difference 8.712306223459787, sinkhorn epsilon 0.0\n",
      "Iteration  2412\n",
      "Training: loss 4.660882949829102, covariance difference 1.0242334604263306\n",
      "Validation: loss 5.677828391949802, covariance difference 8.85925731149211, sinkhorn epsilon 0.0\n",
      "Iteration  2413\n",
      "Training: loss 4.638092041015625, covariance difference 1.0190770626068115\n",
      "Validation: loss 5.5892057344649135, covariance difference 8.537456574169, sinkhorn epsilon 0.0\n",
      "Iteration  2414\n",
      "Training: loss 4.549476623535156, covariance difference 1.0043823719024658\n",
      "Validation: loss 5.671778479257984, covariance difference 8.68387477285961, sinkhorn epsilon 0.0\n",
      "Iteration  2415\n",
      "Training: loss 4.632042407989502, covariance difference 1.017513394355774\n",
      "Validation: loss 5.669058518441313, covariance difference 8.549860193903536, sinkhorn epsilon 0.0\n",
      "Iteration  2416\n",
      "Training: loss 4.629327774047852, covariance difference 1.01680588722229\n",
      "Validation: loss 5.62637352676512, covariance difference 8.427889598771328, sinkhorn epsilon 0.0\n",
      "Iteration  2417\n",
      "Training: loss 4.5866379737854, covariance difference 1.0090886354446411\n",
      "Validation: loss 5.684434851953179, covariance difference 8.544794161596322, sinkhorn epsilon 0.0\n",
      "Iteration  2418\n",
      "Training: loss 4.644698143005371, covariance difference 1.0212279558181763\n",
      "Validation: loss 5.677514146200731, covariance difference 8.66083083414204, sinkhorn epsilon 0.0\n",
      "Iteration  2419\n",
      "Training: loss 4.637779235839844, covariance difference 1.0181227922439575\n",
      "Validation: loss 5.625891882949918, covariance difference 8.452512512268267, sinkhorn epsilon 0.0\n",
      "Iteration  2420\n",
      "Training: loss 4.586156368255615, covariance difference 1.008940577507019\n",
      "Validation: loss 5.684687119114386, covariance difference 8.445796476267612, sinkhorn epsilon 0.0\n",
      "Iteration  2421\n",
      "Training: loss 4.644960403442383, covariance difference 1.0208653211593628\n",
      "Validation: loss 5.687027228670599, covariance difference 8.638374722046716, sinkhorn epsilon 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  2422\n",
      "Training: loss 4.647294521331787, covariance difference 1.0192958116531372\n",
      "Validation: loss 5.684888491415287, covariance difference 8.57615541038302, sinkhorn epsilon 0.0\n",
      "Iteration  2423\n",
      "Training: loss 4.6451568603515625, covariance difference 1.0212184190750122\n",
      "Validation: loss 5.660691554018415, covariance difference 8.707924446002162, sinkhorn epsilon 0.0\n",
      "Iteration  2424\n",
      "Training: loss 4.620955467224121, covariance difference 1.0167316198349\n",
      "Validation: loss 5.640913172004689, covariance difference 8.324815180079534, sinkhorn epsilon 0.0\n",
      "Iteration  2425\n",
      "Training: loss 4.6011810302734375, covariance difference 1.0130890607833862\n",
      "Validation: loss 5.625791612425095, covariance difference 8.629652004427225, sinkhorn epsilon 0.0\n",
      "Iteration  2426\n",
      "Training: loss 4.5860595703125, covariance difference 1.0100317001342773\n",
      "Validation: loss 5.599217198336726, covariance difference 8.700639888754527, sinkhorn epsilon 0.0\n",
      "Iteration  2427\n",
      "Training: loss 4.5594868659973145, covariance difference 1.0052440166473389\n",
      "Validation: loss 5.582750608454647, covariance difference 8.531270330019415, sinkhorn epsilon 0.0\n",
      "Iteration  2428\n",
      "Training: loss 4.543015480041504, covariance difference 1.0017555952072144\n",
      "Validation: loss 5.688816900964173, covariance difference 8.475300785315541, sinkhorn epsilon 0.0\n",
      "Iteration  2429\n",
      "Training: loss 4.649086952209473, covariance difference 1.021454095840454\n",
      "Validation: loss 5.711731203085089, covariance difference 8.539030186217056, sinkhorn epsilon 0.0\n",
      "Iteration  2430\n",
      "Training: loss 4.672008514404297, covariance difference 1.0256400108337402\n",
      "Validation: loss 5.733160931856511, covariance difference 8.932852376047546, sinkhorn epsilon 0.0\n",
      "Iteration  2431\n",
      "Training: loss 4.693424701690674, covariance difference 1.0297216176986694\n",
      "Validation: loss 5.628752152441944, covariance difference 8.565199314135997, sinkhorn epsilon 0.0\n",
      "Iteration  2432\n",
      "Training: loss 4.589020729064941, covariance difference 1.0108964443206787\n",
      "Validation: loss 5.6466904565090585, covariance difference 8.546783379137803, sinkhorn epsilon 0.0\n",
      "Iteration  2433\n",
      "Training: loss 4.606959819793701, covariance difference 1.0150376558303833\n",
      "Validation: loss 5.685418451929031, covariance difference 8.599249154450744, sinkhorn epsilon 0.0\n",
      "Iteration  2434\n",
      "Training: loss 4.645689964294434, covariance difference 1.020585536956787\n",
      "Validation: loss 5.732286594970368, covariance difference 8.697783628753255, sinkhorn epsilon 0.0\n",
      "Iteration  2435\n",
      "Training: loss 4.692554473876953, covariance difference 1.0302491188049316\n",
      "Validation: loss 5.5879618982802235, covariance difference 8.391080179449084, sinkhorn epsilon 3.0093759320981406e-14\n",
      "Iteration  2436\n",
      "Training: loss 4.5482330322265625, covariance difference 1.0009077787399292\n",
      "Validation: loss 5.645496364130686, covariance difference 8.651368517843435, sinkhorn epsilon 0.0\n",
      "Iteration  2437\n",
      "Training: loss 4.60576057434082, covariance difference 1.0161206722259521\n",
      "Validation: loss 5.674356315133457, covariance difference 8.609866854921194, sinkhorn epsilon 0.0\n",
      "Iteration  2438\n",
      "Training: loss 4.634609222412109, covariance difference 1.0187801122665405\n",
      "Validation: loss 5.621298156954107, covariance difference 8.607955027734688, sinkhorn epsilon 0.0\n",
      "Iteration  2439\n",
      "Training: loss 4.58156681060791, covariance difference 1.0079149007797241\n",
      "Validation: loss 5.5832255082033555, covariance difference 8.507019729638005, sinkhorn epsilon 0.0\n",
      "Iteration  2440\n",
      "Training: loss 4.54349422454834, covariance difference 1.0022379159927368\n",
      "Validation: loss 5.70606273818411, covariance difference 8.875991093119199, sinkhorn epsilon 0.0\n",
      "Iteration  2441\n",
      "Training: loss 4.666330814361572, covariance difference 1.0223934650421143\n",
      "Validation: loss 5.642389949405605, covariance difference 8.606470454274396, sinkhorn epsilon 0.0\n",
      "Iteration  2442\n",
      "Training: loss 4.602659225463867, covariance difference 1.013612151145935\n",
      "Validation: loss 5.635505643569623, covariance difference 8.600024162465747, sinkhorn epsilon 0.0\n",
      "Iteration  2443\n",
      "Training: loss 4.595758438110352, covariance difference 1.0111669301986694\n",
      "Validation: loss 5.610150182588271, covariance difference 8.538422800748677, sinkhorn epsilon 0.0\n",
      "Iteration  2444\n",
      "Training: loss 4.5704193115234375, covariance difference 1.0066269636154175\n",
      "Validation: loss 5.676139320090432, covariance difference 8.600779275941125, sinkhorn epsilon 0.0\n",
      "Iteration  2445\n",
      "Training: loss 4.636407852172852, covariance difference 1.0178852081298828\n",
      "Validation: loss 5.707355505501161, covariance difference 8.640243755375066, sinkhorn epsilon 0.0\n",
      "Iteration  2446\n",
      "Training: loss 4.667619228363037, covariance difference 1.02450430393219\n",
      "Validation: loss 5.7009308641759135, covariance difference 8.672765378122145, sinkhorn epsilon 0.0\n",
      "Iteration  2447\n",
      "Training: loss 4.66119384765625, covariance difference 1.022801160812378\n",
      "Validation: loss 5.71186268412478, covariance difference 8.566177196969647, sinkhorn epsilon 0.0\n",
      "Iteration  2448\n",
      "Training: loss 4.672130584716797, covariance difference 1.0258241891860962\n",
      "Validation: loss 5.620327326126952, covariance difference 8.461221201459754, sinkhorn epsilon 0.0\n",
      "Iteration  2449\n",
      "Training: loss 4.580589771270752, covariance difference 1.0094759464263916\n",
      "Validation: loss 5.633594374002909, covariance difference 8.50925515757033, sinkhorn epsilon 0.0\n",
      "Iteration  2450\n",
      "Training: loss 4.593865394592285, covariance difference 1.009405493736267\n",
      "Validation: loss 5.717686189012458, covariance difference 8.603504069127455, sinkhorn epsilon 0.0\n",
      "Iteration  2451\n",
      "Training: loss 4.677947044372559, covariance difference 1.0267375707626343\n",
      "Validation: loss 5.661169435183416, covariance difference 8.827320816418096, sinkhorn epsilon 0.0\n",
      "Iteration  2452\n",
      "Training: loss 4.621437072753906, covariance difference 1.0165588855743408\n",
      "Validation: loss 5.690832724799104, covariance difference 8.67949159348093, sinkhorn epsilon 0.0\n",
      "Iteration  2453\n",
      "Training: loss 4.651101112365723, covariance difference 1.021669864654541\n",
      "Validation: loss 5.708703002176078, covariance difference 8.57777927463536, sinkhorn epsilon 0.0\n",
      "Iteration  2454\n",
      "Training: loss 4.668975830078125, covariance difference 1.0241470336914062\n",
      "Validation: loss 5.595746509162506, covariance difference 8.447152346533219, sinkhorn epsilon 0.0\n",
      "Iteration  2455\n",
      "Training: loss 4.5560150146484375, covariance difference 1.0051583051681519\n",
      "Validation: loss 5.667719776729926, covariance difference 8.759886363904462, sinkhorn epsilon 0.0\n",
      "Iteration  2456\n",
      "Training: loss 4.627984046936035, covariance difference 1.0169044733047485\n",
      "Validation: loss 5.616746209865251, covariance difference 8.658673251557651, sinkhorn epsilon 0.0\n",
      "Iteration  2457\n",
      "Training: loss 4.577013969421387, covariance difference 1.0080740451812744\n",
      "Validation: loss 5.637387454743797, covariance difference 8.924057834121495, sinkhorn epsilon 0.0\n",
      "Iteration  2458\n",
      "Training: loss 4.597655296325684, covariance difference 1.0110172033309937\n",
      "Validation: loss 5.697916493176517, covariance difference 8.54526038772967, sinkhorn epsilon 0.0\n",
      "Iteration  2459\n",
      "Training: loss 4.658186912536621, covariance difference 1.0223066806793213\n",
      "Validation: loss 5.686717984623153, covariance difference 8.602291592442064, sinkhorn epsilon 8.283896825698965e-14\n",
      "Iteration  2460\n",
      "Training: loss 4.646989822387695, covariance difference 1.0187989473342896\n",
      "Validation: loss 5.648600944488653, covariance difference 8.635146162396437, sinkhorn epsilon 0.0\n",
      "Iteration  2461\n",
      "Training: loss 4.608857154846191, covariance difference 1.0130218267440796\n",
      "Validation: loss 5.643075015809605, covariance difference 8.585274485917012, sinkhorn epsilon 0.0\n",
      "Iteration  2462\n",
      "Training: loss 4.603342533111572, covariance difference 1.0119774341583252\n",
      "Validation: loss 5.580254138872233, covariance difference 8.619874774029965, sinkhorn epsilon 0.0\n",
      "Iteration  2463\n",
      "Training: loss 4.540522575378418, covariance difference 1.0011627674102783\n",
      "Validation: loss 5.622222165957524, covariance difference 8.773479464749258, sinkhorn epsilon 0.0\n",
      "Iteration  2464\n",
      "Training: loss 4.582486152648926, covariance difference 1.009236216545105\n",
      "Validation: loss 5.642430064169889, covariance difference 8.447057395523126, sinkhorn epsilon 0.0\n",
      "Iteration  2465\n",
      "Training: loss 4.602694511413574, covariance difference 1.0131534337997437\n",
      "Validation: loss 5.736564407702788, covariance difference 8.620044897080797, sinkhorn epsilon 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  2466\n",
      "Training: loss 4.696832656860352, covariance difference 1.027296543121338\n",
      "Validation: loss 5.647126422009386, covariance difference 8.414685723337527, sinkhorn epsilon 0.0\n",
      "Iteration  2467\n",
      "Training: loss 4.607394218444824, covariance difference 1.0132899284362793\n",
      "Validation: loss 5.685137460283099, covariance difference 8.885702387228484, sinkhorn epsilon 0.0\n",
      "Iteration  2468\n",
      "Training: loss 4.645401477813721, covariance difference 1.0212925672531128\n",
      "Validation: loss 5.667649714894838, covariance difference 8.714643387043603, sinkhorn epsilon 0.0\n",
      "Iteration  2469\n",
      "Training: loss 4.6279144287109375, covariance difference 1.0160603523254395\n",
      "Validation: loss 5.669322039824641, covariance difference 8.745205860435366, sinkhorn epsilon 0.0\n",
      "Iteration  2470\n",
      "Training: loss 4.629574775695801, covariance difference 1.0190370082855225\n",
      "Validation: loss 5.679899005635677, covariance difference 8.747844418415694, sinkhorn epsilon 0.0\n",
      "Iteration  2471\n",
      "Training: loss 4.640162467956543, covariance difference 1.0187602043151855\n",
      "Validation: loss 5.617025182874033, covariance difference 8.639352196319884, sinkhorn epsilon 0.0\n",
      "Iteration  2472\n",
      "Training: loss 4.577289581298828, covariance difference 1.008193850517273\n",
      "Validation: loss 5.694915416942159, covariance difference 8.614239353949403, sinkhorn epsilon 0.0\n",
      "Iteration  2473\n",
      "Training: loss 4.655183792114258, covariance difference 1.019775152206421\n",
      "Validation: loss 5.707351486725447, covariance difference 8.595205881259709, sinkhorn epsilon 0.0\n",
      "Iteration  2474\n",
      "Training: loss 4.6676154136657715, covariance difference 1.0246505737304688\n",
      "Validation: loss 5.636895975043262, covariance difference 8.63731928152176, sinkhorn epsilon 0.0\n",
      "Iteration  2475\n",
      "Training: loss 4.597160339355469, covariance difference 1.0101593732833862\n",
      "Validation: loss 5.626775586077086, covariance difference 8.734793896571006, sinkhorn epsilon 0.0\n",
      "Iteration  2476\n",
      "Training: loss 4.587037086486816, covariance difference 1.0098203420639038\n",
      "Validation: loss 5.736217719163432, covariance difference 8.784558559695366, sinkhorn epsilon 0.0\n",
      "Iteration  2477\n",
      "Training: loss 4.6964874267578125, covariance difference 1.0288050174713135\n",
      "Validation: loss 5.567233316324936, covariance difference 8.55013077097733, sinkhorn epsilon 0.0\n",
      "Iteration  2478\n",
      "Training: loss 4.5275044441223145, covariance difference 0.9992597103118896\n",
      "Validation: loss 5.65321407948034, covariance difference 8.600415733701833, sinkhorn epsilon 0.0\n",
      "Iteration  2479\n",
      "Training: loss 4.6134819984436035, covariance difference 1.0124577283859253\n",
      "Validation: loss 5.726985776265156, covariance difference 8.863206446545615, sinkhorn epsilon 0.0\n",
      "Iteration  2480\n",
      "Training: loss 4.687258720397949, covariance difference 1.0292574167251587\n",
      "Validation: loss 5.582207205053386, covariance difference 8.333051475499687, sinkhorn epsilon 0.0\n",
      "Iteration  2481\n",
      "Training: loss 4.542471408843994, covariance difference 1.0014466047286987\n",
      "Validation: loss 5.5735605495623, covariance difference 8.575602431449674, sinkhorn epsilon 0.0\n",
      "Iteration  2482\n",
      "Training: loss 4.533830642700195, covariance difference 1.0021438598632812\n",
      "Validation: loss 5.678897643540852, covariance difference 8.626518410553485, sinkhorn epsilon 0.0\n",
      "Iteration  2483\n",
      "Training: loss 4.63916540145874, covariance difference 1.019525170326233\n",
      "Validation: loss 5.693917311371525, covariance difference 8.890530891237336, sinkhorn epsilon 0.0\n",
      "Iteration  2484\n",
      "Training: loss 4.654181003570557, covariance difference 1.0219175815582275\n",
      "Validation: loss 5.769040185685393, covariance difference 8.796239834815898, sinkhorn epsilon 0.0\n",
      "Iteration  2485\n",
      "Training: loss 4.729304313659668, covariance difference 1.0339405536651611\n",
      "Validation: loss 5.672088565029103, covariance difference 8.461704069075331, sinkhorn epsilon 0.0\n",
      "Iteration  2486\n",
      "Training: loss 4.632341384887695, covariance difference 1.0172624588012695\n",
      "Validation: loss 5.640990093128805, covariance difference 8.666578427688725, sinkhorn epsilon 0.0\n",
      "Iteration  2487\n",
      "Training: loss 4.60124397277832, covariance difference 1.0096608400344849\n",
      "Validation: loss 5.680719999075602, covariance difference 8.921257305151139, sinkhorn epsilon 0.0\n",
      "Iteration  2488\n",
      "Training: loss 4.640989303588867, covariance difference 1.0179791450500488\n",
      "Validation: loss 5.70298544866683, covariance difference 8.754164385558946, sinkhorn epsilon 0.0\n",
      "Iteration  2489\n",
      "Training: loss 4.663241863250732, covariance difference 1.0256850719451904\n",
      "Validation: loss 5.596269070334698, covariance difference 8.542441862629497, sinkhorn epsilon 0.0\n",
      "Iteration  2490\n",
      "Training: loss 4.556524753570557, covariance difference 1.004850149154663\n",
      "Validation: loss 5.679370282613993, covariance difference 8.679748205363293, sinkhorn epsilon 4.5305756498546055e-14\n",
      "Iteration  2491\n",
      "Training: loss 4.639638423919678, covariance difference 1.0183311700820923\n",
      "Validation: loss 5.628006494846221, covariance difference 8.70368438002109, sinkhorn epsilon 0.0\n",
      "Iteration  2492\n",
      "Training: loss 4.588271141052246, covariance difference 1.0087662935256958\n",
      "Validation: loss 5.667371946482382, covariance difference 8.630554521083763, sinkhorn epsilon 0.0\n",
      "Iteration  2493\n",
      "Training: loss 4.627640247344971, covariance difference 1.017027497291565\n",
      "Validation: loss 5.609593034777409, covariance difference 8.681172512361245, sinkhorn epsilon 0.0\n",
      "Iteration  2494\n",
      "Training: loss 4.569860935211182, covariance difference 1.0068581104278564\n",
      "Validation: loss 5.694845011199433, covariance difference 8.715829041263094, sinkhorn epsilon 0.0\n",
      "Iteration  2495\n",
      "Training: loss 4.6551127433776855, covariance difference 1.0243552923202515\n",
      "Validation: loss 5.730262625378525, covariance difference 8.82800763814575, sinkhorn epsilon 0.0\n",
      "Iteration  2496\n",
      "Training: loss 4.690526008605957, covariance difference 1.0291829109191895\n",
      "Validation: loss 5.655136454526646, covariance difference 8.519854562368554, sinkhorn epsilon 0.0\n",
      "Iteration  2497\n",
      "Training: loss 4.615401268005371, covariance difference 1.0157523155212402\n",
      "Validation: loss 5.6244439392944185, covariance difference 8.688724272958236, sinkhorn epsilon 0.0\n",
      "Iteration  2498\n",
      "Training: loss 4.5847086906433105, covariance difference 1.0095322132110596\n",
      "Validation: loss 5.6691140321051545, covariance difference 8.671019728283431, sinkhorn epsilon 0.0\n",
      "Iteration  2499\n",
      "Training: loss 4.629382133483887, covariance difference 1.0180569887161255\n",
      "Validation: loss 5.56228527775692, covariance difference 8.327687467148557, sinkhorn epsilon 0.0\n"
     ]
    }
   ],
   "source": [
    "y_batch = next(data_gen)\n",
    "x_batch = np.random.normal(size=(y_batch.shape[0], LATENT_DIM))\n",
    "res_train = {'loss':{}, 'cov_diff' : {}}\n",
    "res_test = {'loss':{}, 'cov_diff' : {}, 'sample':{}, 'sink_eps':{}}\n",
    "for i in range(ITERS):\n",
    "    out = generator.train_on_batch(x = x_batch,y = y_batch)\n",
    "    res_train['loss'][i] = out[0]\n",
    "    res_train['cov_diff'][i] = out[1]\n",
    "    y_batch = next(data_gen)\n",
    "    x_batch = np.random.normal(size=(y_batch.shape[0], LATENT_DIM))\n",
    "    #validate on the next data\n",
    "    y_sample = generator.predict(x_batch, batch_size=BATCH_SIZE)\n",
    "    res_test['loss'][i], res_test['sink_eps'][i] = sinkhorn_loss_np(y_sample, y_batch, epsilon, CRITIC_ITERS)\n",
    "    res_test['sample'][i] = y_sample\n",
    "    res_test['cov_diff'][i] = np.linalg.norm(np.cov(y_sample[:256,:]) - np.cov(y_batch[:256,:]))\n",
    "    print('Iteration ', i)\n",
    "    print('Training: loss {}, covariance difference {}'.format(res_train['loss'][i], res_train['cov_diff'][i]))\n",
    "    print('Validation: loss {}, covariance difference {}, sinkhorn epsilon {}'.format(\n",
    "        res_test['loss'][i], res_test['cov_diff'][i], res_test['sink_eps'][i]))\n",
    "    if i % 10 == 0:\n",
    "        with open('logs.pkl', 'wb') as f:\n",
    "            pkl.dump([res_test, res_train], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = zip(*list(res_test['cov_diff'].items()))\n",
    "\n",
    "start = 100\n",
    "plt.plot(x[start:], y[start:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
